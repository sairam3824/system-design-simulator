{"version":3,"sources":["../../../../../../../Documents/Git/system-design/system-design-simulator/src/lib/ollama.ts","../../../../../../../Documents/Git/system-design/system-design-simulator/src/app/api/ollama/status/route.ts","../../../../../../../Documents/Git/system-design/system-design-simulator/node_modules/next/dist/esm/build/templates/app-route.js"],"sourcesContent":["/**\n * Ollama Client for Local LLM Inference\n *\n * Uses Ollama running locally for faster interview interactions.\n *\n * Models:\n * - llama3 (8B): Default for system design interviews\n * - codellama:7b: Specialized for coding challenges\n *\n * Make sure Ollama is running: ollama serve\n * Pull the models:\n *   ollama pull llama3\n *   ollama pull codellama:7b\n */\n\nconst OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || \"http://localhost:11434\";\nconst OLLAMA_MODEL = process.env.OLLAMA_MODEL || \"llama3:8b\";\nconst OLLAMA_CODE_MODEL = process.env.OLLAMA_CODE_MODEL || \"codellama:7b\";\n\n// Model types for different use cases\nexport type ModelType = \"general\" | \"coding\";\n\n// Get the appropriate model based on use case\nexport function getModelForType(type: ModelType): string {\n  switch (type) {\n    case \"coding\":\n      return OLLAMA_CODE_MODEL;\n    case \"general\":\n    default:\n      return OLLAMA_MODEL;\n  }\n}\n\nexport interface OllamaMessage {\n  role: \"system\" | \"user\" | \"assistant\";\n  content: string;\n}\n\nexport interface OllamaCompletionOptions {\n  model?: string;\n  messages: OllamaMessage[];\n  stream?: boolean;\n  temperature?: number;\n  max_tokens?: number;\n  top_p?: number;\n  stop?: string[];\n}\n\nexport interface OllamaResponse {\n  model: string;\n  created_at: string;\n  message: {\n    role: string;\n    content: string;\n  };\n  done: boolean;\n  total_duration?: number;\n  load_duration?: number;\n  prompt_eval_count?: number;\n  eval_count?: number;\n}\n\n/**\n * Check if Ollama is running and available\n */\nexport async function checkOllamaHealth(): Promise<boolean> {\n  try {\n    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {\n      method: \"GET\",\n    });\n    return response.ok;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check Ollama health with Redis caching\n */\nexport async function checkOllamaHealthCached(): Promise<boolean> {\n  const { getOrFetch } = await import(\"@/lib/cache\");\n  const { CACHE_KEYS, CACHE_TTL } = await import(\"@/lib/redis\");\n\n  return getOrFetch(\n    CACHE_KEYS.OLLAMA_HEALTH,\n    checkOllamaHealth,\n    CACHE_TTL.OLLAMA_HEALTH\n  );\n}\n\n/**\n * List available models\n */\nexport async function listModels(): Promise<string[]> {\n  try {\n    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);\n    if (!response.ok) return [];\n    const data = await response.json();\n    return data.models?.map((m: { name: string }) => m.name) || [];\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Non-streaming chat completion\n */\nexport async function ollamaChat(\n  options: OllamaCompletionOptions\n): Promise<OllamaResponse> {\n  const { model = OLLAMA_MODEL, messages, temperature = 0.7 } = options;\n\n  const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\n      model,\n      messages,\n      stream: false,\n      options: {\n        temperature,\n        num_predict: options.max_tokens || 800,\n        top_p: options.top_p || 0.9,\n        stop: options.stop,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Ollama error: ${error}`);\n  }\n\n  return response.json();\n}\n\n/**\n * Streaming chat completion - returns a ReadableStream\n */\nexport async function ollamaChatStream(\n  options: OllamaCompletionOptions\n): Promise<ReadableStream<Uint8Array>> {\n  const { model = OLLAMA_MODEL, messages, temperature = 0.7 } = options;\n\n  const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\n      model,\n      messages,\n      stream: true,\n      options: {\n        temperature,\n        num_predict: options.max_tokens || 800,\n        top_p: options.top_p || 0.9,\n        stop: options.stop,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Ollama streaming error: ${error}`);\n  }\n\n  if (!response.body) {\n    throw new Error(\"No response body from Ollama\");\n  }\n\n  return response.body;\n}\n\n/**\n * Transform Ollama stream to SSE format for client consumption\n */\nexport function createOllamaSSEStream(\n  ollamaStream: ReadableStream<Uint8Array>\n): ReadableStream<Uint8Array> {\n  const encoder = new TextEncoder();\n  const decoder = new TextDecoder();\n\n  let buffer = \"\";\n\n  return new ReadableStream({\n    async start(controller) {\n      const reader = ollamaStream.getReader();\n\n      try {\n        while (true) {\n          const { done, value } = await reader.read();\n\n          if (done) {\n            controller.close();\n            break;\n          }\n\n          buffer += decoder.decode(value, { stream: true });\n\n          // Process complete JSON lines\n          const lines = buffer.split(\"\\n\");\n          buffer = lines.pop() || \"\";\n\n          for (const line of lines) {\n            if (line.trim()) {\n              try {\n                const json = JSON.parse(line);\n                if (json.message?.content) {\n                  // Send as SSE format\n                  const sseData = `data: ${JSON.stringify({ content: json.message.content })}\\n\\n`;\n                  controller.enqueue(encoder.encode(sseData));\n                }\n                if (json.done) {\n                  controller.enqueue(encoder.encode(\"data: [DONE]\\n\\n\"));\n                }\n              } catch {\n                // Skip invalid JSON lines\n              }\n            }\n          }\n        }\n      } catch (error) {\n        controller.error(error);\n      }\n    },\n  });\n}\n\n/**\n * Simple wrapper for interview chat - handles both streaming and non-streaming\n */\nexport const ollama = {\n  chat: {\n    completions: {\n      create: async (options: {\n        model?: string;\n        messages: OllamaMessage[];\n        temperature?: number;\n        max_tokens?: number;\n        stream?: boolean;\n      }) => {\n        if (options.stream) {\n          const stream = await ollamaChatStream({\n            model: options.model || OLLAMA_MODEL,\n            messages: options.messages,\n            temperature: options.temperature,\n            max_tokens: options.max_tokens,\n            stream: true,\n          });\n          return { body: createOllamaSSEStream(stream) };\n        } else {\n          const response = await ollamaChat({\n            model: options.model || OLLAMA_MODEL,\n            messages: options.messages,\n            temperature: options.temperature,\n            max_tokens: options.max_tokens,\n            stream: false,\n          });\n          return {\n            choices: [\n              {\n                message: {\n                  role: response.message.role,\n                  content: response.message.content,\n                },\n              },\n            ],\n          };\n        }\n      },\n    },\n  },\n};\n\n/**\n * CodeLlama-specific chat for coding challenges\n * Uses codellama:7b model optimized for code generation and analysis\n */\nexport async function codeLlamaChat(\n  options: Omit<OllamaCompletionOptions, \"model\">\n): Promise<OllamaResponse> {\n  return ollamaChat({\n    ...options,\n    model: OLLAMA_CODE_MODEL,\n  });\n}\n\n/**\n * Check if CodeLlama model is available\n */\nexport async function checkCodeLlamaAvailable(): Promise<boolean> {\n  try {\n    const models = await listModels();\n    return models.some(\n      (m) => m.includes(\"codellama\") || m.includes(\"code-llama\")\n    );\n  } catch {\n    return false;\n  }\n}\n\nexport default ollama;\n","/**\n * Ollama Status Check API\n *\n * GET /api/ollama/status\n * Returns the status of Ollama and available models\n *\n * Models used:\n * - llama3 (8B): System design interviews\n * - codellama:7b: Coding challenges\n */\n\nimport { NextResponse } from \"next/server\";\nimport { checkOllamaHealth, listModels } from \"@/lib/ollama\";\n\nexport async function GET() {\n  try {\n    const isHealthy = await checkOllamaHealth();\n\n    if (!isHealthy) {\n      return NextResponse.json({\n        status: \"offline\",\n        message: \"Ollama is not running. Start it with: ollama serve\",\n        models: [],\n        modelStatus: {\n          llama3: false,\n          codellama: false,\n        },\n      });\n    }\n\n    const models = await listModels();\n\n    // Check for required models\n    const hasLlama3 = models.some(\n      (m) => m.includes(\"llama3\") || m.includes(\"llama3:8b\")\n    );\n    const hasCodeLlama = models.some(\n      (m) => m.includes(\"codellama\") || m.includes(\"code-llama\")\n    );\n\n    // Build status message\n    const missingModels: string[] = [];\n    if (!hasLlama3) missingModels.push(\"llama3\");\n    if (!hasCodeLlama) missingModels.push(\"codellama:7b\");\n\n    let message = \"Ollama is running\";\n    if (missingModels.length > 0) {\n      message += `. Missing models: ${missingModels.join(\", \")}. Install with: ${missingModels.map(m => `ollama pull ${m}`).join(\" && \")}`;\n    } else {\n      message += \" with all required models (llama3 for interviews, codellama for coding)\";\n    }\n\n    return NextResponse.json({\n      status: \"online\",\n      message,\n      models,\n      modelStatus: {\n        llama3: hasLlama3,\n        codellama: hasCodeLlama,\n      },\n      // For backward compatibility\n      recommendedModel: \"llama3\",\n      hasRecommendedModel: hasLlama3,\n      // For coding challenges\n      codeModel: \"codellama:7b\",\n      hasCodeModel: hasCodeLlama,\n    });\n  } catch (error) {\n    console.error(\"Ollama status check error:\", error);\n    return NextResponse.json(\n      {\n        status: \"error\",\n        message: \"Failed to check Ollama status\",\n        models: [],\n        modelStatus: {\n          llama3: false,\n          codellama: false,\n        },\n      },\n      { status: 500 }\n    );\n  }\n}\n","import { AppRouteRouteModule } from \"next/dist/esm/server/route-modules/app-route/module.compiled\";\nimport { RouteKind } from \"next/dist/esm/server/route-kind\";\nimport { patchFetch as _patchFetch } from \"next/dist/esm/server/lib/patch-fetch\";\nimport { addRequestMeta, getRequestMeta } from \"next/dist/esm/server/request-meta\";\nimport { getTracer, SpanKind } from \"next/dist/esm/server/lib/trace/tracer\";\nimport { setManifestsSingleton } from \"next/dist/esm/server/app-render/manifests-singleton\";\nimport { normalizeAppPath } from \"next/dist/esm/shared/lib/router/utils/app-paths\";\nimport { NodeNextRequest, NodeNextResponse } from \"next/dist/esm/server/base-http/node\";\nimport { NextRequestAdapter, signalFromNodeResponse } from \"next/dist/esm/server/web/spec-extension/adapters/next-request\";\nimport { BaseServerSpan } from \"next/dist/esm/server/lib/trace/constants\";\nimport { getRevalidateReason } from \"next/dist/esm/server/instrumentation/utils\";\nimport { sendResponse } from \"next/dist/esm/server/send-response\";\nimport { fromNodeOutgoingHttpHeaders, toNodeOutgoingHttpHeaders } from \"next/dist/esm/server/web/utils\";\nimport { getCacheControlHeader } from \"next/dist/esm/server/lib/cache-control\";\nimport { INFINITE_CACHE, NEXT_CACHE_TAGS_HEADER } from \"next/dist/esm/lib/constants\";\nimport { NoFallbackError } from \"next/dist/esm/shared/lib/no-fallback-error.external\";\nimport { CachedRouteKind } from \"next/dist/esm/server/response-cache\";\nimport * as userland from \"INNER_APP_ROUTE\";\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\nconst nextConfigOutput = \"\"\nconst routeModule = new AppRouteRouteModule({\n    definition: {\n        kind: RouteKind.APP_ROUTE,\n        page: \"/api/ollama/status/route\",\n        pathname: \"/api/ollama/status\",\n        filename: \"route\",\n        bundlePath: \"\"\n    },\n    distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n    relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n    resolvedPagePath: \"[project]/Documents/Git/system-design/system-design-simulator/src/app/api/ollama/status/route.ts\",\n    nextConfigOutput,\n    userland\n});\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule;\nfunction patchFetch() {\n    return _patchFetch({\n        workAsyncStorage,\n        workUnitAsyncStorage\n    });\n}\nexport { routeModule, workAsyncStorage, workUnitAsyncStorage, serverHooks, patchFetch,  };\nexport async function handler(req, res, ctx) {\n    if (routeModule.isDev) {\n        addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint());\n    }\n    let srcPage = \"/api/ollama/status/route\";\n    // turbopack doesn't normalize `/index` in the page name\n    // so we need to to process dynamic routes properly\n    // TODO: fix turbopack providing differing value from webpack\n    if (process.env.TURBOPACK) {\n        srcPage = srcPage.replace(/\\/index$/, '') || '/';\n    } else if (srcPage === '/index') {\n        // we always normalize /index specifically\n        srcPage = '/';\n    }\n    const multiZoneDraftMode = process.env.__NEXT_MULTI_ZONE_DRAFT_MODE;\n    const prepareResult = await routeModule.prepare(req, res, {\n        srcPage,\n        multiZoneDraftMode\n    });\n    if (!prepareResult) {\n        res.statusCode = 400;\n        res.end('Bad Request');\n        ctx.waitUntil == null ? void 0 : ctx.waitUntil.call(ctx, Promise.resolve());\n        return null;\n    }\n    const { buildId, params, nextConfig, parsedUrl, isDraftMode, prerenderManifest, routerServerContext, isOnDemandRevalidate, revalidateOnlyGenerated, resolvedPathname, clientReferenceManifest, serverActionsManifest } = prepareResult;\n    const normalizedSrcPage = normalizeAppPath(srcPage);\n    let isIsr = Boolean(prerenderManifest.dynamicRoutes[normalizedSrcPage] || prerenderManifest.routes[resolvedPathname]);\n    const render404 = async ()=>{\n        // TODO: should route-module itself handle rendering the 404\n        if (routerServerContext == null ? void 0 : routerServerContext.render404) {\n            await routerServerContext.render404(req, res, parsedUrl, false);\n        } else {\n            res.end('This page could not be found');\n        }\n        return null;\n    };\n    if (isIsr && !isDraftMode) {\n        const isPrerendered = Boolean(prerenderManifest.routes[resolvedPathname]);\n        const prerenderInfo = prerenderManifest.dynamicRoutes[normalizedSrcPage];\n        if (prerenderInfo) {\n            if (prerenderInfo.fallback === false && !isPrerendered) {\n                if (nextConfig.experimental.adapterPath) {\n                    return await render404();\n                }\n                throw new NoFallbackError();\n            }\n        }\n    }\n    let cacheKey = null;\n    if (isIsr && !routeModule.isDev && !isDraftMode) {\n        cacheKey = resolvedPathname;\n        // ensure /index and / is normalized to one key\n        cacheKey = cacheKey === '/index' ? '/' : cacheKey;\n    }\n    const supportsDynamicResponse = // If we're in development, we always support dynamic HTML\n    routeModule.isDev === true || // If this is not SSG or does not have static paths, then it supports\n    // dynamic HTML.\n    !isIsr;\n    // This is a revalidation request if the request is for a static\n    // page and it is not being resumed from a postponed render and\n    // it is not a dynamic RSC request then it is a revalidation\n    // request.\n    const isStaticGeneration = isIsr && !supportsDynamicResponse;\n    // Before rendering (which initializes component tree modules), we have to\n    // set the reference manifests to our global store so Server Action's\n    // encryption util can access to them at the top level of the page module.\n    if (serverActionsManifest && clientReferenceManifest) {\n        setManifestsSingleton({\n            page: srcPage,\n            clientReferenceManifest,\n            serverActionsManifest\n        });\n    }\n    const method = req.method || 'GET';\n    const tracer = getTracer();\n    const activeSpan = tracer.getActiveScopeSpan();\n    const context = {\n        params,\n        prerenderManifest,\n        renderOpts: {\n            experimental: {\n                authInterrupts: Boolean(nextConfig.experimental.authInterrupts)\n            },\n            cacheComponents: Boolean(nextConfig.cacheComponents),\n            supportsDynamicResponse,\n            incrementalCache: getRequestMeta(req, 'incrementalCache'),\n            cacheLifeProfiles: nextConfig.cacheLife,\n            waitUntil: ctx.waitUntil,\n            onClose: (cb)=>{\n                res.on('close', cb);\n            },\n            onAfterTaskError: undefined,\n            onInstrumentationRequestError: (error, _request, errorContext, silenceLog)=>routeModule.onRequestError(req, error, errorContext, silenceLog, routerServerContext)\n        },\n        sharedContext: {\n            buildId\n        }\n    };\n    const nodeNextReq = new NodeNextRequest(req);\n    const nodeNextRes = new NodeNextResponse(res);\n    const nextReq = NextRequestAdapter.fromNodeNextRequest(nodeNextReq, signalFromNodeResponse(res));\n    try {\n        const invokeRouteModule = async (span)=>{\n            return routeModule.handle(nextReq, context).finally(()=>{\n                if (!span) return;\n                span.setAttributes({\n                    'http.status_code': res.statusCode,\n                    'next.rsc': false\n                });\n                const rootSpanAttributes = tracer.getRootSpanAttributes();\n                // We were unable to get attributes, probably OTEL is not enabled\n                if (!rootSpanAttributes) {\n                    return;\n                }\n                if (rootSpanAttributes.get('next.span_type') !== BaseServerSpan.handleRequest) {\n                    console.warn(`Unexpected root span type '${rootSpanAttributes.get('next.span_type')}'. Please report this Next.js issue https://github.com/vercel/next.js`);\n                    return;\n                }\n                const route = rootSpanAttributes.get('next.route');\n                if (route) {\n                    const name = `${method} ${route}`;\n                    span.setAttributes({\n                        'next.route': route,\n                        'http.route': route,\n                        'next.span_name': name\n                    });\n                    span.updateName(name);\n                } else {\n                    span.updateName(`${method} ${srcPage}`);\n                }\n            });\n        };\n        const isMinimalMode = Boolean(process.env.MINIMAL_MODE || getRequestMeta(req, 'minimalMode'));\n        const handleResponse = async (currentSpan)=>{\n            var _cacheEntry_value;\n            const responseGenerator = async ({ previousCacheEntry })=>{\n                try {\n                    if (!isMinimalMode && isOnDemandRevalidate && revalidateOnlyGenerated && !previousCacheEntry) {\n                        res.statusCode = 404;\n                        // on-demand revalidate always sets this header\n                        res.setHeader('x-nextjs-cache', 'REVALIDATED');\n                        res.end('This page could not be found');\n                        return null;\n                    }\n                    const response = await invokeRouteModule(currentSpan);\n                    req.fetchMetrics = context.renderOpts.fetchMetrics;\n                    let pendingWaitUntil = context.renderOpts.pendingWaitUntil;\n                    // Attempt using provided waitUntil if available\n                    // if it's not we fallback to sendResponse's handling\n                    if (pendingWaitUntil) {\n                        if (ctx.waitUntil) {\n                            ctx.waitUntil(pendingWaitUntil);\n                            pendingWaitUntil = undefined;\n                        }\n                    }\n                    const cacheTags = context.renderOpts.collectedTags;\n                    // If the request is for a static response, we can cache it so long\n                    // as it's not edge.\n                    if (isIsr) {\n                        const blob = await response.blob();\n                        // Copy the headers from the response.\n                        const headers = toNodeOutgoingHttpHeaders(response.headers);\n                        if (cacheTags) {\n                            headers[NEXT_CACHE_TAGS_HEADER] = cacheTags;\n                        }\n                        if (!headers['content-type'] && blob.type) {\n                            headers['content-type'] = blob.type;\n                        }\n                        const revalidate = typeof context.renderOpts.collectedRevalidate === 'undefined' || context.renderOpts.collectedRevalidate >= INFINITE_CACHE ? false : context.renderOpts.collectedRevalidate;\n                        const expire = typeof context.renderOpts.collectedExpire === 'undefined' || context.renderOpts.collectedExpire >= INFINITE_CACHE ? undefined : context.renderOpts.collectedExpire;\n                        // Create the cache entry for the response.\n                        const cacheEntry = {\n                            value: {\n                                kind: CachedRouteKind.APP_ROUTE,\n                                status: response.status,\n                                body: Buffer.from(await blob.arrayBuffer()),\n                                headers\n                            },\n                            cacheControl: {\n                                revalidate,\n                                expire\n                            }\n                        };\n                        return cacheEntry;\n                    } else {\n                        // send response without caching if not ISR\n                        await sendResponse(nodeNextReq, nodeNextRes, response, context.renderOpts.pendingWaitUntil);\n                        return null;\n                    }\n                } catch (err) {\n                    // if this is a background revalidate we need to report\n                    // the request error here as it won't be bubbled\n                    if (previousCacheEntry == null ? void 0 : previousCacheEntry.isStale) {\n                        const silenceLog = false;\n                        await routeModule.onRequestError(req, err, {\n                            routerKind: 'App Router',\n                            routePath: srcPage,\n                            routeType: 'route',\n                            revalidateReason: getRevalidateReason({\n                                isStaticGeneration,\n                                isOnDemandRevalidate\n                            })\n                        }, silenceLog, routerServerContext);\n                    }\n                    throw err;\n                }\n            };\n            const cacheEntry = await routeModule.handleResponse({\n                req,\n                nextConfig,\n                cacheKey,\n                routeKind: RouteKind.APP_ROUTE,\n                isFallback: false,\n                prerenderManifest,\n                isRoutePPREnabled: false,\n                isOnDemandRevalidate,\n                revalidateOnlyGenerated,\n                responseGenerator,\n                waitUntil: ctx.waitUntil,\n                isMinimalMode\n            });\n            // we don't create a cacheEntry for ISR\n            if (!isIsr) {\n                return null;\n            }\n            if ((cacheEntry == null ? void 0 : (_cacheEntry_value = cacheEntry.value) == null ? void 0 : _cacheEntry_value.kind) !== CachedRouteKind.APP_ROUTE) {\n                var _cacheEntry_value1;\n                throw Object.defineProperty(new Error(`Invariant: app-route received invalid cache entry ${cacheEntry == null ? void 0 : (_cacheEntry_value1 = cacheEntry.value) == null ? void 0 : _cacheEntry_value1.kind}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E701\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            if (!isMinimalMode) {\n                res.setHeader('x-nextjs-cache', isOnDemandRevalidate ? 'REVALIDATED' : cacheEntry.isMiss ? 'MISS' : cacheEntry.isStale ? 'STALE' : 'HIT');\n            }\n            // Draft mode should never be cached\n            if (isDraftMode) {\n                res.setHeader('Cache-Control', 'private, no-cache, no-store, max-age=0, must-revalidate');\n            }\n            const headers = fromNodeOutgoingHttpHeaders(cacheEntry.value.headers);\n            if (!(isMinimalMode && isIsr)) {\n                headers.delete(NEXT_CACHE_TAGS_HEADER);\n            }\n            // If cache control is already set on the response we don't\n            // override it to allow users to customize it via next.config\n            if (cacheEntry.cacheControl && !res.getHeader('Cache-Control') && !headers.get('Cache-Control')) {\n                headers.set('Cache-Control', getCacheControlHeader(cacheEntry.cacheControl));\n            }\n            await sendResponse(nodeNextReq, nodeNextRes, // @ts-expect-error - Argument of type 'Buffer<ArrayBufferLike>' is not assignable to parameter of type 'BodyInit | null | undefined'.\n            new Response(cacheEntry.value.body, {\n                headers,\n                status: cacheEntry.value.status || 200\n            }));\n            return null;\n        };\n        // TODO: activeSpan code path is for when wrapped by\n        // next-server can be removed when this is no longer used\n        if (activeSpan) {\n            await handleResponse(activeSpan);\n        } else {\n            await tracer.withPropagatedContext(req.headers, ()=>tracer.trace(BaseServerSpan.handleRequest, {\n                    spanName: `${method} ${srcPage}`,\n                    kind: SpanKind.SERVER,\n                    attributes: {\n                        'http.method': method,\n                        'http.target': req.url\n                    }\n                }, handleResponse));\n        }\n    } catch (err) {\n        if (!(err instanceof NoFallbackError)) {\n            const silenceLog = false;\n            await routeModule.onRequestError(req, err, {\n                routerKind: 'App Router',\n                routePath: normalizedSrcPage,\n                routeType: 'route',\n                revalidateReason: getRevalidateReason({\n                    isStaticGeneration,\n                    isOnDemandRevalidate\n                })\n            }, silenceLog, routerServerContext);\n        }\n        // rethrow so that we can handle serving error page\n        // If this is during static generation, throw the error again.\n        if (isIsr) throw err;\n        // Otherwise, send a 500 response.\n        await sendResponse(nodeNextReq, nodeNextRes, new Response(null, {\n            status: 500\n        }));\n        return null;\n    }\n}\n\n//# sourceMappingURL=app-route.js.map\n"],"names":[],"mappings":"m/BAeA,IAAM,EAAkB,QAAQ,GAAG,CAAC,eAAe,EAAI,yBACjD,EAAe,QAAQ,GAAG,CAAC,YAAY,EAAI,YAiD1C,eAAe,IACpB,GAAI,CAIF,MAAO,CAHU,MAAM,MAAM,CAAA,EAAG,EAAgB,SAAS,CAAC,CAAE,CAC1D,OAAQ,KACV,EAAA,EACgB,EAAE,AACpB,CAAE,KAAM,CACN,OAAO,CACT,CACF,CAmBO,eAAe,IACpB,GAAI,CACF,IAAM,EAAW,MAAM,MAAM,CAAA,EAAG,EAAgB,SAAS,CAAC,EAC1D,GAAI,CAAC,EAAS,EAAE,CAAE,MAAO,EAAE,CAC3B,IAAM,EAAO,MAAM,EAAS,IAAI,GAChC,OAAO,EAAK,MAAM,EAAE,IAAI,AAAC,GAAwB,EAAE,IAAI,GAAK,EAAE,AAChE,CAAE,KAAM,CACN,MAAO,EAAE,AACX,CACF,CAKO,eAAe,EACpB,CAAgC,EAEhC,GAAM,OAAE,EAAQ,CAAY,UAAE,CAAQ,aAAE,EAAc,EAAG,CAAE,CAAG,EAExD,EAAW,MAAM,MAAM,CAAA,EAAG,EAAgB,SAAS,CAAC,CAAE,CAC1D,OAAQ,OACR,QAAS,CACP,eAAgB,kBAClB,EACA,KAAM,KAAK,SAAS,CAAC,OACnB,WACA,EACA,QAAQ,EACR,QAAS,aACP,EACA,YAAa,EAAQ,UAAU,EAAI,IACnC,MAAO,EAAQ,KAAK,EAAI,GACxB,KAAM,EAAQ,IAAI,AACpB,CACF,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,cAAc,EAAE,EAAA,CAAO,CAC1C,CAEA,OAAO,EAAS,IAAI,EACtB,CAvH0B,QAAQ,GAAG,CAAC,iBAAiB,IAAI,4FEjB3D,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,MACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,MACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OAAA,IAAA,EAAA,EAAA,CAAA,CAAA,ODLA,EAAA,EAAA,CAAA,CAAA,MACA,EAAA,EAAA,CAAA,CAAA,OAEO,eAAe,IACpB,GAAI,CAGF,GAAI,CAFc,AAEb,MAFmB,CAAA,EAAA,EAER,AAFQ,iBAAA,AAAiB,IAGvC,OAAO,EAAA,YAAY,CAAC,IAAI,CAAC,CACvB,OAAQ,UACR,QAAS,qDACT,OAAQ,EAAE,CACV,YAAa,CACX,QAAQ,EACR,UAAW,EACb,CACF,GAGF,IAAM,EAAS,MAAM,CAAA,EAAA,EAAA,UAAA,AAAU,IAGzB,EAAY,EAAO,IAAI,CAC3B,AAAC,GAAM,EAAE,QAAQ,CAAC,WAAa,EAAE,QAAQ,CAAC,cAEtC,EAAe,EAAO,IAAI,CAC9B,AAAC,GAAM,EAAE,QAAQ,CAAC,cAAgB,EAAE,QAAQ,CAAC,eAIzC,EAA0B,EAAE,AAC9B,CAAC,GAAW,EAAc,IAAI,CAAC,UAC/B,AAAC,GAAc,EAAc,IAAI,CAAC,gBAEtC,IAAI,EAAU,oBAOd,OANI,EAAc,MAAM,CAAG,EACzB,CAD4B,EACjB,CAAC,kBAAkB,EAAE,EAAc,IAAI,CAAC,MAAM,gBAAgB,EAAE,EAAc,GAAG,CAAC,GAAK,CAAC,YAAY,EAAE,EAAA,CAAG,EAAE,IAAI,CAAC,QAAA,CAAS,CAEpI,GAAW,0EAGN,EAAA,YAAY,CAAC,IAAI,CAAC,CACvB,OAAQ,iBACR,EACA,SACA,YAAa,CACX,OAAQ,EACR,UAAW,CACb,EAEA,iBAAkB,SAClB,oBAAqB,EAErB,UAAW,eACX,aAAc,CAChB,EACF,CAAE,MAAO,EAAO,CAEd,OADA,QAAQ,KAAK,CAAC,6BAA8B,GACrC,EAAA,YAAY,CAAC,IAAI,CACtB,CACE,OAAQ,QACR,QAAS,gCACT,OAAQ,EAAE,CACV,YAAa,CACX,QAAQ,EACR,WAAW,CACb,CACF,EACA,CAAE,OAAQ,GAAI,EAElB,CACF,0BCjEA,IAAA,EAAA,EAAA,CAAA,CAAA,OAIA,IAAM,EAAc,IAAI,EAAA,mBAAmB,CAAC,CACxC,WAAY,CACR,KAAM,EAAA,SAAS,CAAC,SAAS,CACzB,KAAM,2BACN,SAAU,qBACV,SAAU,QACV,WAAY,EAChB,EACA,QAAS,CAAA,OACT,IADiD,eACc,CAA3C,EACpB,iBAAkB,mGAClB,iBAZqB,GAarB,SAAA,CACJ,GAIM,kBAAE,CAAgB,sBAAE,CAAoB,aAAE,CAAW,CAAE,CAAG,EAChE,SAAS,IACL,MAAO,CAAA,EAAA,EAAA,UAAA,AAAW,EAAC,kBACf,uBACA,CACJ,EACJ,CAEO,eAAe,EAAQ,CAAG,CAAE,CAAG,CAAE,CAAG,EACnC,EAAY,KAAK,EAAE,AACnB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,+BAAgC,QAAQ,MAAM,CAAC,MAAM,IAE7E,IAAI,EAAU,2BAKV,EAAU,EAAQ,OAAO,CAAC,WAAY,KAAO,IAMjD,IAAM,EAAgB,MAAM,EAAY,OAAO,CAAC,EAAK,EAAK,SACtD,EACA,mBAHE,CAAA,CAIN,GACA,GAAI,CAAC,EAID,OAHA,EAAI,IADY,MACF,CAAG,IACjB,EAAI,GAAG,CAAC,eACR,AAAiB,OAAO,CAApB,IAAyB,KAAhB,EAAoB,EAAI,SAAS,CAAC,IAAI,CAAC,EAAK,QAAQ,OAAO,IACjE,KAEX,GAAM,SAAE,CAAO,QAAE,CAAM,YAAE,CAAU,WAAE,CAAS,CAAE,aAAW,CAAE,mBAAiB,qBAAE,CAAmB,sBAAE,CAAoB,yBAAE,CAAuB,kBAAE,CAAgB,yBAAE,CAAuB,uBAAE,CAAqB,CAAE,CAAG,EACnN,EAAoB,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,GACvC,GAAQ,EAAQ,EAAkB,aAAa,CAAC,EAAkB,EAAI,EAAkB,MAAM,CAAC,EAAA,AAAiB,EAC9G,EAAY,WAEV,AAAuB,QAAO,KAAK,EAAI,EAAoB,SAAA,AAAS,EAAE,AACtE,MAAM,EAAoB,SAAS,CAAC,EAAK,EAAK,GAAW,GAEzD,EAAI,GAAG,CAAC,gCAEL,MAEX,GAAI,GAAS,CAAC,EAAa,CACvB,IAAM,EAAgB,EAAQ,EAAkB,MAAM,CAAC,EAAiB,CAClE,EAAgB,EAAkB,aAAa,CAAC,EAAkB,CACxE,GAAI,IAC+B,IAA3B,EAAc,KADH,GACW,EAAc,CAAC,EAAe,CACpD,GAAI,EAAW,YAAY,CAAC,WAAW,CACnC,CADqC,MAC9B,MAAM,GAEjB,OAAM,IAAI,EAAA,eACd,AAD6B,CAGrC,CACA,IAAI,EAAW,MACX,GAAU,EAAY,IAAb,CAAkB,EAAK,EAAD,EAG/B,EAAW,AAAa,OAHqB,KAC7C,EAAW,CAAA,EAEwB,IAAM,CAAA,EAE7C,IAAM,EACN,CAAsB,MAAV,EAAkB,GAAb,EAEjB,CAAC,EAKK,EAAqB,GAAS,CAAC,EAIjC,GAAyB,GACzB,CAAA,EAAA,EAAA,iBADkD,IAClD,AAAqB,EAAC,CAClB,KAAM,aAbqF,aAc3F,wBACA,CACJ,GAEJ,IAAM,EAAS,EAAI,MAAM,EAAI,MACvB,EAAS,CAAA,EAAA,EAAA,SAAA,AAAS,IAClB,EAAa,EAAO,kBAAkB,GACtC,EAAU,CACZ,SACA,oBACA,WAAY,CACR,aAAc,CACV,gBAAgB,CAAQ,EAAW,YAAY,CAAC,cAAc,AAClE,EACA,iBAAiB,CAAQ,EAAW,eAAe,yBACnD,EACA,iBAAkB,CAAA,EAAA,EAAA,cAAc,AAAd,EAAe,EAAK,oBACtC,kBAAmB,EAAW,SAAS,CACvC,UAAW,EAAI,SAAS,CACxB,QAAS,AAAC,IACN,EAAI,EAAE,CAAC,QAAS,EACpB,EACA,sBAAkB,EAClB,8BAA+B,CAAC,EAAO,EAAU,EAAc,IAAa,EAAY,cAAc,CAAC,EAAK,EAAO,EAAc,EAAY,EACjJ,EACA,cAAe,SACX,CACJ,CACJ,EACM,EAAc,IAAI,EAAA,eAAe,CAAC,GAClC,EAAc,IAAI,EAAA,gBAAgB,CAAC,GACnC,EAAU,EAAA,kBAAkB,CAAC,mBAAmB,CAAC,EAAa,CAAA,EAAA,EAAA,sBAAA,AAAsB,EAAC,IAC3F,GAAI,CACA,IAAM,EAAoB,MAAO,GACtB,EAAY,MAAM,CAAC,EAAS,GAAS,OAAO,CAAC,KAChD,GAAI,CAAC,EAAM,OACX,EAAK,aAAa,CAAC,CACf,mBAAoB,EAAI,UAAU,CAClC,YAAY,CAChB,GACA,IAAM,EAAqB,EAAO,qBAAqB,GAEvD,GAAI,CAAC,EACD,OAEJ,GAAI,EAAmB,GAAG,CAAC,EAHF,kBAGwB,EAAA,cAAc,CAAC,aAAa,CAAE,YAC3E,QAAQ,IAAI,CAAC,CAAC,2BAA2B,EAAE,EAAmB,GAAG,CAAC,kBAAkB,qEAAqE,CAAC,EAG9J,IAAM,EAAQ,EAAmB,GAAG,CAAC,cACrC,GAAI,EAAO,CACP,IAAM,EAAO,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAO,CACjC,EAAK,aAAa,CAAC,CACf,aAAc,EACd,aAAc,EACd,iBAAkB,CACtB,GACA,EAAK,UAAU,CAAC,EACpB,MACI,CADG,CACE,UAAU,CAAC,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAE9C,GAEE,GAAgB,CAAoC,CAAA,EAAA,EAAA,EAA5B,YAA0C,AAAd,EAAe,EAAK,eACxE,EAAiB,MAAO,QACtB,EA4FI,EA3FR,IAAM,EAAoB,MAAO,oBAAE,CAAkB,CAAE,IACnD,GAAI,CACA,GAAI,CAAC,GAAiB,GAAwB,GAA2B,CAAC,EAKtE,OAJA,EAAI,SADsF,CAC5E,CAAG,IAEjB,EAAI,SAAS,CAAC,iBAAkB,eAChC,EAAI,GAAG,CAAC,gCACD,KAEX,IAAM,EAAW,MAAM,EAAkB,EACzC,GAAI,YAAY,CAAG,EAAQ,UAAU,CAAC,YAAY,CAClD,IAAI,EAAmB,EAAQ,UAAU,CAAC,gBAAgB,CAGtD,GACI,EAAI,SAAS,EAAE,CACf,CAFc,CAEV,SAAS,CAAC,GACd,OAAmB,GAG3B,IAAM,EAAY,EAAQ,UAAU,CAAC,aAAa,CAGlD,IAAI,EA6BA,OADA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,EAAU,EAAQ,UAAU,CAAC,gBAAgB,EACnF,IA7BA,EACP,IAAM,EAAO,MAAM,EAAS,IAAI,GAE1B,EAAU,CAAA,EAAA,EAAA,yBAAA,AAAyB,EAAC,EAAS,OAAO,EACtD,IACA,CAAO,CAAC,EAAA,GADG,mBACmB,CAAC,CAAG,CAAA,EAElC,CAAC,CAAO,CAAC,eAAe,EAAI,EAAK,IAAI,EAAE,CACvC,CAAO,CAAC,eAAe,CAAG,EAAK,IAAA,AAAI,EAEvC,IAAM,EAAa,KAAkD,IAA3C,EAAQ,UAAU,CAAC,mBAAmB,IAAoB,EAAQ,UAAU,CAAC,mBAAmB,EAAI,EAAA,cAAA,AAAc,GAAG,AAAQ,EAAQ,UAAU,CAAC,mBAAmB,CACvL,EAAS,KAA8C,IAAvC,EAAQ,UAAU,CAAC,eAAe,EAAoB,EAAQ,UAAU,CAAC,eAAe,EAAI,EAAA,cAAc,MAAG,EAAY,EAAQ,UAAU,CAAC,eAAe,CAcjL,MAZmB,CAYZ,AAXH,MAAO,CACH,KAAM,EAAA,eAAe,CAAC,SAAS,CAC/B,OAAQ,EAAS,MAAM,CACvB,KAAM,OAAO,IAAI,CAAC,MAAM,EAAK,WAAW,YACxC,CACJ,EACA,aAAc,YACV,SACA,CACJ,CACJ,CAEJ,CAKJ,CAAE,KALS,CAKF,EAAK,CAeV,MAZ0B,MAAtB,EAA6B,KAAK,EAAI,EAAmB,OAAA,AAAO,EAAE,CAElE,MAAM,EAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAmB,AAAnB,EAAoB,oBAClC,uBACA,CACJ,EACJ,GAAG,AATgB,EASJ,GAEb,CACV,CACJ,EACM,EAAa,MAAM,EAAY,cAAc,CAAC,KAChD,EACA,sBACA,EACA,UAAW,EAAA,SAAS,CAAC,SAAS,CAC9B,YAAY,oBACZ,EACA,mBAAmB,uBACnB,0BACA,oBACA,EACA,UAAW,EAAI,SAAS,eACxB,CACJ,GAEA,GAAI,CAAC,EACD,KADQ,EACD,KAEX,GAAI,CAAe,MAAd,CAAqB,EAAS,AAA0C,GAA9C,GAAK,GAAoB,EAAW,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,IAAM,EAAA,eAAe,CAAC,SAAS,CAE9I,CAFgJ,KAE1I,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,kDAAkD,EAAgB,MAAd,CAAqB,EAAS,AAA2C,GAA/C,IAAK,EAAqB,EAAW,KAAA,AAAK,EAAY,KAAK,EAAI,EAAmB,IAAI,CAAA,CAAE,EAAG,oBAAqB,CACjO,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAEA,CAAC,GACD,EAAI,SAAS,CADG,AACF,iBAAkB,EAAuB,cAAgB,EAAW,MAAM,CAAG,OAAS,EAAW,OAAO,CAAG,QAAU,OAGnI,GACA,EAAI,QADS,CACA,CAAC,gBAAiB,2DAEnC,IAAM,EAAU,CAAA,EAAA,EAAA,2BAAA,AAA2B,EAAC,EAAW,KAAK,CAAC,OAAO,EAcpE,OAbI,AAAE,CAAD,EAAkB,GACnB,EADwB,AAChB,GADmB,GACb,CAAC,EAAA,sBAAsB,GAIrC,EAAW,YAAY,EAAK,EAAD,AAAK,SAAS,CAAC,kBAAqB,EAAD,AAAS,GAAG,CAAC,kBAAkB,AAC7F,EAAQ,GAAG,CAAC,gBAAiB,CAAA,EAAA,EAAA,qBAAA,AAAqB,EAAC,EAAW,YAAY,GAE9E,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAChC,IAAI,SAAS,EAAW,KAAK,CAAC,IAAI,CAAE,SAChC,EACA,OAAQ,EAAW,KAAK,CAAC,MAAM,EAAI,GACvC,IACO,IACX,EAGI,EACA,MAAM,EAAe,EADT,CAGZ,MAAM,EAAO,qBAAqB,CAAC,EAAI,OAAO,CAAE,IAAI,EAAO,KAAK,CAAC,EAAA,cAAc,CAAC,aAAa,CAAE,CACvF,SAAU,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAChC,KAAM,EAAA,QAAQ,CAAC,MAAM,CACrB,WAAY,CACR,cAAe,EACf,cAAe,EAAI,GAAG,AAC1B,CACJ,EAAG,GAEf,CAAE,MAAO,EAAK,CAeV,GAdM,aAAe,EAAA,eAAe,EAEhC,CAFmC,KAE7B,EAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,oBAClC,uBACA,CACJ,EACJ,GAAG,AATgB,EASJ,GAIf,EAAO,MAAM,EAKjB,OAHA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,IAAI,SAAS,KAAM,CAC5D,OAAQ,GACZ,IACO,IACX,CACJ,EAEA,qCAAqC","ignoreList":[2]}