{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 70, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/internal/class.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n * WARNING: This is an internal file that is subject to change!\n *\n * ðŸ›‘ Under no circumstances should you import this file directly! ðŸ›‘\n *\n * Please import the `PrismaClient` class from the `client.ts` file instead.\n */\n\nimport * as runtime from \"@prisma/client/runtime/client\"\nimport type * as Prisma from \"./prismaNamespace\"\n\n\nconst config: runtime.GetPrismaClientConfig = {\n  \"previewFeatures\": [],\n  \"clientVersion\": \"7.3.0\",\n  \"engineVersion\": \"9d6ad21cbbceab97458517b147a6a09ff43aa735\",\n  \"activeProvider\": \"sqlite\",\n  \"inlineSchema\": \"// Prisma schema for AI System Design Simulator\\ngenerator client {\\n  provider = \\\"prisma-client\\\"\\n  output   = \\\"../src/generated/prisma\\\"\\n}\\n\\ndatasource db {\\n  provider = \\\"sqlite\\\"\\n}\\n\\nmodel User {\\n  id        String   @id @default(cuid())\\n  email     String   @unique\\n  password  String\\n  name      String?\\n  avatar    String?\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n\\n  profile          Profile?\\n  resumes          Resume[]\\n  interviews       Interview[]\\n  analytics        UserAnalytics?\\n  codingChallenges CodingChallenge[]\\n  codingTests      CodingTest[]\\n}\\n\\nmodel Profile {\\n  id     String @id @default(cuid())\\n  userId String @unique\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  bio             String?\\n  yearsExperience Int?\\n  skills          String  @default(\\\"[]\\\") // JSON array stored as string\\n  targetCompanies String  @default(\\\"[]\\\") // JSON array stored as string\\n  targetRole      String?\\n\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n}\\n\\nmodel Resume {\\n  id     String @id @default(cuid())\\n  userId String\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  fileName String\\n  content  String // Full text content of resume\\n  analysis String? // JSON object with AI analysis\\n  filePath String? // Local path to the stored resume file\\n\\n  // ATS Score Data\\n  atsScore       Int? // Total ATS score (0-100)\\n  atsBreakdown   String? // JSON: { contactInfo, structure, experience, keywords, impact }\\n  atsFeedback    String? // JSON array of feedback strings\\n  keywords       String? // JSON array of extracted keywords\\n  softSkills     String? // JSON array of soft skills\\n  predictedRoles String? // JSON array of predicted job roles\\n\\n  uploadedAt DateTime @default(now())\\n  updatedAt  DateTime @updatedAt\\n}\\n\\nmodel Interview {\\n  id     String @id @default(cuid())\\n  userId String\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  topic      String // e.g., \\\"Design Twitter\\\", \\\"Design Uber\\\"\\n  difficulty String @default(\\\"medium\\\") // easy, medium, hard\\n  status     String @default(\\\"pending\\\") // pending, in_progress, completed\\n\\n  startedAt DateTime?\\n  endedAt   DateTime?\\n  createdAt DateTime  @default(now())\\n\\n  // Time tracking for phases\\n  phaseDurations   String? // JSON: { requirements: 480, highLevel: 720 } in seconds\\n  phaseTransitions String? // JSON: [{ phase: \\\"requirements\\\", startedAt: ISO, endedAt: ISO }]\\n\\n  messages Message[]\\n  score    Score?\\n\\n  @@index([userId, status, endedAt])\\n}\\n\\nmodel Message {\\n  id          String    @id @default(cuid())\\n  interviewId String\\n  interview   Interview @relation(fields: [interviewId], references: [id], onDelete: Cascade)\\n\\n  role    String // user, assistant, system\\n  content String\\n\\n  timestamp DateTime @default(now())\\n}\\n\\nmodel Score {\\n  id          String    @id @default(cuid())\\n  interviewId String    @unique\\n  interview   Interview @relation(fields: [interviewId], references: [id], onDelete: Cascade)\\n\\n  // 6 Industry-Standard FAANG Evaluation Dimensions (1-4 scale)\\n  requirementsClarification Int @default(0)\\n  highLevelDesign           Int @default(0)\\n  detailedDesign            Int @default(0)\\n  scalability               Int @default(0)\\n  tradeoffs                 Int @default(0)\\n  communication             Int @default(0)\\n\\n  // Calculated fields\\n  overallScore Float   @default(0) // Weighted average\\n  passStatus   Boolean @default(false)\\n\\n  // Detailed feedback as JSON\\n  feedback String @default(\\\"{}\\\") // JSON with per-dimension comments\\n\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n}\\n\\n// Cached analytics for user performance tracking\\nmodel UserAnalytics {\\n  id     String @id @default(cuid())\\n  userId String @unique\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  // Cached aggregates (updated after each interview)\\n  totalInterviews     Int    @default(0)\\n  completedInterviews Int    @default(0)\\n  avgOverallScore     Float?\\n  passRate            Float?\\n\\n  // Weak/strong areas tracking\\n  weakDimensions   String @default(\\\"[]\\\") // JSON array: [\\\"scalability\\\", \\\"tradeoffs\\\"]\\n  strongDimensions String @default(\\\"[]\\\") // JSON array: [\\\"communication\\\", \\\"requirements\\\"]\\n\\n  // Topic performance\\n  topicStats String @default(\\\"{}\\\") // JSON: { \\\"Design Twitter\\\": { count: 5, avgScore: 2.8 } }\\n\\n  // Trend data\\n  scoreTrend       String   @default(\\\"stable\\\") // \\\"improving\\\" | \\\"stable\\\" | \\\"declining\\\"\\n  lastCalculatedAt DateTime @default(now())\\n\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n}\\n\\n// ==================== CODING CHALLENGE MODELS ====================\\n\\n// Predefined problem bank\\nmodel CodingProblem {\\n  id                 String            @id @default(cuid())\\n  title              String\\n  description        String\\n  difficulty         String // easy, medium, hard\\n  category           String // arrays, strings, dp, graphs, trees, etc.\\n  companies          String            @default(\\\"[]\\\") // JSON array of company names\\n  constraints        String            @default(\\\"[]\\\") // JSON array\\n  examples           String            @default(\\\"[]\\\") // JSON [{input, output, explanation}]\\n  testCases          String            @default(\\\"[]\\\") // JSON [{input, expectedOutput, isHidden}]\\n  solutionApproaches String            @default(\\\"[]\\\") // JSON array\\n  starterCode        String            @default(\\\"{}\\\") // JSON {python: \\\"...\\\", java: \\\"...\\\"}\\n  timeLimit          Int               @default(45) // minutes\\n  createdAt          DateTime          @default(now())\\n  updatedAt          DateTime          @updatedAt\\n  challenges         CodingChallenge[]\\n\\n  @@index([difficulty, category])\\n}\\n\\n// User's coding challenge instance\\nmodel CodingChallenge {\\n  id           String                @id @default(cuid())\\n  userId       String\\n  user         User                  @relation(fields: [userId], references: [id], onDelete: Cascade)\\n  problemId    String?\\n  problem      CodingProblem?        @relation(fields: [problemId], references: [id])\\n  testId       String?\\n  test         CodingTest?           @relation(fields: [testId], references: [id], onDelete: Cascade)\\n  title        String\\n  description  String\\n  difficulty   String\\n  category     String\\n  company      String?\\n  language     String // python, java, javascript, cpp, c, csharp, go\\n  visibleTests String                @default(\\\"[]\\\")\\n  hiddenTests  String                @default(\\\"[]\\\")\\n  timeLimit    Int                   @default(45)\\n  status       String                @default(\\\"pending\\\") // pending, in_progress, completed\\n  startedAt    DateTime?\\n  endedAt      DateTime?\\n  starterCode  String?\\n  finalCode    String?\\n  createdAt    DateTime              @default(now())\\n  updatedAt    DateTime              @updatedAt\\n  submissions  ChallengeSubmission[]\\n  score        ChallengeScore?\\n\\n  @@index([userId, status])\\n}\\n\\n// Code submission for evaluation\\nmodel ChallengeSubmission {\\n  id           String          @id @default(cuid())\\n  challengeId  String\\n  challenge    CodingChallenge @relation(fields: [challengeId], references: [id], onDelete: Cascade)\\n  code         String\\n  language     String\\n  submittedAt  DateTime        @default(now())\\n  evaluation   String?\\n  testResults  String?\\n  isValid      Boolean         @default(false)\\n  errorMessage String?\\n\\n  @@index([challengeId])\\n}\\n\\n// Final score for coding challenge\\nmodel ChallengeScore {\\n  id                 String          @id @default(cuid())\\n  challengeId        String          @unique\\n  challenge          CodingChallenge @relation(fields: [challengeId], references: [id], onDelete: Cascade)\\n  correctness        Float\\n  efficiency         Float\\n  codeQuality        Float\\n  edgeCases          Float\\n  overallScore       Float\\n  passStatus         Boolean\\n  feedback           String\\n  suggestedApproach  String?\\n  complexityAnalysis String?\\n  createdAt          DateTime        @default(now())\\n}\\n\\n// ==================== CODING TEST MODELS ====================\\n\\nmodel CodingTest {\\n  id         String            @id @default(cuid())\\n  userId     String\\n  user       User              @relation(fields: [userId], references: [id], onDelete: Cascade)\\n  challenges CodingChallenge[]\\n  status     String            @default(\\\"pending\\\") // pending, in_progress, completed\\n  startedAt  DateTime?\\n  endedAt    DateTime?\\n  timeLimit  Int // Total minutes for all questions\\n  createdAt  DateTime          @default(now())\\n  updatedAt  DateTime          @updatedAt\\n}\\n\",\n  \"runtimeDataModel\": {\n    \"models\": {},\n    \"enums\": {},\n    \"types\": {}\n  }\n}\n\nconfig.runtimeDataModel = JSON.parse(\"{\\\"models\\\":{\\\"User\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"email\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"password\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"name\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"avatar\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"profile\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Profile\\\",\\\"relationName\\\":\\\"ProfileToUser\\\"},{\\\"name\\\":\\\"resumes\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Resume\\\",\\\"relationName\\\":\\\"ResumeToUser\\\"},{\\\"name\\\":\\\"interviews\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Interview\\\",\\\"relationName\\\":\\\"InterviewToUser\\\"},{\\\"name\\\":\\\"analytics\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"UserAnalytics\\\",\\\"relationName\\\":\\\"UserToUserAnalytics\\\"},{\\\"name\\\":\\\"codingChallenges\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingChallenge\\\",\\\"relationName\\\":\\\"CodingChallengeToUser\\\"},{\\\"name\\\":\\\"codingTests\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingTest\\\",\\\"relationName\\\":\\\"CodingTestToUser\\\"}],\\\"dbName\\\":null},\\\"Profile\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"ProfileToUser\\\"},{\\\"name\\\":\\\"bio\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"yearsExperience\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"skills\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"targetCompanies\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"targetRole\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"Resume\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"ResumeToUser\\\"},{\\\"name\\\":\\\"fileName\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"content\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"analysis\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"filePath\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"atsScore\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"atsBreakdown\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"atsFeedback\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"keywords\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"softSkills\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"predictedRoles\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"uploadedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"Interview\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"InterviewToUser\\\"},{\\\"name\\\":\\\"topic\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"difficulty\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"status\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"startedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"endedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"phaseDurations\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"phaseTransitions\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"messages\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Message\\\",\\\"relationName\\\":\\\"InterviewToMessage\\\"},{\\\"name\\\":\\\"score\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Score\\\",\\\"relationName\\\":\\\"InterviewToScore\\\"}],\\\"dbName\\\":null},\\\"Message\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interviewId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interview\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Interview\\\",\\\"relationName\\\":\\\"InterviewToMessage\\\"},{\\\"name\\\":\\\"role\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"content\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"timestamp\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"Score\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interviewId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interview\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Interview\\\",\\\"relationName\\\":\\\"InterviewToScore\\\"},{\\\"name\\\":\\\"requirementsClarification\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"highLevelDesign\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"detailedDesign\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"scalability\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"tradeoffs\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"communication\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"overallScore\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"passStatus\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Boolean\\\"},{\\\"name\\\":\\\"feedback\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"UserAnalytics\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"UserToUserAnalytics\\\"},{\\\"name\\\":\\\"totalInterviews\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"completedInterviews\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"avgOverallScore\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"passRate\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"weakDimensions\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"strongDimensions\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"topicStats\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"scoreTrend\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"lastCalculatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"CodingProblem\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"title\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"description\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"difficulty\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"category\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"companies\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"constraints\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"examples\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"testCases\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"solutionApproaches\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"starterCode\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"timeLimit\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"challenges\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingChallenge\\\",\\\"relationName\\\":\\\"CodingChallengeToCodingProblem\\\"}],\\\"dbName\\\":null},\\\"CodingChallenge\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"CodingChallengeToUser\\\"},{\\\"name\\\":\\\"problemId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"problem\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingProblem\\\",\\\"relationName\\\":\\\"CodingChallengeToCodingProblem\\\"},{\\\"name\\\":\\\"testId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"test\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingTest\\\",\\\"relationName\\\":\\\"CodingChallengeToCodingTest\\\"},{\\\"name\\\":\\\"title\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"description\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"difficulty\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"category\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"company\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"language\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"visibleTests\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"hiddenTests\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"timeLimit\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"status\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"startedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"endedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"starterCode\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"finalCode\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"submissions\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"ChallengeSubmission\\\",\\\"relationName\\\":\\\"ChallengeSubmissionToCodingChallenge\\\"},{\\\"name\\\":\\\"score\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"ChallengeScore\\\",\\\"relationName\\\":\\\"ChallengeScoreToCodingChallenge\\\"}],\\\"dbName\\\":null},\\\"ChallengeSubmission\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"challengeId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"challenge\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingChallenge\\\",\\\"relationName\\\":\\\"ChallengeSubmissionToCodingChallenge\\\"},{\\\"name\\\":\\\"code\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"language\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"submittedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"evaluation\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"testResults\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"isValid\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Boolean\\\"},{\\\"name\\\":\\\"errorMessage\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"}],\\\"dbName\\\":null},\\\"ChallengeScore\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"challengeId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"challenge\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingChallenge\\\",\\\"relationName\\\":\\\"ChallengeScoreToCodingChallenge\\\"},{\\\"name\\\":\\\"correctness\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"efficiency\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"codeQuality\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"edgeCases\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"overallScore\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"passStatus\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Boolean\\\"},{\\\"name\\\":\\\"feedback\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"suggestedApproach\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"complexityAnalysis\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"CodingTest\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"CodingTestToUser\\\"},{\\\"name\\\":\\\"challenges\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"CodingChallenge\\\",\\\"relationName\\\":\\\"CodingChallengeToCodingTest\\\"},{\\\"name\\\":\\\"status\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"startedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"endedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"timeLimit\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null}},\\\"enums\\\":{},\\\"types\\\":{}}\")\n\nasync function decodeBase64AsWasm(wasmBase64: string): Promise<WebAssembly.Module> {\n  const { Buffer } = await import('node:buffer')\n  const wasmArray = Buffer.from(wasmBase64, 'base64')\n  return new WebAssembly.Module(wasmArray)\n}\n\nconfig.compilerWasm = {\n  getRuntime: async () => await import(\"@prisma/client/runtime/query_compiler_fast_bg.sqlite.mjs\"),\n\n  getQueryCompilerWasmModule: async () => {\n    const { wasm } = await import(\"@prisma/client/runtime/query_compiler_fast_bg.sqlite.wasm-base64.mjs\")\n    return await decodeBase64AsWasm(wasm)\n  },\n\n  importName: \"./query_compiler_fast_bg.js\"\n}\n\n\n\nexport type LogOptions<ClientOptions extends Prisma.PrismaClientOptions> =\n  'log' extends keyof ClientOptions ? ClientOptions['log'] extends Array<Prisma.LogLevel | Prisma.LogDefinition> ? Prisma.GetEvents<ClientOptions['log']> : never : never\n\nexport interface PrismaClientConstructor {\n    /**\n   * ## Prisma Client\n   * \n   * Type-safe database client for TypeScript\n   * @example\n   * ```\n   * const prisma = new PrismaClient()\n   * // Fetch zero or more Users\n   * const users = await prisma.user.findMany()\n   * ```\n   * \n   * Read more in our [docs](https://pris.ly/d/client).\n   */\n\n  new <\n    Options extends Prisma.PrismaClientOptions = Prisma.PrismaClientOptions,\n    LogOpts extends LogOptions<Options> = LogOptions<Options>,\n    OmitOpts extends Prisma.PrismaClientOptions['omit'] = Options extends { omit: infer U } ? U : Prisma.PrismaClientOptions['omit'],\n    ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs\n  >(options: Prisma.Subset<Options, Prisma.PrismaClientOptions> ): PrismaClient<LogOpts, OmitOpts, ExtArgs>\n}\n\n/**\n * ## Prisma Client\n * \n * Type-safe database client for TypeScript\n * @example\n * ```\n * const prisma = new PrismaClient()\n * // Fetch zero or more Users\n * const users = await prisma.user.findMany()\n * ```\n * \n * Read more in our [docs](https://pris.ly/d/client).\n */\n\nexport interface PrismaClient<\n  in LogOpts extends Prisma.LogLevel = never,\n  in out OmitOpts extends Prisma.PrismaClientOptions['omit'] = undefined,\n  in out ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs\n> {\n  [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['other'] }\n\n  $on<V extends LogOpts>(eventType: V, callback: (event: V extends 'query' ? Prisma.QueryEvent : Prisma.LogEvent) => void): PrismaClient;\n\n  /**\n   * Connect with the database\n   */\n  $connect(): runtime.Types.Utils.JsPromise<void>;\n\n  /**\n   * Disconnect from the database\n   */\n  $disconnect(): runtime.Types.Utils.JsPromise<void>;\n\n/**\n   * Executes a prepared raw query and returns the number of affected rows.\n   * @example\n   * ```\n   * const result = await prisma.$executeRaw`UPDATE User SET cool = ${true} WHERE email = ${'user@email.com'};`\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $executeRaw<T = unknown>(query: TemplateStringsArray | Prisma.Sql, ...values: any[]): Prisma.PrismaPromise<number>;\n\n  /**\n   * Executes a raw query and returns the number of affected rows.\n   * Susceptible to SQL injections, see documentation.\n   * @example\n   * ```\n   * const result = await prisma.$executeRawUnsafe('UPDATE User SET cool = $1 WHERE email = $2 ;', true, 'user@email.com')\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $executeRawUnsafe<T = unknown>(query: string, ...values: any[]): Prisma.PrismaPromise<number>;\n\n  /**\n   * Performs a prepared raw query and returns the `SELECT` data.\n   * @example\n   * ```\n   * const result = await prisma.$queryRaw`SELECT * FROM User WHERE id = ${1} OR email = ${'user@email.com'};`\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $queryRaw<T = unknown>(query: TemplateStringsArray | Prisma.Sql, ...values: any[]): Prisma.PrismaPromise<T>;\n\n  /**\n   * Performs a raw query and returns the `SELECT` data.\n   * Susceptible to SQL injections, see documentation.\n   * @example\n   * ```\n   * const result = await prisma.$queryRawUnsafe('SELECT * FROM User WHERE id = $1 OR email = $2;', 1, 'user@email.com')\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $queryRawUnsafe<T = unknown>(query: string, ...values: any[]): Prisma.PrismaPromise<T>;\n\n\n  /**\n   * Allows the running of a sequence of read/write operations that are guaranteed to either succeed or fail as a whole.\n   * @example\n   * ```\n   * const [george, bob, alice] = await prisma.$transaction([\n   *   prisma.user.create({ data: { name: 'George' } }),\n   *   prisma.user.create({ data: { name: 'Bob' } }),\n   *   prisma.user.create({ data: { name: 'Alice' } }),\n   * ])\n   * ```\n   * \n   * Read more in our [docs](https://www.prisma.io/docs/concepts/components/prisma-client/transactions).\n   */\n  $transaction<P extends Prisma.PrismaPromise<any>[]>(arg: [...P], options?: { isolationLevel?: Prisma.TransactionIsolationLevel }): runtime.Types.Utils.JsPromise<runtime.Types.Utils.UnwrapTuple<P>>\n\n  $transaction<R>(fn: (prisma: Omit<PrismaClient, runtime.ITXClientDenyList>) => runtime.Types.Utils.JsPromise<R>, options?: { maxWait?: number, timeout?: number, isolationLevel?: Prisma.TransactionIsolationLevel }): runtime.Types.Utils.JsPromise<R>\n\n  $extends: runtime.Types.Extensions.ExtendsHook<\"extends\", Prisma.TypeMapCb<OmitOpts>, ExtArgs, runtime.Types.Utils.Call<Prisma.TypeMapCb<OmitOpts>, {\n    extArgs: ExtArgs\n  }>>\n\n      /**\n   * `prisma.user`: Exposes CRUD operations for the **User** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Users\n    * const users = await prisma.user.findMany()\n    * ```\n    */\n  get user(): Prisma.UserDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.profile`: Exposes CRUD operations for the **Profile** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Profiles\n    * const profiles = await prisma.profile.findMany()\n    * ```\n    */\n  get profile(): Prisma.ProfileDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.resume`: Exposes CRUD operations for the **Resume** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Resumes\n    * const resumes = await prisma.resume.findMany()\n    * ```\n    */\n  get resume(): Prisma.ResumeDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.interview`: Exposes CRUD operations for the **Interview** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Interviews\n    * const interviews = await prisma.interview.findMany()\n    * ```\n    */\n  get interview(): Prisma.InterviewDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.message`: Exposes CRUD operations for the **Message** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Messages\n    * const messages = await prisma.message.findMany()\n    * ```\n    */\n  get message(): Prisma.MessageDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.score`: Exposes CRUD operations for the **Score** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Scores\n    * const scores = await prisma.score.findMany()\n    * ```\n    */\n  get score(): Prisma.ScoreDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.userAnalytics`: Exposes CRUD operations for the **UserAnalytics** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more UserAnalytics\n    * const userAnalytics = await prisma.userAnalytics.findMany()\n    * ```\n    */\n  get userAnalytics(): Prisma.UserAnalyticsDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.codingProblem`: Exposes CRUD operations for the **CodingProblem** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more CodingProblems\n    * const codingProblems = await prisma.codingProblem.findMany()\n    * ```\n    */\n  get codingProblem(): Prisma.CodingProblemDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.codingChallenge`: Exposes CRUD operations for the **CodingChallenge** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more CodingChallenges\n    * const codingChallenges = await prisma.codingChallenge.findMany()\n    * ```\n    */\n  get codingChallenge(): Prisma.CodingChallengeDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.challengeSubmission`: Exposes CRUD operations for the **ChallengeSubmission** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more ChallengeSubmissions\n    * const challengeSubmissions = await prisma.challengeSubmission.findMany()\n    * ```\n    */\n  get challengeSubmission(): Prisma.ChallengeSubmissionDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.challengeScore`: Exposes CRUD operations for the **ChallengeScore** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more ChallengeScores\n    * const challengeScores = await prisma.challengeScore.findMany()\n    * ```\n    */\n  get challengeScore(): Prisma.ChallengeScoreDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.codingTest`: Exposes CRUD operations for the **CodingTest** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more CodingTests\n    * const codingTests = await prisma.codingTest.findMany()\n    * ```\n    */\n  get codingTest(): Prisma.CodingTestDelegate<ExtArgs, { omit: OmitOpts }>;\n}\n\nexport function getPrismaClientClass(): PrismaClientConstructor {\n  return runtime.getPrismaClient(config) as unknown as PrismaClientConstructor\n}\n"],"names":[],"mappings":";;;;AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;;;CAMC,GAED;;AAIA,MAAM,SAAwC;IAC5C,mBAAmB,EAAE;IACrB,iBAAiB;IACjB,iBAAiB;IACjB,kBAAkB;IAClB,gBAAgB;IAChB,oBAAoB;QAClB,UAAU,CAAC;QACX,SAAS,CAAC;QACV,SAAS,CAAC;IACZ;AACF;AAEA,OAAO,gBAAgB,GAAG,KAAK,KAAK,CAAC;AAErC,eAAe,mBAAmB,UAAkB;IAClD,MAAM,EAAE,MAAM,EAAE,GAAG;IACnB,MAAM,YAAY,OAAO,IAAI,CAAC,YAAY;IAC1C,OAAO,IAAI,YAAY,MAAM,CAAC;AAChC;AAEA,OAAO,YAAY,GAAG;IACpB,YAAY,UAAY;IAExB,4BAA4B;QAC1B,MAAM,EAAE,IAAI,EAAE,GAAG;QACjB,OAAO,MAAM,mBAAmB;IAClC;IAEA,YAAY;AACd;AA4PO,SAAS;IACd,OAAO,4TAAuB,CAAC;AACjC"}},
    {"offset": {"line": 117, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/internal/prismaNamespace.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n * WARNING: This is an internal file that is subject to change!\n *\n * ðŸ›‘ Under no circumstances should you import this file directly! ðŸ›‘\n *\n * All exports from this file are wrapped under a `Prisma` namespace object in the client.ts file.\n * While this enables partial backward compatibility, it is not part of the stable public API.\n *\n * If you are looking for your Models, Enums, and Input Types, please import them from the respective\n * model files in the `model` directory!\n */\n\nimport * as runtime from \"@prisma/client/runtime/client\"\nimport type * as Prisma from \"../models\"\nimport { type PrismaClient } from \"./class\"\n\nexport type * from '../models'\n\nexport type DMMF = typeof runtime.DMMF\n\nexport type PrismaPromise<T> = runtime.Types.Public.PrismaPromise<T>\n\n/**\n * Prisma Errors\n */\n\nexport const PrismaClientKnownRequestError = runtime.PrismaClientKnownRequestError\nexport type PrismaClientKnownRequestError = runtime.PrismaClientKnownRequestError\n\nexport const PrismaClientUnknownRequestError = runtime.PrismaClientUnknownRequestError\nexport type PrismaClientUnknownRequestError = runtime.PrismaClientUnknownRequestError\n\nexport const PrismaClientRustPanicError = runtime.PrismaClientRustPanicError\nexport type PrismaClientRustPanicError = runtime.PrismaClientRustPanicError\n\nexport const PrismaClientInitializationError = runtime.PrismaClientInitializationError\nexport type PrismaClientInitializationError = runtime.PrismaClientInitializationError\n\nexport const PrismaClientValidationError = runtime.PrismaClientValidationError\nexport type PrismaClientValidationError = runtime.PrismaClientValidationError\n\n/**\n * Re-export of sql-template-tag\n */\nexport const sql = runtime.sqltag\nexport const empty = runtime.empty\nexport const join = runtime.join\nexport const raw = runtime.raw\nexport const Sql = runtime.Sql\nexport type Sql = runtime.Sql\n\n\n\n/**\n * Decimal.js\n */\nexport const Decimal = runtime.Decimal\nexport type Decimal = runtime.Decimal\n\nexport type DecimalJsLike = runtime.DecimalJsLike\n\n/**\n* Extensions\n*/\nexport type Extension = runtime.Types.Extensions.UserArgs\nexport const getExtensionContext = runtime.Extensions.getExtensionContext\nexport type Args<T, F extends runtime.Operation> = runtime.Types.Public.Args<T, F>\nexport type Payload<T, F extends runtime.Operation = never> = runtime.Types.Public.Payload<T, F>\nexport type Result<T, A, F extends runtime.Operation> = runtime.Types.Public.Result<T, A, F>\nexport type Exact<A, W> = runtime.Types.Public.Exact<A, W>\n\nexport type PrismaVersion = {\n  client: string\n  engine: string\n}\n\n/**\n * Prisma Client JS version: 7.3.0\n * Query Engine version: 9d6ad21cbbceab97458517b147a6a09ff43aa735\n */\nexport const prismaVersion: PrismaVersion = {\n  client: \"7.3.0\",\n  engine: \"9d6ad21cbbceab97458517b147a6a09ff43aa735\"\n}\n\n/**\n * Utility Types\n */\n\nexport type Bytes = runtime.Bytes\nexport type JsonObject = runtime.JsonObject\nexport type JsonArray = runtime.JsonArray\nexport type JsonValue = runtime.JsonValue\nexport type InputJsonObject = runtime.InputJsonObject\nexport type InputJsonArray = runtime.InputJsonArray\nexport type InputJsonValue = runtime.InputJsonValue\n\n\nexport const NullTypes = {\n  DbNull: runtime.NullTypes.DbNull as (new (secret: never) => typeof runtime.DbNull),\n  JsonNull: runtime.NullTypes.JsonNull as (new (secret: never) => typeof runtime.JsonNull),\n  AnyNull: runtime.NullTypes.AnyNull as (new (secret: never) => typeof runtime.AnyNull),\n}\n/**\n * Helper for filtering JSON entries that have `null` on the database (empty on the db)\n *\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n */\nexport const DbNull = runtime.DbNull\n\n/**\n * Helper for filtering JSON entries that have JSON `null` values (not empty on the db)\n *\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n */\nexport const JsonNull = runtime.JsonNull\n\n/**\n * Helper for filtering JSON entries that are `Prisma.DbNull` or `Prisma.JsonNull`\n *\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n */\nexport const AnyNull = runtime.AnyNull\n\n\ntype SelectAndInclude = {\n  select: any\n  include: any\n}\n\ntype SelectAndOmit = {\n  select: any\n  omit: any\n}\n\n/**\n * From T, pick a set of properties whose keys are in the union K\n */\ntype Prisma__Pick<T, K extends keyof T> = {\n    [P in K]: T[P];\n};\n\nexport type Enumerable<T> = T | Array<T>;\n\n/**\n * Subset\n * @desc From `T` pick properties that exist in `U`. Simple version of Intersection\n */\nexport type Subset<T, U> = {\n  [key in keyof T]: key extends keyof U ? T[key] : never;\n};\n\n/**\n * SelectSubset\n * @desc From `T` pick properties that exist in `U`. Simple version of Intersection.\n * Additionally, it validates, if both select and include are present. If the case, it errors.\n */\nexport type SelectSubset<T, U> = {\n  [key in keyof T]: key extends keyof U ? T[key] : never\n} &\n  (T extends SelectAndInclude\n    ? 'Please either choose `select` or `include`.'\n    : T extends SelectAndOmit\n      ? 'Please either choose `select` or `omit`.'\n      : {})\n\n/**\n * Subset + Intersection\n * @desc From `T` pick properties that exist in `U` and intersect `K`\n */\nexport type SubsetIntersection<T, U, K> = {\n  [key in keyof T]: key extends keyof U ? T[key] : never\n} &\n  K\n\ntype Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };\n\n/**\n * XOR is needed to have a real mutually exclusive union type\n * https://stackoverflow.com/questions/42123407/does-typescript-support-mutually-exclusive-types\n */\nexport type XOR<T, U> =\n  T extends object ?\n  U extends object ?\n    (Without<T, U> & U) | (Without<U, T> & T)\n  : U : T\n\n\n/**\n * Is T a Record?\n */\ntype IsObject<T extends any> = T extends Array<any>\n? False\n: T extends Date\n? False\n: T extends Uint8Array\n? False\n: T extends BigInt\n? False\n: T extends object\n? True\n: False\n\n\n/**\n * If it's T[], return T\n */\nexport type UnEnumerate<T extends unknown> = T extends Array<infer U> ? U : T\n\n/**\n * From ts-toolbelt\n */\n\ntype __Either<O extends object, K extends Key> = Omit<O, K> &\n  {\n    // Merge all but K\n    [P in K]: Prisma__Pick<O, P & keyof O> // With K possibilities\n  }[K]\n\ntype EitherStrict<O extends object, K extends Key> = Strict<__Either<O, K>>\n\ntype EitherLoose<O extends object, K extends Key> = ComputeRaw<__Either<O, K>>\n\ntype _Either<\n  O extends object,\n  K extends Key,\n  strict extends Boolean\n> = {\n  1: EitherStrict<O, K>\n  0: EitherLoose<O, K>\n}[strict]\n\nexport type Either<\n  O extends object,\n  K extends Key,\n  strict extends Boolean = 1\n> = O extends unknown ? _Either<O, K, strict> : never\n\nexport type Union = any\n\nexport type PatchUndefined<O extends object, O1 extends object> = {\n  [K in keyof O]: O[K] extends undefined ? At<O1, K> : O[K]\n} & {}\n\n/** Helper Types for \"Merge\" **/\nexport type IntersectOf<U extends Union> = (\n  U extends unknown ? (k: U) => void : never\n) extends (k: infer I) => void\n  ? I\n  : never\n\nexport type Overwrite<O extends object, O1 extends object> = {\n    [K in keyof O]: K extends keyof O1 ? O1[K] : O[K];\n} & {};\n\ntype _Merge<U extends object> = IntersectOf<Overwrite<U, {\n    [K in keyof U]-?: At<U, K>;\n}>>;\n\ntype Key = string | number | symbol;\ntype AtStrict<O extends object, K extends Key> = O[K & keyof O];\ntype AtLoose<O extends object, K extends Key> = O extends unknown ? AtStrict<O, K> : never;\nexport type At<O extends object, K extends Key, strict extends Boolean = 1> = {\n    1: AtStrict<O, K>;\n    0: AtLoose<O, K>;\n}[strict];\n\nexport type ComputeRaw<A extends any> = A extends Function ? A : {\n  [K in keyof A]: A[K];\n} & {};\n\nexport type OptionalFlat<O> = {\n  [K in keyof O]?: O[K];\n} & {};\n\ntype _Record<K extends keyof any, T> = {\n  [P in K]: T;\n};\n\n// cause typescript not to expand types and preserve names\ntype NoExpand<T> = T extends unknown ? T : never;\n\n// this type assumes the passed object is entirely optional\nexport type AtLeast<O extends object, K extends string> = NoExpand<\n  O extends unknown\n  ? | (K extends keyof O ? { [P in K]: O[P] } & O : O)\n    | {[P in keyof O as P extends K ? P : never]-?: O[P]} & O\n  : never>;\n\ntype _Strict<U, _U = U> = U extends unknown ? U & OptionalFlat<_Record<Exclude<Keys<_U>, keyof U>, never>> : never;\n\nexport type Strict<U extends object> = ComputeRaw<_Strict<U>>;\n/** End Helper Types for \"Merge\" **/\n\nexport type Merge<U extends object> = ComputeRaw<_Merge<Strict<U>>>;\n\nexport type Boolean = True | False\n\nexport type True = 1\n\nexport type False = 0\n\nexport type Not<B extends Boolean> = {\n  0: 1\n  1: 0\n}[B]\n\nexport type Extends<A1 extends any, A2 extends any> = [A1] extends [never]\n  ? 0 // anything `never` is false\n  : A1 extends A2\n  ? 1\n  : 0\n\nexport type Has<U extends Union, U1 extends Union> = Not<\n  Extends<Exclude<U1, U>, U1>\n>\n\nexport type Or<B1 extends Boolean, B2 extends Boolean> = {\n  0: {\n    0: 0\n    1: 1\n  }\n  1: {\n    0: 1\n    1: 1\n  }\n}[B1][B2]\n\nexport type Keys<U extends Union> = U extends unknown ? keyof U : never\n\nexport type GetScalarType<T, O> = O extends object ? {\n  [P in keyof T]: P extends keyof O\n    ? O[P]\n    : never\n} : never\n\ntype FieldPaths<\n  T,\n  U = Omit<T, '_avg' | '_sum' | '_count' | '_min' | '_max'>\n> = IsObject<T> extends True ? U : T\n\nexport type GetHavingFields<T> = {\n  [K in keyof T]: Or<\n    Or<Extends<'OR', K>, Extends<'AND', K>>,\n    Extends<'NOT', K>\n  > extends True\n    ? // infer is only needed to not hit TS limit\n      // based on the brilliant idea of Pierre-Antoine Mills\n      // https://github.com/microsoft/TypeScript/issues/30188#issuecomment-478938437\n      T[K] extends infer TK\n      ? GetHavingFields<UnEnumerate<TK> extends object ? Merge<UnEnumerate<TK>> : never>\n      : never\n    : {} extends FieldPaths<T[K]>\n    ? never\n    : K\n}[keyof T]\n\n/**\n * Convert tuple to union\n */\ntype _TupleToUnion<T> = T extends (infer E)[] ? E : never\ntype TupleToUnion<K extends readonly any[]> = _TupleToUnion<K>\nexport type MaybeTupleToUnion<T> = T extends any[] ? TupleToUnion<T> : T\n\n/**\n * Like `Pick`, but additionally can also accept an array of keys\n */\nexport type PickEnumerable<T, K extends Enumerable<keyof T> | keyof T> = Prisma__Pick<T, MaybeTupleToUnion<K>>\n\n/**\n * Exclude all keys with underscores\n */\nexport type ExcludeUnderscoreKeys<T extends string> = T extends `_${string}` ? never : T\n\n\nexport type FieldRef<Model, FieldType> = runtime.FieldRef<Model, FieldType>\n\ntype FieldRefInputType<Model, FieldType> = Model extends never ? never : FieldRef<Model, FieldType>\n\n\nexport const ModelName = {\n  User: 'User',\n  Profile: 'Profile',\n  Resume: 'Resume',\n  Interview: 'Interview',\n  Message: 'Message',\n  Score: 'Score',\n  UserAnalytics: 'UserAnalytics',\n  CodingProblem: 'CodingProblem',\n  CodingChallenge: 'CodingChallenge',\n  ChallengeSubmission: 'ChallengeSubmission',\n  ChallengeScore: 'ChallengeScore',\n  CodingTest: 'CodingTest'\n} as const\n\nexport type ModelName = (typeof ModelName)[keyof typeof ModelName]\n\n\n\nexport interface TypeMapCb<GlobalOmitOptions = {}> extends runtime.Types.Utils.Fn<{extArgs: runtime.Types.Extensions.InternalArgs }, runtime.Types.Utils.Record<string, any>> {\n  returns: TypeMap<this['params']['extArgs'], GlobalOmitOptions>\n}\n\nexport type TypeMap<ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs, GlobalOmitOptions = {}> = {\n  globalOmitOptions: {\n    omit: GlobalOmitOptions\n  }\n  meta: {\n    modelProps: \"user\" | \"profile\" | \"resume\" | \"interview\" | \"message\" | \"score\" | \"userAnalytics\" | \"codingProblem\" | \"codingChallenge\" | \"challengeSubmission\" | \"challengeScore\" | \"codingTest\"\n    txIsolationLevel: TransactionIsolationLevel\n  }\n  model: {\n    User: {\n      payload: Prisma.$UserPayload<ExtArgs>\n      fields: Prisma.UserFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.UserFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.UserFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        findFirst: {\n          args: Prisma.UserFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.UserFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        findMany: {\n          args: Prisma.UserFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>[]\n        }\n        create: {\n          args: Prisma.UserCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        createMany: {\n          args: Prisma.UserCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.UserCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>[]\n        }\n        delete: {\n          args: Prisma.UserDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        update: {\n          args: Prisma.UserUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        deleteMany: {\n          args: Prisma.UserDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.UserUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.UserUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>[]\n        }\n        upsert: {\n          args: Prisma.UserUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        aggregate: {\n          args: Prisma.UserAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateUser>\n        }\n        groupBy: {\n          args: Prisma.UserGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.UserGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.UserCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.UserCountAggregateOutputType> | number\n        }\n      }\n    }\n    Profile: {\n      payload: Prisma.$ProfilePayload<ExtArgs>\n      fields: Prisma.ProfileFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ProfileFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ProfileFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        findFirst: {\n          args: Prisma.ProfileFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ProfileFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        findMany: {\n          args: Prisma.ProfileFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>[]\n        }\n        create: {\n          args: Prisma.ProfileCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        createMany: {\n          args: Prisma.ProfileCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ProfileCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>[]\n        }\n        delete: {\n          args: Prisma.ProfileDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        update: {\n          args: Prisma.ProfileUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        deleteMany: {\n          args: Prisma.ProfileDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ProfileUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ProfileUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>[]\n        }\n        upsert: {\n          args: Prisma.ProfileUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        aggregate: {\n          args: Prisma.ProfileAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateProfile>\n        }\n        groupBy: {\n          args: Prisma.ProfileGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ProfileGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ProfileCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ProfileCountAggregateOutputType> | number\n        }\n      }\n    }\n    Resume: {\n      payload: Prisma.$ResumePayload<ExtArgs>\n      fields: Prisma.ResumeFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ResumeFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ResumeFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        findFirst: {\n          args: Prisma.ResumeFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ResumeFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        findMany: {\n          args: Prisma.ResumeFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>[]\n        }\n        create: {\n          args: Prisma.ResumeCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        createMany: {\n          args: Prisma.ResumeCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ResumeCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>[]\n        }\n        delete: {\n          args: Prisma.ResumeDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        update: {\n          args: Prisma.ResumeUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        deleteMany: {\n          args: Prisma.ResumeDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ResumeUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ResumeUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>[]\n        }\n        upsert: {\n          args: Prisma.ResumeUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        aggregate: {\n          args: Prisma.ResumeAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateResume>\n        }\n        groupBy: {\n          args: Prisma.ResumeGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ResumeGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ResumeCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ResumeCountAggregateOutputType> | number\n        }\n      }\n    }\n    Interview: {\n      payload: Prisma.$InterviewPayload<ExtArgs>\n      fields: Prisma.InterviewFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.InterviewFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.InterviewFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        findFirst: {\n          args: Prisma.InterviewFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.InterviewFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        findMany: {\n          args: Prisma.InterviewFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>[]\n        }\n        create: {\n          args: Prisma.InterviewCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        createMany: {\n          args: Prisma.InterviewCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.InterviewCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>[]\n        }\n        delete: {\n          args: Prisma.InterviewDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        update: {\n          args: Prisma.InterviewUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        deleteMany: {\n          args: Prisma.InterviewDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.InterviewUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.InterviewUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>[]\n        }\n        upsert: {\n          args: Prisma.InterviewUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        aggregate: {\n          args: Prisma.InterviewAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateInterview>\n        }\n        groupBy: {\n          args: Prisma.InterviewGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.InterviewGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.InterviewCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.InterviewCountAggregateOutputType> | number\n        }\n      }\n    }\n    Message: {\n      payload: Prisma.$MessagePayload<ExtArgs>\n      fields: Prisma.MessageFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.MessageFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.MessageFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        findFirst: {\n          args: Prisma.MessageFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.MessageFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        findMany: {\n          args: Prisma.MessageFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>[]\n        }\n        create: {\n          args: Prisma.MessageCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        createMany: {\n          args: Prisma.MessageCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.MessageCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>[]\n        }\n        delete: {\n          args: Prisma.MessageDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        update: {\n          args: Prisma.MessageUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        deleteMany: {\n          args: Prisma.MessageDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.MessageUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.MessageUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>[]\n        }\n        upsert: {\n          args: Prisma.MessageUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        aggregate: {\n          args: Prisma.MessageAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateMessage>\n        }\n        groupBy: {\n          args: Prisma.MessageGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.MessageGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.MessageCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.MessageCountAggregateOutputType> | number\n        }\n      }\n    }\n    Score: {\n      payload: Prisma.$ScorePayload<ExtArgs>\n      fields: Prisma.ScoreFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ScoreFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ScoreFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        findFirst: {\n          args: Prisma.ScoreFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ScoreFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        findMany: {\n          args: Prisma.ScoreFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>[]\n        }\n        create: {\n          args: Prisma.ScoreCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        createMany: {\n          args: Prisma.ScoreCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ScoreCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>[]\n        }\n        delete: {\n          args: Prisma.ScoreDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        update: {\n          args: Prisma.ScoreUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        deleteMany: {\n          args: Prisma.ScoreDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ScoreUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ScoreUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>[]\n        }\n        upsert: {\n          args: Prisma.ScoreUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        aggregate: {\n          args: Prisma.ScoreAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateScore>\n        }\n        groupBy: {\n          args: Prisma.ScoreGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ScoreGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ScoreCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ScoreCountAggregateOutputType> | number\n        }\n      }\n    }\n    UserAnalytics: {\n      payload: Prisma.$UserAnalyticsPayload<ExtArgs>\n      fields: Prisma.UserAnalyticsFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.UserAnalyticsFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.UserAnalyticsFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>\n        }\n        findFirst: {\n          args: Prisma.UserAnalyticsFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.UserAnalyticsFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>\n        }\n        findMany: {\n          args: Prisma.UserAnalyticsFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>[]\n        }\n        create: {\n          args: Prisma.UserAnalyticsCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>\n        }\n        createMany: {\n          args: Prisma.UserAnalyticsCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.UserAnalyticsCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>[]\n        }\n        delete: {\n          args: Prisma.UserAnalyticsDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>\n        }\n        update: {\n          args: Prisma.UserAnalyticsUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>\n        }\n        deleteMany: {\n          args: Prisma.UserAnalyticsDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.UserAnalyticsUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.UserAnalyticsUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>[]\n        }\n        upsert: {\n          args: Prisma.UserAnalyticsUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserAnalyticsPayload>\n        }\n        aggregate: {\n          args: Prisma.UserAnalyticsAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateUserAnalytics>\n        }\n        groupBy: {\n          args: Prisma.UserAnalyticsGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.UserAnalyticsGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.UserAnalyticsCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.UserAnalyticsCountAggregateOutputType> | number\n        }\n      }\n    }\n    CodingProblem: {\n      payload: Prisma.$CodingProblemPayload<ExtArgs>\n      fields: Prisma.CodingProblemFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.CodingProblemFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.CodingProblemFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>\n        }\n        findFirst: {\n          args: Prisma.CodingProblemFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.CodingProblemFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>\n        }\n        findMany: {\n          args: Prisma.CodingProblemFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>[]\n        }\n        create: {\n          args: Prisma.CodingProblemCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>\n        }\n        createMany: {\n          args: Prisma.CodingProblemCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.CodingProblemCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>[]\n        }\n        delete: {\n          args: Prisma.CodingProblemDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>\n        }\n        update: {\n          args: Prisma.CodingProblemUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>\n        }\n        deleteMany: {\n          args: Prisma.CodingProblemDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.CodingProblemUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.CodingProblemUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>[]\n        }\n        upsert: {\n          args: Prisma.CodingProblemUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingProblemPayload>\n        }\n        aggregate: {\n          args: Prisma.CodingProblemAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateCodingProblem>\n        }\n        groupBy: {\n          args: Prisma.CodingProblemGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.CodingProblemGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.CodingProblemCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.CodingProblemCountAggregateOutputType> | number\n        }\n      }\n    }\n    CodingChallenge: {\n      payload: Prisma.$CodingChallengePayload<ExtArgs>\n      fields: Prisma.CodingChallengeFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.CodingChallengeFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.CodingChallengeFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>\n        }\n        findFirst: {\n          args: Prisma.CodingChallengeFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.CodingChallengeFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>\n        }\n        findMany: {\n          args: Prisma.CodingChallengeFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>[]\n        }\n        create: {\n          args: Prisma.CodingChallengeCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>\n        }\n        createMany: {\n          args: Prisma.CodingChallengeCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.CodingChallengeCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>[]\n        }\n        delete: {\n          args: Prisma.CodingChallengeDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>\n        }\n        update: {\n          args: Prisma.CodingChallengeUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>\n        }\n        deleteMany: {\n          args: Prisma.CodingChallengeDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.CodingChallengeUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.CodingChallengeUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>[]\n        }\n        upsert: {\n          args: Prisma.CodingChallengeUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingChallengePayload>\n        }\n        aggregate: {\n          args: Prisma.CodingChallengeAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateCodingChallenge>\n        }\n        groupBy: {\n          args: Prisma.CodingChallengeGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.CodingChallengeGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.CodingChallengeCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.CodingChallengeCountAggregateOutputType> | number\n        }\n      }\n    }\n    ChallengeSubmission: {\n      payload: Prisma.$ChallengeSubmissionPayload<ExtArgs>\n      fields: Prisma.ChallengeSubmissionFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ChallengeSubmissionFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ChallengeSubmissionFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>\n        }\n        findFirst: {\n          args: Prisma.ChallengeSubmissionFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ChallengeSubmissionFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>\n        }\n        findMany: {\n          args: Prisma.ChallengeSubmissionFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>[]\n        }\n        create: {\n          args: Prisma.ChallengeSubmissionCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>\n        }\n        createMany: {\n          args: Prisma.ChallengeSubmissionCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ChallengeSubmissionCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>[]\n        }\n        delete: {\n          args: Prisma.ChallengeSubmissionDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>\n        }\n        update: {\n          args: Prisma.ChallengeSubmissionUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>\n        }\n        deleteMany: {\n          args: Prisma.ChallengeSubmissionDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ChallengeSubmissionUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ChallengeSubmissionUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>[]\n        }\n        upsert: {\n          args: Prisma.ChallengeSubmissionUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeSubmissionPayload>\n        }\n        aggregate: {\n          args: Prisma.ChallengeSubmissionAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateChallengeSubmission>\n        }\n        groupBy: {\n          args: Prisma.ChallengeSubmissionGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ChallengeSubmissionGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ChallengeSubmissionCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ChallengeSubmissionCountAggregateOutputType> | number\n        }\n      }\n    }\n    ChallengeScore: {\n      payload: Prisma.$ChallengeScorePayload<ExtArgs>\n      fields: Prisma.ChallengeScoreFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ChallengeScoreFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ChallengeScoreFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>\n        }\n        findFirst: {\n          args: Prisma.ChallengeScoreFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ChallengeScoreFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>\n        }\n        findMany: {\n          args: Prisma.ChallengeScoreFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>[]\n        }\n        create: {\n          args: Prisma.ChallengeScoreCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>\n        }\n        createMany: {\n          args: Prisma.ChallengeScoreCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ChallengeScoreCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>[]\n        }\n        delete: {\n          args: Prisma.ChallengeScoreDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>\n        }\n        update: {\n          args: Prisma.ChallengeScoreUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>\n        }\n        deleteMany: {\n          args: Prisma.ChallengeScoreDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ChallengeScoreUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ChallengeScoreUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>[]\n        }\n        upsert: {\n          args: Prisma.ChallengeScoreUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ChallengeScorePayload>\n        }\n        aggregate: {\n          args: Prisma.ChallengeScoreAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateChallengeScore>\n        }\n        groupBy: {\n          args: Prisma.ChallengeScoreGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ChallengeScoreGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ChallengeScoreCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ChallengeScoreCountAggregateOutputType> | number\n        }\n      }\n    }\n    CodingTest: {\n      payload: Prisma.$CodingTestPayload<ExtArgs>\n      fields: Prisma.CodingTestFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.CodingTestFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.CodingTestFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>\n        }\n        findFirst: {\n          args: Prisma.CodingTestFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.CodingTestFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>\n        }\n        findMany: {\n          args: Prisma.CodingTestFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>[]\n        }\n        create: {\n          args: Prisma.CodingTestCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>\n        }\n        createMany: {\n          args: Prisma.CodingTestCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.CodingTestCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>[]\n        }\n        delete: {\n          args: Prisma.CodingTestDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>\n        }\n        update: {\n          args: Prisma.CodingTestUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>\n        }\n        deleteMany: {\n          args: Prisma.CodingTestDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.CodingTestUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.CodingTestUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>[]\n        }\n        upsert: {\n          args: Prisma.CodingTestUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$CodingTestPayload>\n        }\n        aggregate: {\n          args: Prisma.CodingTestAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateCodingTest>\n        }\n        groupBy: {\n          args: Prisma.CodingTestGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.CodingTestGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.CodingTestCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.CodingTestCountAggregateOutputType> | number\n        }\n      }\n    }\n  }\n} & {\n  other: {\n    payload: any\n    operations: {\n      $executeRaw: {\n        args: [query: TemplateStringsArray | Sql, ...values: any[]],\n        result: any\n      }\n      $executeRawUnsafe: {\n        args: [query: string, ...values: any[]],\n        result: any\n      }\n      $queryRaw: {\n        args: [query: TemplateStringsArray | Sql, ...values: any[]],\n        result: any\n      }\n      $queryRawUnsafe: {\n        args: [query: string, ...values: any[]],\n        result: any\n      }\n    }\n  }\n}\n\n/**\n * Enums\n */\n\nexport const TransactionIsolationLevel = runtime.makeStrictEnum({\n  Serializable: 'Serializable'\n} as const)\n\nexport type TransactionIsolationLevel = (typeof TransactionIsolationLevel)[keyof typeof TransactionIsolationLevel]\n\n\nexport const UserScalarFieldEnum = {\n  id: 'id',\n  email: 'email',\n  password: 'password',\n  name: 'name',\n  avatar: 'avatar',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type UserScalarFieldEnum = (typeof UserScalarFieldEnum)[keyof typeof UserScalarFieldEnum]\n\n\nexport const ProfileScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  bio: 'bio',\n  yearsExperience: 'yearsExperience',\n  skills: 'skills',\n  targetCompanies: 'targetCompanies',\n  targetRole: 'targetRole',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type ProfileScalarFieldEnum = (typeof ProfileScalarFieldEnum)[keyof typeof ProfileScalarFieldEnum]\n\n\nexport const ResumeScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  fileName: 'fileName',\n  content: 'content',\n  analysis: 'analysis',\n  filePath: 'filePath',\n  atsScore: 'atsScore',\n  atsBreakdown: 'atsBreakdown',\n  atsFeedback: 'atsFeedback',\n  keywords: 'keywords',\n  softSkills: 'softSkills',\n  predictedRoles: 'predictedRoles',\n  uploadedAt: 'uploadedAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type ResumeScalarFieldEnum = (typeof ResumeScalarFieldEnum)[keyof typeof ResumeScalarFieldEnum]\n\n\nexport const InterviewScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  topic: 'topic',\n  difficulty: 'difficulty',\n  status: 'status',\n  startedAt: 'startedAt',\n  endedAt: 'endedAt',\n  createdAt: 'createdAt',\n  phaseDurations: 'phaseDurations',\n  phaseTransitions: 'phaseTransitions'\n} as const\n\nexport type InterviewScalarFieldEnum = (typeof InterviewScalarFieldEnum)[keyof typeof InterviewScalarFieldEnum]\n\n\nexport const MessageScalarFieldEnum = {\n  id: 'id',\n  interviewId: 'interviewId',\n  role: 'role',\n  content: 'content',\n  timestamp: 'timestamp'\n} as const\n\nexport type MessageScalarFieldEnum = (typeof MessageScalarFieldEnum)[keyof typeof MessageScalarFieldEnum]\n\n\nexport const ScoreScalarFieldEnum = {\n  id: 'id',\n  interviewId: 'interviewId',\n  requirementsClarification: 'requirementsClarification',\n  highLevelDesign: 'highLevelDesign',\n  detailedDesign: 'detailedDesign',\n  scalability: 'scalability',\n  tradeoffs: 'tradeoffs',\n  communication: 'communication',\n  overallScore: 'overallScore',\n  passStatus: 'passStatus',\n  feedback: 'feedback',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type ScoreScalarFieldEnum = (typeof ScoreScalarFieldEnum)[keyof typeof ScoreScalarFieldEnum]\n\n\nexport const UserAnalyticsScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  totalInterviews: 'totalInterviews',\n  completedInterviews: 'completedInterviews',\n  avgOverallScore: 'avgOverallScore',\n  passRate: 'passRate',\n  weakDimensions: 'weakDimensions',\n  strongDimensions: 'strongDimensions',\n  topicStats: 'topicStats',\n  scoreTrend: 'scoreTrend',\n  lastCalculatedAt: 'lastCalculatedAt',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type UserAnalyticsScalarFieldEnum = (typeof UserAnalyticsScalarFieldEnum)[keyof typeof UserAnalyticsScalarFieldEnum]\n\n\nexport const CodingProblemScalarFieldEnum = {\n  id: 'id',\n  title: 'title',\n  description: 'description',\n  difficulty: 'difficulty',\n  category: 'category',\n  companies: 'companies',\n  constraints: 'constraints',\n  examples: 'examples',\n  testCases: 'testCases',\n  solutionApproaches: 'solutionApproaches',\n  starterCode: 'starterCode',\n  timeLimit: 'timeLimit',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type CodingProblemScalarFieldEnum = (typeof CodingProblemScalarFieldEnum)[keyof typeof CodingProblemScalarFieldEnum]\n\n\nexport const CodingChallengeScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  problemId: 'problemId',\n  testId: 'testId',\n  title: 'title',\n  description: 'description',\n  difficulty: 'difficulty',\n  category: 'category',\n  company: 'company',\n  language: 'language',\n  visibleTests: 'visibleTests',\n  hiddenTests: 'hiddenTests',\n  timeLimit: 'timeLimit',\n  status: 'status',\n  startedAt: 'startedAt',\n  endedAt: 'endedAt',\n  starterCode: 'starterCode',\n  finalCode: 'finalCode',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type CodingChallengeScalarFieldEnum = (typeof CodingChallengeScalarFieldEnum)[keyof typeof CodingChallengeScalarFieldEnum]\n\n\nexport const ChallengeSubmissionScalarFieldEnum = {\n  id: 'id',\n  challengeId: 'challengeId',\n  code: 'code',\n  language: 'language',\n  submittedAt: 'submittedAt',\n  evaluation: 'evaluation',\n  testResults: 'testResults',\n  isValid: 'isValid',\n  errorMessage: 'errorMessage'\n} as const\n\nexport type ChallengeSubmissionScalarFieldEnum = (typeof ChallengeSubmissionScalarFieldEnum)[keyof typeof ChallengeSubmissionScalarFieldEnum]\n\n\nexport const ChallengeScoreScalarFieldEnum = {\n  id: 'id',\n  challengeId: 'challengeId',\n  correctness: 'correctness',\n  efficiency: 'efficiency',\n  codeQuality: 'codeQuality',\n  edgeCases: 'edgeCases',\n  overallScore: 'overallScore',\n  passStatus: 'passStatus',\n  feedback: 'feedback',\n  suggestedApproach: 'suggestedApproach',\n  complexityAnalysis: 'complexityAnalysis',\n  createdAt: 'createdAt'\n} as const\n\nexport type ChallengeScoreScalarFieldEnum = (typeof ChallengeScoreScalarFieldEnum)[keyof typeof ChallengeScoreScalarFieldEnum]\n\n\nexport const CodingTestScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  status: 'status',\n  startedAt: 'startedAt',\n  endedAt: 'endedAt',\n  timeLimit: 'timeLimit',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type CodingTestScalarFieldEnum = (typeof CodingTestScalarFieldEnum)[keyof typeof CodingTestScalarFieldEnum]\n\n\nexport const SortOrder = {\n  asc: 'asc',\n  desc: 'desc'\n} as const\n\nexport type SortOrder = (typeof SortOrder)[keyof typeof SortOrder]\n\n\nexport const NullsOrder = {\n  first: 'first',\n  last: 'last'\n} as const\n\nexport type NullsOrder = (typeof NullsOrder)[keyof typeof NullsOrder]\n\n\n\n/**\n * Field references\n */\n\n\n/**\n * Reference to a field of type 'String'\n */\nexport type StringFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'String'>\n    \n\n\n/**\n * Reference to a field of type 'DateTime'\n */\nexport type DateTimeFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'DateTime'>\n    \n\n\n/**\n * Reference to a field of type 'Int'\n */\nexport type IntFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Int'>\n    \n\n\n/**\n * Reference to a field of type 'Float'\n */\nexport type FloatFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Float'>\n    \n\n\n/**\n * Reference to a field of type 'Boolean'\n */\nexport type BooleanFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Boolean'>\n    \n\n/**\n * Batch Payload for updateMany & deleteMany & createMany\n */\nexport type BatchPayload = {\n  count: number\n}\n\nexport const defineExtension = runtime.Extensions.defineExtension as unknown as runtime.Types.Extensions.ExtendsHook<\"define\", TypeMapCb, runtime.Types.Extensions.DefaultArgs>\nexport type DefaultPrismaClient = PrismaClient\nexport type ErrorFormat = 'pretty' | 'colorless' | 'minimal'\nexport type PrismaClientOptions = ({\n  /**\n   * Instance of a Driver Adapter, e.g., like one provided by `@prisma/adapter-pg`.\n   */\n  adapter: runtime.SqlDriverAdapterFactory\n  accelerateUrl?: never\n} | {\n  /**\n   * Prisma Accelerate URL allowing the client to connect through Accelerate instead of a direct database.\n   */\n  accelerateUrl: string\n  adapter?: never\n}) & {\n  /**\n   * @default \"colorless\"\n   */\n  errorFormat?: ErrorFormat\n  /**\n   * @example\n   * ```\n   * // Shorthand for `emit: 'stdout'`\n   * log: ['query', 'info', 'warn', 'error']\n   * \n   * // Emit as events only\n   * log: [\n   *   { emit: 'event', level: 'query' },\n   *   { emit: 'event', level: 'info' },\n   *   { emit: 'event', level: 'warn' }\n   *   { emit: 'event', level: 'error' }\n   * ]\n   * \n   * / Emit as events and log to stdout\n   * og: [\n   *  { emit: 'stdout', level: 'query' },\n   *  { emit: 'stdout', level: 'info' },\n   *  { emit: 'stdout', level: 'warn' }\n   *  { emit: 'stdout', level: 'error' }\n   * \n   * ```\n   * Read more in our [docs](https://pris.ly/d/logging).\n   */\n  log?: (LogLevel | LogDefinition)[]\n  /**\n   * The default values for transactionOptions\n   * maxWait ?= 2000\n   * timeout ?= 5000\n   */\n  transactionOptions?: {\n    maxWait?: number\n    timeout?: number\n    isolationLevel?: TransactionIsolationLevel\n  }\n  /**\n   * Global configuration for omitting model fields by default.\n   * \n   * @example\n   * ```\n   * const prisma = new PrismaClient({\n   *   omit: {\n   *     user: {\n   *       password: true\n   *     }\n   *   }\n   * })\n   * ```\n   */\n  omit?: GlobalOmitConfig\n  /**\n   * SQL commenter plugins that add metadata to SQL queries as comments.\n   * Comments follow the sqlcommenter format: https://google.github.io/sqlcommenter/\n   * \n   * @example\n   * ```\n   * const prisma = new PrismaClient({\n   *   adapter,\n   *   comments: [\n   *     traceContext(),\n   *     queryInsights(),\n   *   ],\n   * })\n   * ```\n   */\n  comments?: runtime.SqlCommenterPlugin[]\n}\nexport type GlobalOmitConfig = {\n  user?: Prisma.UserOmit\n  profile?: Prisma.ProfileOmit\n  resume?: Prisma.ResumeOmit\n  interview?: Prisma.InterviewOmit\n  message?: Prisma.MessageOmit\n  score?: Prisma.ScoreOmit\n  userAnalytics?: Prisma.UserAnalyticsOmit\n  codingProblem?: Prisma.CodingProblemOmit\n  codingChallenge?: Prisma.CodingChallengeOmit\n  challengeSubmission?: Prisma.ChallengeSubmissionOmit\n  challengeScore?: Prisma.ChallengeScoreOmit\n  codingTest?: Prisma.CodingTestOmit\n}\n\n/* Types for Logging */\nexport type LogLevel = 'info' | 'query' | 'warn' | 'error'\nexport type LogDefinition = {\n  level: LogLevel\n  emit: 'stdout' | 'event'\n}\n\nexport type CheckIsLogLevel<T> = T extends LogLevel ? T : never;\n\nexport type GetLogType<T> = CheckIsLogLevel<\n  T extends LogDefinition ? T['level'] : T\n>;\n\nexport type GetEvents<T extends any[]> = T extends Array<LogLevel | LogDefinition>\n  ? GetLogType<T[number]>\n  : never;\n\nexport type QueryEvent = {\n  timestamp: Date\n  query: string\n  params: string\n  duration: number\n  target: string\n}\n\nexport type LogEvent = {\n  timestamp: Date\n  message: string\n  target: string\n}\n/* End Types for Logging */\n\n\nexport type PrismaAction =\n  | 'findUnique'\n  | 'findUniqueOrThrow'\n  | 'findMany'\n  | 'findFirst'\n  | 'findFirstOrThrow'\n  | 'create'\n  | 'createMany'\n  | 'createManyAndReturn'\n  | 'update'\n  | 'updateMany'\n  | 'updateManyAndReturn'\n  | 'upsert'\n  | 'delete'\n  | 'deleteMany'\n  | 'executeRaw'\n  | 'queryRaw'\n  | 'aggregate'\n  | 'count'\n  | 'runCommandRaw'\n  | 'findRaw'\n  | 'groupBy'\n\n/**\n * `PrismaClient` proxy available in interactive transactions.\n */\nexport type TransactionClient = Omit<DefaultPrismaClient, runtime.ITXClientDenyList>\n\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;;;;;;;CAUC,GAED;;AAcO,MAAM,gCAAgC,0UAAqC;AAG3E,MAAM,kCAAkC,4UAAuC;AAG/E,MAAM,6BAA6B,uUAAkC;AAGrE,MAAM,kCAAkC,4UAAuC;AAG/E,MAAM,8BAA8B,wUAAmC;AAMvE,MAAM,MAAM,mTAAc;AAC1B,MAAM,QAAQ,kTAAa;AAC3B,MAAM,OAAO,iTAAY;AACzB,MAAM,MAAM,gTAAW;AACvB,MAAM,MAAM,gTAAW;AAQvB,MAAM,UAAU,oTAAe;AAS/B,MAAM,sBAAsB,uTAAkB,CAAC,mBAAmB;AAelE,MAAM,gBAA+B;IAC1C,QAAQ;IACR,QAAQ;AACV;AAeO,MAAM,YAAY;IACvB,QAAQ,sTAAiB,CAAC,MAAM;IAChC,UAAU,sTAAiB,CAAC,QAAQ;IACpC,SAAS,sTAAiB,CAAC,OAAO;AACpC;AAMO,MAAM,SAAS,mTAAc;AAO7B,MAAM,WAAW,qTAAgB;AAOjC,MAAM,UAAU,oTAAe;AAkQ/B,MAAM,YAAY;IACvB,MAAM;IACN,SAAS;IACT,QAAQ;IACR,WAAW;IACX,SAAS;IACT,OAAO;IACP,eAAe;IACf,eAAe;IACf,iBAAiB;IACjB,qBAAqB;IACrB,gBAAgB;IAChB,YAAY;AACd;AAw6BO,MAAM,4BAA4B,2TAAsB,CAAC;IAC9D,cAAc;AAChB;AAKO,MAAM,sBAAsB;IACjC,IAAI;IACJ,OAAO;IACP,UAAU;IACV,MAAM;IACN,QAAQ;IACR,WAAW;IACX,WAAW;AACb;AAKO,MAAM,yBAAyB;IACpC,IAAI;IACJ,QAAQ;IACR,KAAK;IACL,iBAAiB;IACjB,QAAQ;IACR,iBAAiB;IACjB,YAAY;IACZ,WAAW;IACX,WAAW;AACb;AAKO,MAAM,wBAAwB;IACnC,IAAI;IACJ,QAAQ;IACR,UAAU;IACV,SAAS;IACT,UAAU;IACV,UAAU;IACV,UAAU;IACV,cAAc;IACd,aAAa;IACb,UAAU;IACV,YAAY;IACZ,gBAAgB;IAChB,YAAY;IACZ,WAAW;AACb;AAKO,MAAM,2BAA2B;IACtC,IAAI;IACJ,QAAQ;IACR,OAAO;IACP,YAAY;IACZ,QAAQ;IACR,WAAW;IACX,SAAS;IACT,WAAW;IACX,gBAAgB;IAChB,kBAAkB;AACpB;AAKO,MAAM,yBAAyB;IACpC,IAAI;IACJ,aAAa;IACb,MAAM;IACN,SAAS;IACT,WAAW;AACb;AAKO,MAAM,uBAAuB;IAClC,IAAI;IACJ,aAAa;IACb,2BAA2B;IAC3B,iBAAiB;IACjB,gBAAgB;IAChB,aAAa;IACb,WAAW;IACX,eAAe;IACf,cAAc;IACd,YAAY;IACZ,UAAU;IACV,WAAW;IACX,WAAW;AACb;AAKO,MAAM,+BAA+B;IAC1C,IAAI;IACJ,QAAQ;IACR,iBAAiB;IACjB,qBAAqB;IACrB,iBAAiB;IACjB,UAAU;IACV,gBAAgB;IAChB,kBAAkB;IAClB,YAAY;IACZ,YAAY;IACZ,kBAAkB;IAClB,WAAW;IACX,WAAW;AACb;AAKO,MAAM,+BAA+B;IAC1C,IAAI;IACJ,OAAO;IACP,aAAa;IACb,YAAY;IACZ,UAAU;IACV,WAAW;IACX,aAAa;IACb,UAAU;IACV,WAAW;IACX,oBAAoB;IACpB,aAAa;IACb,WAAW;IACX,WAAW;IACX,WAAW;AACb;AAKO,MAAM,iCAAiC;IAC5C,IAAI;IACJ,QAAQ;IACR,WAAW;IACX,QAAQ;IACR,OAAO;IACP,aAAa;IACb,YAAY;IACZ,UAAU;IACV,SAAS;IACT,UAAU;IACV,cAAc;IACd,aAAa;IACb,WAAW;IACX,QAAQ;IACR,WAAW;IACX,SAAS;IACT,aAAa;IACb,WAAW;IACX,WAAW;IACX,WAAW;AACb;AAKO,MAAM,qCAAqC;IAChD,IAAI;IACJ,aAAa;IACb,MAAM;IACN,UAAU;IACV,aAAa;IACb,YAAY;IACZ,aAAa;IACb,SAAS;IACT,cAAc;AAChB;AAKO,MAAM,gCAAgC;IAC3C,IAAI;IACJ,aAAa;IACb,aAAa;IACb,YAAY;IACZ,aAAa;IACb,WAAW;IACX,cAAc;IACd,YAAY;IACZ,UAAU;IACV,mBAAmB;IACnB,oBAAoB;IACpB,WAAW;AACb;AAKO,MAAM,4BAA4B;IACvC,IAAI;IACJ,QAAQ;IACR,QAAQ;IACR,WAAW;IACX,SAAS;IACT,WAAW;IACX,WAAW;IACX,WAAW;AACb;AAKO,MAAM,YAAY;IACvB,KAAK;IACL,MAAM;AACR;AAKO,MAAM,aAAa;IACxB,OAAO;IACP,MAAM;AACR;AAoDO,MAAM,kBAAkB,uTAAkB,CAAC,eAAe"}},
    {"offset": {"line": 413, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/enums.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n* This file exports all enum related types from the schema.\n*\n* ðŸŸ¢ You can import this file directly.\n*/\n\n\n\n// This file is empty because there are no enums in the schema.\nexport {}\n"],"names":[],"mappings":"AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;AAIA,GAIA,+DAA+D"}},
    {"offset": {"line": 426, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/client.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n * This file should be your main import to use Prisma. Through it you get access to all the models, enums, and input types.\n * If you're looking for something you can import in the client-side of your application, please refer to the `browser.ts` file instead.\n *\n * ðŸŸ¢ You can import this file directly.\n */\n\nimport * as process from 'node:process'\nimport * as path from 'node:path'\nimport { fileURLToPath } from 'node:url'\nglobalThis['__dirname'] = path.dirname(fileURLToPath(import.meta.url))\n\nimport * as runtime from \"@prisma/client/runtime/client\"\nimport * as $Enums from \"./enums\"\nimport * as $Class from \"./internal/class\"\nimport * as Prisma from \"./internal/prismaNamespace\"\n\nexport * as $Enums from './enums'\nexport * from \"./enums\"\n/**\n * ## Prisma Client\n * \n * Type-safe database client for TypeScript\n * @example\n * ```\n * const prisma = new PrismaClient()\n * // Fetch zero or more Users\n * const users = await prisma.user.findMany()\n * ```\n * \n * Read more in our [docs](https://pris.ly/d/client).\n */\nexport const PrismaClient = $Class.getPrismaClientClass()\nexport type PrismaClient<LogOpts extends Prisma.LogLevel = never, OmitOpts extends Prisma.PrismaClientOptions[\"omit\"] = Prisma.PrismaClientOptions[\"omit\"], ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs> = $Class.PrismaClient<LogOpts, OmitOpts, ExtArgs>\nexport { Prisma }\n\n/**\n * Model User\n * \n */\nexport type User = Prisma.UserModel\n/**\n * Model Profile\n * \n */\nexport type Profile = Prisma.ProfileModel\n/**\n * Model Resume\n * \n */\nexport type Resume = Prisma.ResumeModel\n/**\n * Model Interview\n * \n */\nexport type Interview = Prisma.InterviewModel\n/**\n * Model Message\n * \n */\nexport type Message = Prisma.MessageModel\n/**\n * Model Score\n * \n */\nexport type Score = Prisma.ScoreModel\n/**\n * Model UserAnalytics\n * \n */\nexport type UserAnalytics = Prisma.UserAnalyticsModel\n/**\n * Model CodingProblem\n * \n */\nexport type CodingProblem = Prisma.CodingProblemModel\n/**\n * Model CodingChallenge\n * \n */\nexport type CodingChallenge = Prisma.CodingChallengeModel\n/**\n * Model ChallengeSubmission\n * \n */\nexport type ChallengeSubmission = Prisma.ChallengeSubmissionModel\n/**\n * Model ChallengeScore\n * \n */\nexport type ChallengeScore = Prisma.ChallengeScoreModel\n/**\n * Model CodingTest\n * \n */\nexport type CodingTest = Prisma.CodingTestModel\n"],"names":[],"mappings":"AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;;CAKC;;;;AAGD;AACA;AAKA;AACA;AAEA;;;;;;;;AAPA,UAAU,CAAC,YAAY,GAAG,4HAAY,CAAC,IAAA,gIAAa,EAAC,8BAAY,GAAG;;;;;AAsB7D,MAAM,eAAe,kPAA2B"}},
    {"offset": {"line": 462, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/prisma.ts"],"sourcesContent":["import { PrismaClient } from \"../generated/prisma/client\";\nimport { PrismaLibSql } from \"@prisma/adapter-libsql\";\n\nconst adapter = new PrismaLibSql({\n  url: process.env.DATABASE_URL || \"file:./dev.db\",\n});\n\nconst globalForPrisma = globalThis as unknown as {\n  prisma: PrismaClient | undefined;\n};\n\nexport const prisma = globalForPrisma.prisma ?? new PrismaClient({ adapter });\n\nif (process.env.NODE_ENV !== \"production\") globalForPrisma.prisma = prisma;\n\nexport default prisma;\n"],"names":[],"mappings":";;;;;;AAAA;AACA;;;;;;;AAEA,MAAM,UAAU,IAAI,kQAAY,CAAC;IAC/B,KAAK,QAAQ,GAAG,CAAC,YAAY,IAAI;AACnC;AAEA,MAAM,kBAAkB;AAIjB,MAAM,SAAS,gBAAgB,MAAM,IAAI,IAAI,+OAAY,CAAC;IAAE;AAAQ;AAE3E,wCAA2C,gBAAgB,MAAM,GAAG;uCAErD"}},
    {"offset": {"line": 492, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/auth.ts"],"sourcesContent":["import NextAuth from \"next-auth\";\nimport Credentials from \"next-auth/providers/credentials\";\nimport bcrypt from \"bcryptjs\";\nimport { prisma } from \"./prisma\";\n\nexport const { handlers, signIn, signOut, auth } = NextAuth({\n  providers: [\n    Credentials({\n      name: \"credentials\",\n      credentials: {\n        email: { label: \"Email\", type: \"email\" },\n        password: { label: \"Password\", type: \"password\" },\n      },\n      async authorize(credentials) {\n        if (!credentials?.email || !credentials?.password) {\n          return null;\n        }\n\n        const email = credentials.email as string;\n        const password = credentials.password as string;\n\n        const user = await prisma.user.findUnique({\n          where: { email },\n        });\n\n        if (!user) {\n          return null;\n        }\n\n        const isPasswordValid = await bcrypt.compare(password, user.password);\n\n        if (!isPasswordValid) {\n          return null;\n        }\n\n        return {\n          id: user.id,\n          email: user.email,\n          name: user.name,\n          image: user.avatar,\n        };\n      },\n    }),\n  ],\n  callbacks: {\n    async jwt({ token, user }) {\n      if (user) {\n        token.id = user.id;\n      }\n      return token;\n    },\n    async session({ session, token }) {\n      if (session.user) {\n        session.user.id = token.id as string;\n      }\n      return session;\n    },\n  },\n  pages: {\n    signIn: \"/login\",\n  },\n  session: {\n    strategy: \"jwt\",\n  },\n});\n"],"names":[],"mappings":";;;;;;;;;;AAAA;AACA;AAAA;AACA;AACA;;;;;;;;;AAEO,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,OAAO,EAAE,IAAI,EAAE,GAAG,IAAA,2OAAQ,EAAC;IAC1D,WAAW;QACT,IAAA,gPAAW,EAAC;YACV,MAAM;YACN,aAAa;gBACX,OAAO;oBAAE,OAAO;oBAAS,MAAM;gBAAQ;gBACvC,UAAU;oBAAE,OAAO;oBAAY,MAAM;gBAAW;YAClD;YACA,MAAM,WAAU,WAAW;gBACzB,IAAI,CAAC,aAAa,SAAS,CAAC,aAAa,UAAU;oBACjD,OAAO;gBACT;gBAEA,MAAM,QAAQ,YAAY,KAAK;gBAC/B,MAAM,WAAW,YAAY,QAAQ;gBAErC,MAAM,OAAO,MAAM,yMAAM,CAAC,IAAI,CAAC,UAAU,CAAC;oBACxC,OAAO;wBAAE;oBAAM;gBACjB;gBAEA,IAAI,CAAC,MAAM;oBACT,OAAO;gBACT;gBAEA,MAAM,kBAAkB,MAAM,uNAAM,CAAC,OAAO,CAAC,UAAU,KAAK,QAAQ;gBAEpE,IAAI,CAAC,iBAAiB;oBACpB,OAAO;gBACT;gBAEA,OAAO;oBACL,IAAI,KAAK,EAAE;oBACX,OAAO,KAAK,KAAK;oBACjB,MAAM,KAAK,IAAI;oBACf,OAAO,KAAK,MAAM;gBACpB;YACF;QACF;KACD;IACD,WAAW;QACT,MAAM,KAAI,EAAE,KAAK,EAAE,IAAI,EAAE;YACvB,IAAI,MAAM;gBACR,MAAM,EAAE,GAAG,KAAK,EAAE;YACpB;YACA,OAAO;QACT;QACA,MAAM,SAAQ,EAAE,OAAO,EAAE,KAAK,EAAE;YAC9B,IAAI,QAAQ,IAAI,EAAE;gBAChB,QAAQ,IAAI,CAAC,EAAE,GAAG,MAAM,EAAE;YAC5B;YACA,OAAO;QACT;IACF;IACA,OAAO;QACL,QAAQ;IACV;IACA,SAAS;QACP,UAAU;IACZ;AACF"}},
    {"offset": {"line": 582, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/openai.ts"],"sourcesContent":["import OpenAI from \"openai\";\n\nexport const openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n});\n\nexport default openai;\n"],"names":[],"mappings":";;;;;;AAAA;AAAA;;AAEO,MAAM,SAAS,IAAI,4PAAM,CAAC;IAC/B,QAAQ,QAAQ,GAAG,CAAC,cAAc;AACpC;uCAEe"}},
    {"offset": {"line": 601, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/analytics/performance-analytics.ts"],"sourcesContent":["/**\n * Performance Analytics Library\n *\n * Core analytics calculations for user performance tracking.\n * Tracks score progression, identifies weak areas, and generates insights.\n */\n\nimport { prisma } from \"@/lib/prisma\";\n\n// Score dimension type for type-safe access\ntype ScoreDimension =\n  | \"requirementsClarification\"\n  | \"highLevelDesign\"\n  | \"detailedDesign\"\n  | \"scalability\"\n  | \"tradeoffs\"\n  | \"communication\";\n\n// Helper to get score value from dimension key\nfunction getScoreValue(\n  score: {\n    requirementsClarification: number;\n    highLevelDesign: number;\n    detailedDesign: number;\n    scalability: number;\n    tradeoffs: number;\n    communication: number;\n  },\n  dimension: ScoreDimension\n): number {\n  return score[dimension];\n}\n\n// Types\nexport interface ScoreDataPoint {\n  date: string;\n  overallScore: number;\n  passStatus: boolean;\n  topic: string;\n  interviewId: string;\n}\n\nexport interface DimensionMetrics {\n  avgScore: number;\n  trend: \"improving\" | \"stable\" | \"declining\";\n  isWeak: boolean; // Below 2.5\n  isStrong: boolean; // Above 3.0\n  recentScores: number[];\n}\n\nexport interface WeakArea {\n  dimension: string;\n  avgScore: number;\n  occurrences: number;\n  lastScore: number;\n  trend: \"improving\" | \"stable\" | \"declining\";\n}\n\nexport interface PerformanceMetrics {\n  overall: {\n    totalInterviews: number;\n    completedInterviews: number;\n    avgScore: number;\n    passRate: number;\n    scoreTrend: \"improving\" | \"stable\" | \"declining\";\n  };\n  dimensions: {\n    [key: string]: DimensionMetrics;\n  };\n  recentScores: ScoreDataPoint[];\n  insights: string[];\n  recommendations: string[];\n}\n\n// Dimension names mapping\nconst DIMENSION_NAMES: Record<string, string> = {\n  requirementsClarification: \"Requirements Clarification\",\n  highLevelDesign: \"High-Level Design\",\n  detailedDesign: \"Detailed Design\",\n  scalability: \"Scalability\",\n  tradeoffs: \"Trade-offs\",\n  communication: \"Communication\",\n};\n\nconst DIMENSION_KEYS = Object.keys(DIMENSION_NAMES);\n\n/**\n * Calculate trend from an array of scores (oldest to newest)\n */\nexport function calculateTrend(scores: number[]): \"improving\" | \"stable\" | \"declining\" {\n  if (scores.length < 3) return \"stable\";\n\n  // Use linear regression to determine trend\n  const n = scores.length;\n  let sumX = 0, sumY = 0, sumXY = 0, sumXX = 0;\n\n  for (let i = 0; i < n; i++) {\n    sumX += i;\n    sumY += scores[i];\n    sumXY += i * scores[i];\n    sumXX += i * i;\n  }\n\n  const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);\n\n  // Threshold for trend detection\n  if (slope > 0.1) return \"improving\";\n  if (slope < -0.1) return \"declining\";\n  return \"stable\";\n}\n\n/**\n * Get score progression over time for a user\n */\nexport async function getScoreProgression(\n  userId: string,\n  dimension?: string,\n  limit: number = 20\n): Promise<ScoreDataPoint[]> {\n  const interviews = await prisma.interview.findMany({\n    where: {\n      userId,\n      status: \"completed\",\n    },\n    orderBy: { endedAt: \"asc\" },\n    take: limit,\n    include: {\n      score: true,\n    },\n  });\n\n  return interviews\n    .filter((i) => i.score)\n    .map((interview) => ({\n      date: interview.endedAt?.toISOString() || interview.createdAt.toISOString(),\n      overallScore: dimension\n        ? getScoreValue(interview.score!, dimension as ScoreDimension)\n        : interview.score!.overallScore,\n      passStatus: interview.score!.passStatus,\n      topic: interview.topic,\n      interviewId: interview.id,\n    }));\n}\n\n/**\n * Identify weak areas for a user\n */\nexport async function identifyWeakAreas(userId: string, limit: number = 10): Promise<WeakArea[]> {\n  const interviews = await prisma.interview.findMany({\n    where: {\n      userId,\n      status: \"completed\",\n    },\n    orderBy: { endedAt: \"desc\" },\n    take: limit,\n    include: {\n      score: true,\n    },\n  });\n\n  const dimensionScores: Record<string, number[]> = {};\n\n  // Initialize arrays for each dimension\n  DIMENSION_KEYS.forEach((key) => {\n    dimensionScores[key] = [];\n  });\n\n  // Collect scores for each dimension\n  for (const interview of interviews) {\n    if (!interview.score) continue;\n\n    DIMENSION_KEYS.forEach((key) => {\n      const score = getScoreValue(interview.score!, key as ScoreDimension);\n      if (score !== undefined) {\n        dimensionScores[key].push(score);\n      }\n    });\n  }\n\n  // Calculate weak areas (avg < 2.5)\n  const weakAreas: WeakArea[] = [];\n\n  for (const [dimension, scores] of Object.entries(dimensionScores)) {\n    if (scores.length === 0) continue;\n\n    const avgScore = scores.reduce((a, b) => a + b, 0) / scores.length;\n\n    if (avgScore < 2.5) {\n      weakAreas.push({\n        dimension: DIMENSION_NAMES[dimension] || dimension,\n        avgScore: Number(avgScore.toFixed(2)),\n        occurrences: scores.filter((s) => s < 2.5).length,\n        lastScore: scores[0], // Most recent\n        trend: calculateTrend(scores.reverse()), // Oldest to newest for trend\n      });\n    }\n  }\n\n  // Sort by average score (weakest first)\n  return weakAreas.sort((a, b) => a.avgScore - b.avgScore);\n}\n\n/**\n * Generate insights based on performance metrics\n */\nexport function generateInsights(metrics: PerformanceMetrics): string[] {\n  const insights: string[] = [];\n\n  // Overall performance insights\n  if (metrics.overall.completedInterviews === 0) {\n    insights.push(\"Complete your first interview to start tracking progress!\");\n    return insights;\n  }\n\n  if (metrics.overall.avgScore >= 3.0) {\n    insights.push(\"Your overall performance is strong. You're ready for senior-level interviews.\");\n  } else if (metrics.overall.avgScore >= 2.5) {\n    insights.push(\"You're performing at a passing level. Focus on your weak areas to improve.\");\n  } else {\n    insights.push(\"Your scores indicate room for improvement. Consider more practice sessions.\");\n  }\n\n  // Pass rate insights\n  if (metrics.overall.passRate >= 80) {\n    insights.push(`Excellent pass rate of ${metrics.overall.passRate.toFixed(0)}%!`);\n  } else if (metrics.overall.passRate >= 50) {\n    insights.push(`Your pass rate is ${metrics.overall.passRate.toFixed(0)}%. Aim for consistency.`);\n  } else if (metrics.overall.completedInterviews >= 3) {\n    insights.push(`Pass rate of ${metrics.overall.passRate.toFixed(0)}% needs attention. Review fundamentals.`);\n  }\n\n  // Trend insights\n  if (metrics.overall.scoreTrend === \"improving\") {\n    insights.push(\"Your scores are trending upward. Keep up the great work!\");\n  } else if (metrics.overall.scoreTrend === \"declining\") {\n    insights.push(\"Your recent scores have declined. Consider reviewing basics.\");\n  }\n\n  // Dimension-specific insights\n  const weakDimensions = Object.entries(metrics.dimensions)\n    .filter(([, m]) => m.isWeak)\n    .map(([key]) => DIMENSION_NAMES[key] || key);\n\n  if (weakDimensions.length > 0) {\n    insights.push(`Focus areas: ${weakDimensions.join(\", \")}`);\n  }\n\n  const strongDimensions = Object.entries(metrics.dimensions)\n    .filter(([, m]) => m.isStrong)\n    .map(([key]) => DIMENSION_NAMES[key] || key);\n\n  if (strongDimensions.length > 0) {\n    insights.push(`Strong areas: ${strongDimensions.join(\", \")}`);\n  }\n\n  return insights;\n}\n\n/**\n * Generate recommendations based on performance\n */\nexport function generateRecommendations(metrics: PerformanceMetrics): string[] {\n  const recommendations: string[] = [];\n\n  if (metrics.overall.completedInterviews === 0) {\n    recommendations.push(\"Start with an easy difficulty interview to build confidence.\");\n    return recommendations;\n  }\n\n  // Weak dimension recommendations\n  const weakDimensions = Object.entries(metrics.dimensions)\n    .filter(([, m]) => m.isWeak)\n    .sort((a, b) => a[1].avgScore - b[1].avgScore);\n\n  for (const [key, dimMetrics] of weakDimensions.slice(0, 2)) {\n    const name = DIMENSION_NAMES[key] || key;\n\n    switch (key) {\n      case \"requirementsClarification\":\n        recommendations.push(\n          `Practice asking clarifying questions about scale, users, and constraints.`\n        );\n        break;\n      case \"highLevelDesign\":\n        recommendations.push(\n          `Study common system design patterns and practice drawing architecture diagrams.`\n        );\n        break;\n      case \"detailedDesign\":\n        recommendations.push(\n          `Review data modeling, API design, and dive deeper into component internals.`\n        );\n        break;\n      case \"scalability\":\n        recommendations.push(\n          `Study caching, sharding, load balancing, and horizontal scaling strategies.`\n        );\n        break;\n      case \"tradeoffs\":\n        recommendations.push(\n          `Practice discussing CAP theorem, consistency vs availability, and cost tradeoffs.`\n        );\n        break;\n      case \"communication\":\n        recommendations.push(\n          `Practice explaining your thought process clearly and structuring your responses.`\n        );\n        break;\n      default:\n        recommendations.push(`Focus on improving ${name} (current avg: ${dimMetrics.avgScore.toFixed(1)}).`);\n    }\n  }\n\n  // Interview frequency recommendation\n  if (metrics.overall.completedInterviews < 5) {\n    recommendations.push(\"Complete at least 5 interviews to establish reliable patterns.\");\n  }\n\n  // Difficulty recommendation\n  if (metrics.overall.avgScore >= 3.0 && metrics.overall.passRate >= 70) {\n    recommendations.push(\"Consider increasing difficulty to challenge yourself further.\");\n  } else if (metrics.overall.avgScore < 2.0) {\n    recommendations.push(\"Try easier interviews to build foundational knowledge.\");\n  }\n\n  return recommendations;\n}\n\n/**\n * Calculate comprehensive performance metrics for a user\n */\nexport async function calculatePerformanceMetrics(\n  userId: string,\n  limit: number = 20\n): Promise<PerformanceMetrics> {\n  // Fetch interview data\n  const [totalCount, completedInterviews] = await Promise.all([\n    prisma.interview.count({\n      where: { userId },\n    }),\n    prisma.interview.findMany({\n      where: {\n        userId,\n        status: \"completed\",\n      },\n      orderBy: { endedAt: \"desc\" },\n      take: limit,\n      include: {\n        score: true,\n      },\n    }),\n  ]);\n\n  const completedCount = completedInterviews.length;\n  const interviewsWithScores = completedInterviews.filter((i) => i.score);\n\n  // Calculate overall metrics\n  let avgScore = 0;\n  let passCount = 0;\n  const overallScores: number[] = [];\n\n  for (const interview of interviewsWithScores) {\n    avgScore += interview.score!.overallScore;\n    if (interview.score!.passStatus) passCount++;\n    overallScores.push(interview.score!.overallScore);\n  }\n\n  if (interviewsWithScores.length > 0) {\n    avgScore /= interviewsWithScores.length;\n  }\n\n  const passRate = interviewsWithScores.length > 0\n    ? (passCount / interviewsWithScores.length) * 100\n    : 0;\n\n  // Calculate dimension metrics\n  const dimensionMetrics: Record<string, DimensionMetrics> = {};\n\n  for (const key of DIMENSION_KEYS) {\n    const scores: number[] = [];\n\n    for (const interview of interviewsWithScores) {\n      const score = getScoreValue(interview.score!, key as ScoreDimension);\n      if (score !== undefined) {\n        scores.push(score);\n      }\n    }\n\n    if (scores.length > 0) {\n      const dimAvg = scores.reduce((a, b) => a + b, 0) / scores.length;\n      dimensionMetrics[key] = {\n        avgScore: Number(dimAvg.toFixed(2)),\n        trend: calculateTrend(scores.reverse()), // Oldest to newest\n        isWeak: dimAvg < 2.5,\n        isStrong: dimAvg >= 3.0,\n        recentScores: scores.slice(-5),\n      };\n    } else {\n      dimensionMetrics[key] = {\n        avgScore: 0,\n        trend: \"stable\",\n        isWeak: false,\n        isStrong: false,\n        recentScores: [],\n      };\n    }\n  }\n\n  // Build recent scores\n  const recentScores: ScoreDataPoint[] = interviewsWithScores.map((i) => ({\n    date: i.endedAt?.toISOString() || i.createdAt.toISOString(),\n    overallScore: i.score!.overallScore,\n    passStatus: i.score!.passStatus,\n    topic: i.topic,\n    interviewId: i.id,\n  }));\n\n  // Build metrics object\n  const metrics: PerformanceMetrics = {\n    overall: {\n      totalInterviews: totalCount,\n      completedInterviews: completedCount,\n      avgScore: Number(avgScore.toFixed(2)),\n      passRate: Number(passRate.toFixed(1)),\n      scoreTrend: calculateTrend(overallScores.reverse()),\n    },\n    dimensions: dimensionMetrics,\n    recentScores,\n    insights: [],\n    recommendations: [],\n  };\n\n  // Generate insights and recommendations\n  metrics.insights = generateInsights(metrics);\n  metrics.recommendations = generateRecommendations(metrics);\n\n  return metrics;\n}\n\n/**\n * Update cached user analytics after an interview\n */\nexport async function updateUserAnalyticsCache(userId: string): Promise<void> {\n  const metrics = await calculatePerformanceMetrics(userId, 50);\n\n  // Extract weak and strong dimensions\n  const weakDimensions = Object.entries(metrics.dimensions)\n    .filter(([, m]) => m.isWeak)\n    .map(([key]) => key);\n\n  const strongDimensions = Object.entries(metrics.dimensions)\n    .filter(([, m]) => m.isStrong)\n    .map(([key]) => key);\n\n  // Calculate topic stats\n  const topicInterviews = await prisma.interview.findMany({\n    where: { userId, status: \"completed\" },\n    include: { score: true },\n  });\n\n  const topicStats: Record<string, { count: number; totalScore: number; passCount: number }> = {};\n\n  for (const interview of topicInterviews) {\n    if (!interview.score) continue;\n\n    if (!topicStats[interview.topic]) {\n      topicStats[interview.topic] = { count: 0, totalScore: 0, passCount: 0 };\n    }\n\n    topicStats[interview.topic].count++;\n    topicStats[interview.topic].totalScore += interview.score.overallScore;\n    if (interview.score.passStatus) {\n      topicStats[interview.topic].passCount++;\n    }\n  }\n\n  // Convert to final format\n  const finalTopicStats: Record<string, { count: number; avgScore: number; passRate: number }> = {};\n  for (const [topic, stats] of Object.entries(topicStats)) {\n    finalTopicStats[topic] = {\n      count: stats.count,\n      avgScore: Number((stats.totalScore / stats.count).toFixed(2)),\n      passRate: Number(((stats.passCount / stats.count) * 100).toFixed(1)),\n    };\n  }\n\n  // Upsert analytics record\n  await prisma.userAnalytics.upsert({\n    where: { userId },\n    create: {\n      userId,\n      totalInterviews: metrics.overall.totalInterviews,\n      completedInterviews: metrics.overall.completedInterviews,\n      avgOverallScore: metrics.overall.avgScore,\n      passRate: metrics.overall.passRate,\n      weakDimensions: JSON.stringify(weakDimensions),\n      strongDimensions: JSON.stringify(strongDimensions),\n      topicStats: JSON.stringify(finalTopicStats),\n      scoreTrend: metrics.overall.scoreTrend,\n      lastCalculatedAt: new Date(),\n    },\n    update: {\n      totalInterviews: metrics.overall.totalInterviews,\n      completedInterviews: metrics.overall.completedInterviews,\n      avgOverallScore: metrics.overall.avgScore,\n      passRate: metrics.overall.passRate,\n      weakDimensions: JSON.stringify(weakDimensions),\n      strongDimensions: JSON.stringify(strongDimensions),\n      topicStats: JSON.stringify(finalTopicStats),\n      scoreTrend: metrics.overall.scoreTrend,\n      lastCalculatedAt: new Date(),\n    },\n  });\n}\n\n/**\n * Get performance category based on average score\n */\nexport function getPerformanceCategory(\n  avgScore: number\n): \"struggling\" | \"developing\" | \"proficient\" | \"excelling\" {\n  if (avgScore < 2.0) return \"struggling\";\n  if (avgScore < 2.5) return \"developing\";\n  if (avgScore < 3.0) return \"proficient\";\n  return \"excelling\";\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAAA;;;;;CAKC,GAED;;;;;;AAWA,+CAA+C;AAC/C,SAAS,cACP,KAOC,EACD,SAAyB;IAEzB,OAAO,KAAK,CAAC,UAAU;AACzB;AA2CA,0BAA0B;AAC1B,MAAM,kBAA0C;IAC9C,2BAA2B;IAC3B,iBAAiB;IACjB,gBAAgB;IAChB,aAAa;IACb,WAAW;IACX,eAAe;AACjB;AAEA,MAAM,iBAAiB,OAAO,IAAI,CAAC;AAK5B,SAAS,eAAe,MAAgB;IAC7C,IAAI,OAAO,MAAM,GAAG,GAAG,OAAO;IAE9B,2CAA2C;IAC3C,MAAM,IAAI,OAAO,MAAM;IACvB,IAAI,OAAO,GAAG,OAAO,GAAG,QAAQ,GAAG,QAAQ;IAE3C,IAAK,IAAI,IAAI,GAAG,IAAI,GAAG,IAAK;QAC1B,QAAQ;QACR,QAAQ,MAAM,CAAC,EAAE;QACjB,SAAS,IAAI,MAAM,CAAC,EAAE;QACtB,SAAS,IAAI;IACf;IAEA,MAAM,QAAQ,CAAC,IAAI,QAAQ,OAAO,IAAI,IAAI,CAAC,IAAI,QAAQ,OAAO,IAAI;IAElE,gCAAgC;IAChC,IAAI,QAAQ,KAAK,OAAO;IACxB,IAAI,QAAQ,CAAC,KAAK,OAAO;IACzB,OAAO;AACT;AAKO,eAAe,oBACpB,MAAc,EACd,SAAkB,EAClB,QAAgB,EAAE;IAElB,MAAM,aAAa,MAAM,yMAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;QACjD,OAAO;YACL;YACA,QAAQ;QACV;QACA,SAAS;YAAE,SAAS;QAAM;QAC1B,MAAM;QACN,SAAS;YACP,OAAO;QACT;IACF;IAEA,OAAO,WACJ,MAAM,CAAC,CAAC,IAAM,EAAE,KAAK,EACrB,GAAG,CAAC,CAAC,YAAc,CAAC;YACnB,MAAM,UAAU,OAAO,EAAE,iBAAiB,UAAU,SAAS,CAAC,WAAW;YACzE,cAAc,YACV,cAAc,UAAU,KAAK,EAAG,aAChC,UAAU,KAAK,CAAE,YAAY;YACjC,YAAY,UAAU,KAAK,CAAE,UAAU;YACvC,OAAO,UAAU,KAAK;YACtB,aAAa,UAAU,EAAE;QAC3B,CAAC;AACL;AAKO,eAAe,kBAAkB,MAAc,EAAE,QAAgB,EAAE;IACxE,MAAM,aAAa,MAAM,yMAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;QACjD,OAAO;YACL;YACA,QAAQ;QACV;QACA,SAAS;YAAE,SAAS;QAAO;QAC3B,MAAM;QACN,SAAS;YACP,OAAO;QACT;IACF;IAEA,MAAM,kBAA4C,CAAC;IAEnD,uCAAuC;IACvC,eAAe,OAAO,CAAC,CAAC;QACtB,eAAe,CAAC,IAAI,GAAG,EAAE;IAC3B;IAEA,oCAAoC;IACpC,KAAK,MAAM,aAAa,WAAY;QAClC,IAAI,CAAC,UAAU,KAAK,EAAE;QAEtB,eAAe,OAAO,CAAC,CAAC;YACtB,MAAM,QAAQ,cAAc,UAAU,KAAK,EAAG;YAC9C,IAAI,UAAU,WAAW;gBACvB,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC;YAC5B;QACF;IACF;IAEA,mCAAmC;IACnC,MAAM,YAAwB,EAAE;IAEhC,KAAK,MAAM,CAAC,WAAW,OAAO,IAAI,OAAO,OAAO,CAAC,iBAAkB;QACjE,IAAI,OAAO,MAAM,KAAK,GAAG;QAEzB,MAAM,WAAW,OAAO,MAAM,CAAC,CAAC,GAAG,IAAM,IAAI,GAAG,KAAK,OAAO,MAAM;QAElE,IAAI,WAAW,KAAK;YAClB,UAAU,IAAI,CAAC;gBACb,WAAW,eAAe,CAAC,UAAU,IAAI;gBACzC,UAAU,OAAO,SAAS,OAAO,CAAC;gBAClC,aAAa,OAAO,MAAM,CAAC,CAAC,IAAM,IAAI,KAAK,MAAM;gBACjD,WAAW,MAAM,CAAC,EAAE;gBACpB,OAAO,eAAe,OAAO,OAAO;YACtC;QACF;IACF;IAEA,wCAAwC;IACxC,OAAO,UAAU,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,QAAQ,GAAG,EAAE,QAAQ;AACzD;AAKO,SAAS,iBAAiB,OAA2B;IAC1D,MAAM,WAAqB,EAAE;IAE7B,+BAA+B;IAC/B,IAAI,QAAQ,OAAO,CAAC,mBAAmB,KAAK,GAAG;QAC7C,SAAS,IAAI,CAAC;QACd,OAAO;IACT;IAEA,IAAI,QAAQ,OAAO,CAAC,QAAQ,IAAI,KAAK;QACnC,SAAS,IAAI,CAAC;IAChB,OAAO,IAAI,QAAQ,OAAO,CAAC,QAAQ,IAAI,KAAK;QAC1C,SAAS,IAAI,CAAC;IAChB,OAAO;QACL,SAAS,IAAI,CAAC;IAChB;IAEA,qBAAqB;IACrB,IAAI,QAAQ,OAAO,CAAC,QAAQ,IAAI,IAAI;QAClC,SAAS,IAAI,CAAC,CAAC,uBAAuB,EAAE,QAAQ,OAAO,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAE,CAAC;IACjF,OAAO,IAAI,QAAQ,OAAO,CAAC,QAAQ,IAAI,IAAI;QACzC,SAAS,IAAI,CAAC,CAAC,kBAAkB,EAAE,QAAQ,OAAO,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,uBAAuB,CAAC;IACjG,OAAO,IAAI,QAAQ,OAAO,CAAC,mBAAmB,IAAI,GAAG;QACnD,SAAS,IAAI,CAAC,CAAC,aAAa,EAAE,QAAQ,OAAO,CAAC,QAAQ,CAAC,OAAO,CAAC,GAAG,uCAAuC,CAAC;IAC5G;IAEA,iBAAiB;IACjB,IAAI,QAAQ,OAAO,CAAC,UAAU,KAAK,aAAa;QAC9C,SAAS,IAAI,CAAC;IAChB,OAAO,IAAI,QAAQ,OAAO,CAAC,UAAU,KAAK,aAAa;QACrD,SAAS,IAAI,CAAC;IAChB;IAEA,8BAA8B;IAC9B,MAAM,iBAAiB,OAAO,OAAO,CAAC,QAAQ,UAAU,EACrD,MAAM,CAAC,CAAC,GAAG,EAAE,GAAK,EAAE,MAAM,EAC1B,GAAG,CAAC,CAAC,CAAC,IAAI,GAAK,eAAe,CAAC,IAAI,IAAI;IAE1C,IAAI,eAAe,MAAM,GAAG,GAAG;QAC7B,SAAS,IAAI,CAAC,CAAC,aAAa,EAAE,eAAe,IAAI,CAAC,OAAO;IAC3D;IAEA,MAAM,mBAAmB,OAAO,OAAO,CAAC,QAAQ,UAAU,EACvD,MAAM,CAAC,CAAC,GAAG,EAAE,GAAK,EAAE,QAAQ,EAC5B,GAAG,CAAC,CAAC,CAAC,IAAI,GAAK,eAAe,CAAC,IAAI,IAAI;IAE1C,IAAI,iBAAiB,MAAM,GAAG,GAAG;QAC/B,SAAS,IAAI,CAAC,CAAC,cAAc,EAAE,iBAAiB,IAAI,CAAC,OAAO;IAC9D;IAEA,OAAO;AACT;AAKO,SAAS,wBAAwB,OAA2B;IACjE,MAAM,kBAA4B,EAAE;IAEpC,IAAI,QAAQ,OAAO,CAAC,mBAAmB,KAAK,GAAG;QAC7C,gBAAgB,IAAI,CAAC;QACrB,OAAO;IACT;IAEA,iCAAiC;IACjC,MAAM,iBAAiB,OAAO,OAAO,CAAC,QAAQ,UAAU,EACrD,MAAM,CAAC,CAAC,GAAG,EAAE,GAAK,EAAE,MAAM,EAC1B,IAAI,CAAC,CAAC,GAAG,IAAM,CAAC,CAAC,EAAE,CAAC,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,QAAQ;IAE/C,KAAK,MAAM,CAAC,KAAK,WAAW,IAAI,eAAe,KAAK,CAAC,GAAG,GAAI;QAC1D,MAAM,OAAO,eAAe,CAAC,IAAI,IAAI;QAErC,OAAQ;YACN,KAAK;gBACH,gBAAgB,IAAI,CAClB,CAAC,yEAAyE,CAAC;gBAE7E;YACF,KAAK;gBACH,gBAAgB,IAAI,CAClB,CAAC,+EAA+E,CAAC;gBAEnF;YACF,KAAK;gBACH,gBAAgB,IAAI,CAClB,CAAC,2EAA2E,CAAC;gBAE/E;YACF,KAAK;gBACH,gBAAgB,IAAI,CAClB,CAAC,2EAA2E,CAAC;gBAE/E;YACF,KAAK;gBACH,gBAAgB,IAAI,CAClB,CAAC,iFAAiF,CAAC;gBAErF;YACF,KAAK;gBACH,gBAAgB,IAAI,CAClB,CAAC,gFAAgF,CAAC;gBAEpF;YACF;gBACE,gBAAgB,IAAI,CAAC,CAAC,mBAAmB,EAAE,KAAK,eAAe,EAAE,WAAW,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAE,CAAC;QACvG;IACF;IAEA,qCAAqC;IACrC,IAAI,QAAQ,OAAO,CAAC,mBAAmB,GAAG,GAAG;QAC3C,gBAAgB,IAAI,CAAC;IACvB;IAEA,4BAA4B;IAC5B,IAAI,QAAQ,OAAO,CAAC,QAAQ,IAAI,OAAO,QAAQ,OAAO,CAAC,QAAQ,IAAI,IAAI;QACrE,gBAAgB,IAAI,CAAC;IACvB,OAAO,IAAI,QAAQ,OAAO,CAAC,QAAQ,GAAG,KAAK;QACzC,gBAAgB,IAAI,CAAC;IACvB;IAEA,OAAO;AACT;AAKO,eAAe,4BACpB,MAAc,EACd,QAAgB,EAAE;IAElB,uBAAuB;IACvB,MAAM,CAAC,YAAY,oBAAoB,GAAG,MAAM,QAAQ,GAAG,CAAC;QAC1D,yMAAM,CAAC,SAAS,CAAC,KAAK,CAAC;YACrB,OAAO;gBAAE;YAAO;QAClB;QACA,yMAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;YACxB,OAAO;gBACL;gBACA,QAAQ;YACV;YACA,SAAS;gBAAE,SAAS;YAAO;YAC3B,MAAM;YACN,SAAS;gBACP,OAAO;YACT;QACF;KACD;IAED,MAAM,iBAAiB,oBAAoB,MAAM;IACjD,MAAM,uBAAuB,oBAAoB,MAAM,CAAC,CAAC,IAAM,EAAE,KAAK;IAEtE,4BAA4B;IAC5B,IAAI,WAAW;IACf,IAAI,YAAY;IAChB,MAAM,gBAA0B,EAAE;IAElC,KAAK,MAAM,aAAa,qBAAsB;QAC5C,YAAY,UAAU,KAAK,CAAE,YAAY;QACzC,IAAI,UAAU,KAAK,CAAE,UAAU,EAAE;QACjC,cAAc,IAAI,CAAC,UAAU,KAAK,CAAE,YAAY;IAClD;IAEA,IAAI,qBAAqB,MAAM,GAAG,GAAG;QACnC,YAAY,qBAAqB,MAAM;IACzC;IAEA,MAAM,WAAW,qBAAqB,MAAM,GAAG,IAC3C,AAAC,YAAY,qBAAqB,MAAM,GAAI,MAC5C;IAEJ,8BAA8B;IAC9B,MAAM,mBAAqD,CAAC;IAE5D,KAAK,MAAM,OAAO,eAAgB;QAChC,MAAM,SAAmB,EAAE;QAE3B,KAAK,MAAM,aAAa,qBAAsB;YAC5C,MAAM,QAAQ,cAAc,UAAU,KAAK,EAAG;YAC9C,IAAI,UAAU,WAAW;gBACvB,OAAO,IAAI,CAAC;YACd;QACF;QAEA,IAAI,OAAO,MAAM,GAAG,GAAG;YACrB,MAAM,SAAS,OAAO,MAAM,CAAC,CAAC,GAAG,IAAM,IAAI,GAAG,KAAK,OAAO,MAAM;YAChE,gBAAgB,CAAC,IAAI,GAAG;gBACtB,UAAU,OAAO,OAAO,OAAO,CAAC;gBAChC,OAAO,eAAe,OAAO,OAAO;gBACpC,QAAQ,SAAS;gBACjB,UAAU,UAAU;gBACpB,cAAc,OAAO,KAAK,CAAC,CAAC;YAC9B;QACF,OAAO;YACL,gBAAgB,CAAC,IAAI,GAAG;gBACtB,UAAU;gBACV,OAAO;gBACP,QAAQ;gBACR,UAAU;gBACV,cAAc,EAAE;YAClB;QACF;IACF;IAEA,sBAAsB;IACtB,MAAM,eAAiC,qBAAqB,GAAG,CAAC,CAAC,IAAM,CAAC;YACtE,MAAM,EAAE,OAAO,EAAE,iBAAiB,EAAE,SAAS,CAAC,WAAW;YACzD,cAAc,EAAE,KAAK,CAAE,YAAY;YACnC,YAAY,EAAE,KAAK,CAAE,UAAU;YAC/B,OAAO,EAAE,KAAK;YACd,aAAa,EAAE,EAAE;QACnB,CAAC;IAED,uBAAuB;IACvB,MAAM,UAA8B;QAClC,SAAS;YACP,iBAAiB;YACjB,qBAAqB;YACrB,UAAU,OAAO,SAAS,OAAO,CAAC;YAClC,UAAU,OAAO,SAAS,OAAO,CAAC;YAClC,YAAY,eAAe,cAAc,OAAO;QAClD;QACA,YAAY;QACZ;QACA,UAAU,EAAE;QACZ,iBAAiB,EAAE;IACrB;IAEA,wCAAwC;IACxC,QAAQ,QAAQ,GAAG,iBAAiB;IACpC,QAAQ,eAAe,GAAG,wBAAwB;IAElD,OAAO;AACT;AAKO,eAAe,yBAAyB,MAAc;IAC3D,MAAM,UAAU,MAAM,4BAA4B,QAAQ;IAE1D,qCAAqC;IACrC,MAAM,iBAAiB,OAAO,OAAO,CAAC,QAAQ,UAAU,EACrD,MAAM,CAAC,CAAC,GAAG,EAAE,GAAK,EAAE,MAAM,EAC1B,GAAG,CAAC,CAAC,CAAC,IAAI,GAAK;IAElB,MAAM,mBAAmB,OAAO,OAAO,CAAC,QAAQ,UAAU,EACvD,MAAM,CAAC,CAAC,GAAG,EAAE,GAAK,EAAE,QAAQ,EAC5B,GAAG,CAAC,CAAC,CAAC,IAAI,GAAK;IAElB,wBAAwB;IACxB,MAAM,kBAAkB,MAAM,yMAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;QACtD,OAAO;YAAE;YAAQ,QAAQ;QAAY;QACrC,SAAS;YAAE,OAAO;QAAK;IACzB;IAEA,MAAM,aAAuF,CAAC;IAE9F,KAAK,MAAM,aAAa,gBAAiB;QACvC,IAAI,CAAC,UAAU,KAAK,EAAE;QAEtB,IAAI,CAAC,UAAU,CAAC,UAAU,KAAK,CAAC,EAAE;YAChC,UAAU,CAAC,UAAU,KAAK,CAAC,GAAG;gBAAE,OAAO;gBAAG,YAAY;gBAAG,WAAW;YAAE;QACxE;QAEA,UAAU,CAAC,UAAU,KAAK,CAAC,CAAC,KAAK;QACjC,UAAU,CAAC,UAAU,KAAK,CAAC,CAAC,UAAU,IAAI,UAAU,KAAK,CAAC,YAAY;QACtE,IAAI,UAAU,KAAK,CAAC,UAAU,EAAE;YAC9B,UAAU,CAAC,UAAU,KAAK,CAAC,CAAC,SAAS;QACvC;IACF;IAEA,0BAA0B;IAC1B,MAAM,kBAAyF,CAAC;IAChG,KAAK,MAAM,CAAC,OAAO,MAAM,IAAI,OAAO,OAAO,CAAC,YAAa;QACvD,eAAe,CAAC,MAAM,GAAG;YACvB,OAAO,MAAM,KAAK;YAClB,UAAU,OAAO,CAAC,MAAM,UAAU,GAAG,MAAM,KAAK,EAAE,OAAO,CAAC;YAC1D,UAAU,OAAO,CAAC,AAAC,MAAM,SAAS,GAAG,MAAM,KAAK,GAAI,GAAG,EAAE,OAAO,CAAC;QACnE;IACF;IAEA,0BAA0B;IAC1B,MAAM,yMAAM,CAAC,aAAa,CAAC,MAAM,CAAC;QAChC,OAAO;YAAE;QAAO;QAChB,QAAQ;YACN;YACA,iBAAiB,QAAQ,OAAO,CAAC,eAAe;YAChD,qBAAqB,QAAQ,OAAO,CAAC,mBAAmB;YACxD,iBAAiB,QAAQ,OAAO,CAAC,QAAQ;YACzC,UAAU,QAAQ,OAAO,CAAC,QAAQ;YAClC,gBAAgB,KAAK,SAAS,CAAC;YAC/B,kBAAkB,KAAK,SAAS,CAAC;YACjC,YAAY,KAAK,SAAS,CAAC;YAC3B,YAAY,QAAQ,OAAO,CAAC,UAAU;YACtC,kBAAkB,IAAI;QACxB;QACA,QAAQ;YACN,iBAAiB,QAAQ,OAAO,CAAC,eAAe;YAChD,qBAAqB,QAAQ,OAAO,CAAC,mBAAmB;YACxD,iBAAiB,QAAQ,OAAO,CAAC,QAAQ;YACzC,UAAU,QAAQ,OAAO,CAAC,QAAQ;YAClC,gBAAgB,KAAK,SAAS,CAAC;YAC/B,kBAAkB,KAAK,SAAS,CAAC;YACjC,YAAY,KAAK,SAAS,CAAC;YAC3B,YAAY,QAAQ,OAAO,CAAC,UAAU;YACtC,kBAAkB,IAAI;QACxB;IACF;AACF;AAKO,SAAS,uBACd,QAAgB;IAEhB,IAAI,WAAW,KAAK,OAAO;IAC3B,IAAI,WAAW,KAAK,OAAO;IAC3B,IAAI,WAAW,KAAK,OAAO;IAC3B,OAAO;AACT"}},
    {"offset": {"line": 990, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/followup-engine.ts"],"sourcesContent":["/**\n * Follow-up Questions Engine\n *\n * Generates follow-up questions based on past weak points.\n * AI remembers previous attempts and asks about past weak points.\n */\n\nimport { prisma } from \"@/lib/prisma\";\nimport { identifyWeakAreas, calculatePerformanceMetrics } from \"./analytics/performance-analytics\";\n\n// Score dimension type for type-safe access\ntype ScoreDimension =\n  | \"requirementsClarification\"\n  | \"highLevelDesign\"\n  | \"detailedDesign\"\n  | \"scalability\"\n  | \"tradeoffs\"\n  | \"communication\";\n\n// Helper to get score value from dimension key\nfunction getScoreValue(\n  score: {\n    requirementsClarification: number;\n    highLevelDesign: number;\n    detailedDesign: number;\n    scalability: number;\n    tradeoffs: number;\n    communication: number;\n  },\n  dimension: ScoreDimension\n): number {\n  return score[dimension];\n}\n\n// Types\nexport interface WeakPoint {\n  dimension: string;\n  dimensionKey: string;\n  topic: string;\n  concept: string;\n  lastScore: number;\n  occurrences: number;\n  trend: \"improving\" | \"stable\" | \"declining\";\n}\n\nexport interface FollowUpContext {\n  weakPoints: WeakPoint[];\n  topicsToReinforce: string[];\n  conceptsToProbe: string[];\n  adaptedDifficulty: \"easier\" | \"standard\" | \"harder\";\n  hasHistory: boolean;\n  totalPastInterviews: number;\n}\n\n// Dimension to concept mapping\nconst DIMENSION_CONCEPTS: Record<string, string[]> = {\n  requirementsClarification: [\n    \"scale estimation (DAU, QPS)\",\n    \"functional vs non-functional requirements\",\n    \"latency and availability requirements\",\n    \"data consistency requirements\",\n    \"feature prioritization\",\n  ],\n  highLevelDesign: [\n    \"API design and endpoints\",\n    \"component architecture\",\n    \"database selection\",\n    \"data flow between components\",\n    \"service boundaries\",\n  ],\n  detailedDesign: [\n    \"data models and schemas\",\n    \"algorithm choices\",\n    \"caching strategies\",\n    \"protocol selection\",\n    \"failure handling\",\n  ],\n  scalability: [\n    \"horizontal vs vertical scaling\",\n    \"database sharding\",\n    \"load balancing strategies\",\n    \"caching layers\",\n    \"CDN usage\",\n  ],\n  tradeoffs: [\n    \"CAP theorem implications\",\n    \"consistency vs availability\",\n    \"cost vs performance\",\n    \"latency vs throughput\",\n    \"complexity vs maintainability\",\n  ],\n  communication: [\n    \"structured thinking\",\n    \"clear explanations\",\n    \"diagram usage\",\n    \"time management\",\n    \"handling clarifications\",\n  ],\n};\n\n// Dimension names\nconst DIMENSION_NAMES: Record<string, string> = {\n  requirementsClarification: \"Requirements Clarification\",\n  highLevelDesign: \"High-Level Design\",\n  detailedDesign: \"Detailed Design\",\n  scalability: \"Scalability\",\n  tradeoffs: \"Trade-offs\",\n  communication: \"Communication\",\n};\n\n/**\n * Get weak points for a user based on past interview performance\n */\nexport async function getWeakPointsForUser(\n  userId: string,\n  limit: number = 10\n): Promise<WeakPoint[]> {\n  const weakAreas = await identifyWeakAreas(userId, limit);\n\n  // Convert weak areas to weak points with concepts\n  const weakPoints: WeakPoint[] = [];\n\n  for (const area of weakAreas) {\n    // Find the dimension key from the display name\n    const dimensionKey = Object.entries(DIMENSION_NAMES).find(\n      ([, name]) => name === area.dimension\n    )?.[0];\n\n    if (!dimensionKey) continue;\n\n    const concepts = DIMENSION_CONCEPTS[dimensionKey] || [];\n\n    // Select 1-2 relevant concepts to probe based on the weak area\n    const conceptsToProbe = concepts.slice(0, 2);\n\n    weakPoints.push({\n      dimension: area.dimension,\n      dimensionKey,\n      topic: \"\", // Will be filled with specific topic if available\n      concept: conceptsToProbe.join(\", \"),\n      lastScore: area.lastScore,\n      occurrences: area.occurrences,\n      trend: area.trend,\n    });\n  }\n\n  return weakPoints;\n}\n\n/**\n * Build follow-up context for a new interview\n */\nexport async function buildFollowUpContext(\n  userId: string,\n  currentTopic: string\n): Promise<FollowUpContext> {\n  // Get performance metrics\n  const metrics = await calculatePerformanceMetrics(userId, 15);\n\n  // Get weak points\n  const weakPoints = await getWeakPointsForUser(userId, 10);\n\n  // Get topics that need reinforcement\n  const topicInterviews = await prisma.interview.findMany({\n    where: {\n      userId,\n      status: \"completed\",\n    },\n    include: { score: true },\n    orderBy: { endedAt: \"desc\" },\n    take: 20,\n  });\n\n  // Find topics with low pass rates\n  const topicStats: Record<string, { total: number; passed: number }> = {};\n\n  for (const interview of topicInterviews) {\n    if (!interview.score) continue;\n\n    if (!topicStats[interview.topic]) {\n      topicStats[interview.topic] = { total: 0, passed: 0 };\n    }\n\n    topicStats[interview.topic].total++;\n    if (interview.score.passStatus) {\n      topicStats[interview.topic].passed++;\n    }\n  }\n\n  const topicsToReinforce = Object.entries(topicStats)\n    .filter(([, stats]) => stats.total >= 2 && stats.passed / stats.total < 0.5)\n    .map(([topic]) => topic);\n\n  // Determine concepts to probe based on weak points\n  const conceptsToProbe: string[] = [];\n\n  for (const wp of weakPoints.slice(0, 3)) {\n    const concepts = DIMENSION_CONCEPTS[wp.dimensionKey] || [];\n    conceptsToProbe.push(...concepts.slice(0, 2));\n  }\n\n  // Determine difficulty adaptation\n  let adaptedDifficulty: \"easier\" | \"standard\" | \"harder\" = \"standard\";\n\n  if (metrics.overall.avgScore < 2.0) {\n    adaptedDifficulty = \"easier\";\n  } else if (metrics.overall.avgScore >= 3.0 && metrics.overall.passRate >= 70) {\n    adaptedDifficulty = \"harder\";\n  }\n\n  return {\n    weakPoints,\n    topicsToReinforce,\n    conceptsToProbe: [...new Set(conceptsToProbe)], // Remove duplicates\n    adaptedDifficulty,\n    hasHistory: metrics.overall.completedInterviews > 0,\n    totalPastInterviews: metrics.overall.completedInterviews,\n  };\n}\n\n/**\n * Generate prompt addition for follow-up context\n */\nexport function generateFollowUpPromptAddition(context: FollowUpContext): string {\n  if (!context.hasHistory || context.weakPoints.length === 0) {\n    return \"\";\n  }\n\n  let prompt = `\n## Candidate's Past Performance Context\n\nThis candidate has completed ${context.totalPastInterviews} previous interview${context.totalPastInterviews === 1 ? \"\" : \"s\"}.\n\n### Weak Areas to Focus On\n`;\n\n  for (const wp of context.weakPoints.slice(0, 3)) {\n    prompt += `- **${wp.dimension}** (avg score: ${wp.lastScore}/4, trend: ${wp.trend})\n  - Concepts to probe: ${wp.concept}\n`;\n  }\n\n  if (context.conceptsToProbe.length > 0) {\n    prompt += `\n### Specific Concepts to Cover\nDuring the interview, make sure to ask about:\n${context.conceptsToProbe.map((c) => `- ${c}`).join(\"\\n\")}\n`;\n  }\n\n  if (context.topicsToReinforce.length > 0) {\n    prompt += `\n### Related Topics With Low Performance\nThe candidate has struggled with these related topics: ${context.topicsToReinforce.join(\", \")}\nConsider asking questions that reinforce fundamentals from these areas.\n`;\n  }\n\n  prompt += `\n### Adaptation Instructions\n- Difficulty adaptation: ${context.adaptedDifficulty}\n${context.adaptedDifficulty === \"easier\" ? \"- Provide more hints and guidance for this candidate\" : \"\"}\n${context.adaptedDifficulty === \"harder\" ? \"- Challenge this candidate with edge cases and deeper probing\" : \"\"}\n- When the candidate answers questions related to their weak areas, probe deeper\n- Acknowledge improvement if they perform better on previously weak dimensions\n`;\n\n  return prompt;\n}\n\n/**\n * Track improvement on a specific concept (for future enhancement)\n */\nexport async function trackConceptImprovement(\n  userId: string,\n  interviewId: string,\n  dimension: string,\n  newScore: number\n): Promise<{ improved: boolean; previousScore: number | null }> {\n  // Get the previous score for this dimension\n  const previousInterviews = await prisma.interview.findMany({\n    where: {\n      userId,\n      status: \"completed\",\n      id: { not: interviewId },\n    },\n    include: { score: true },\n    orderBy: { endedAt: \"desc\" },\n    take: 5,\n  });\n\n  const previousScores = previousInterviews\n    .filter((i) => i.score)\n    .map((i) => getScoreValue(i.score!, dimension as ScoreDimension))\n    .filter((s) => s !== undefined);\n\n  if (previousScores.length === 0) {\n    return { improved: false, previousScore: null };\n  }\n\n  const previousAvg = previousScores.reduce((a, b) => a + b, 0) / previousScores.length;\n\n  return {\n    improved: newScore > previousAvg,\n    previousScore: Number(previousAvg.toFixed(2)),\n  };\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;;;;CAKC,GAED;AACA;;;;;;;;AAWA,+CAA+C;AAC/C,SAAS,cACP,KAOC,EACD,SAAyB;IAEzB,OAAO,KAAK,CAAC,UAAU;AACzB;AAsBA,+BAA+B;AAC/B,MAAM,qBAA+C;IACnD,2BAA2B;QACzB;QACA;QACA;QACA;QACA;KACD;IACD,iBAAiB;QACf;QACA;QACA;QACA;QACA;KACD;IACD,gBAAgB;QACd;QACA;QACA;QACA;QACA;KACD;IACD,aAAa;QACX;QACA;QACA;QACA;QACA;KACD;IACD,WAAW;QACT;QACA;QACA;QACA;QACA;KACD;IACD,eAAe;QACb;QACA;QACA;QACA;QACA;KACD;AACH;AAEA,kBAAkB;AAClB,MAAM,kBAA0C;IAC9C,2BAA2B;IAC3B,iBAAiB;IACjB,gBAAgB;IAChB,aAAa;IACb,WAAW;IACX,eAAe;AACjB;AAKO,eAAe,qBACpB,MAAc,EACd,QAAgB,EAAE;IAElB,MAAM,YAAY,MAAM,IAAA,mPAAiB,EAAC,QAAQ;IAElD,kDAAkD;IAClD,MAAM,aAA0B,EAAE;IAElC,KAAK,MAAM,QAAQ,UAAW;QAC5B,+CAA+C;QAC/C,MAAM,eAAe,OAAO,OAAO,CAAC,iBAAiB,IAAI,CACvD,CAAC,GAAG,KAAK,GAAK,SAAS,KAAK,SAAS,GACpC,CAAC,EAAE;QAEN,IAAI,CAAC,cAAc;QAEnB,MAAM,WAAW,kBAAkB,CAAC,aAAa,IAAI,EAAE;QAEvD,+DAA+D;QAC/D,MAAM,kBAAkB,SAAS,KAAK,CAAC,GAAG;QAE1C,WAAW,IAAI,CAAC;YACd,WAAW,KAAK,SAAS;YACzB;YACA,OAAO;YACP,SAAS,gBAAgB,IAAI,CAAC;YAC9B,WAAW,KAAK,SAAS;YACzB,aAAa,KAAK,WAAW;YAC7B,OAAO,KAAK,KAAK;QACnB;IACF;IAEA,OAAO;AACT;AAKO,eAAe,qBACpB,MAAc,EACd,YAAoB;IAEpB,0BAA0B;IAC1B,MAAM,UAAU,MAAM,IAAA,6PAA2B,EAAC,QAAQ;IAE1D,kBAAkB;IAClB,MAAM,aAAa,MAAM,qBAAqB,QAAQ;IAEtD,qCAAqC;IACrC,MAAM,kBAAkB,MAAM,yMAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;QACtD,OAAO;YACL;YACA,QAAQ;QACV;QACA,SAAS;YAAE,OAAO;QAAK;QACvB,SAAS;YAAE,SAAS;QAAO;QAC3B,MAAM;IACR;IAEA,kCAAkC;IAClC,MAAM,aAAgE,CAAC;IAEvE,KAAK,MAAM,aAAa,gBAAiB;QACvC,IAAI,CAAC,UAAU,KAAK,EAAE;QAEtB,IAAI,CAAC,UAAU,CAAC,UAAU,KAAK,CAAC,EAAE;YAChC,UAAU,CAAC,UAAU,KAAK,CAAC,GAAG;gBAAE,OAAO;gBAAG,QAAQ;YAAE;QACtD;QAEA,UAAU,CAAC,UAAU,KAAK,CAAC,CAAC,KAAK;QACjC,IAAI,UAAU,KAAK,CAAC,UAAU,EAAE;YAC9B,UAAU,CAAC,UAAU,KAAK,CAAC,CAAC,MAAM;QACpC;IACF;IAEA,MAAM,oBAAoB,OAAO,OAAO,CAAC,YACtC,MAAM,CAAC,CAAC,GAAG,MAAM,GAAK,MAAM,KAAK,IAAI,KAAK,MAAM,MAAM,GAAG,MAAM,KAAK,GAAG,KACvE,GAAG,CAAC,CAAC,CAAC,MAAM,GAAK;IAEpB,mDAAmD;IACnD,MAAM,kBAA4B,EAAE;IAEpC,KAAK,MAAM,MAAM,WAAW,KAAK,CAAC,GAAG,GAAI;QACvC,MAAM,WAAW,kBAAkB,CAAC,GAAG,YAAY,CAAC,IAAI,EAAE;QAC1D,gBAAgB,IAAI,IAAI,SAAS,KAAK,CAAC,GAAG;IAC5C;IAEA,kCAAkC;IAClC,IAAI,oBAAsD;IAE1D,IAAI,QAAQ,OAAO,CAAC,QAAQ,GAAG,KAAK;QAClC,oBAAoB;IACtB,OAAO,IAAI,QAAQ,OAAO,CAAC,QAAQ,IAAI,OAAO,QAAQ,OAAO,CAAC,QAAQ,IAAI,IAAI;QAC5E,oBAAoB;IACtB;IAEA,OAAO;QACL;QACA;QACA,iBAAiB;eAAI,IAAI,IAAI;SAAiB;QAC9C;QACA,YAAY,QAAQ,OAAO,CAAC,mBAAmB,GAAG;QAClD,qBAAqB,QAAQ,OAAO,CAAC,mBAAmB;IAC1D;AACF;AAKO,SAAS,+BAA+B,OAAwB;IACrE,IAAI,CAAC,QAAQ,UAAU,IAAI,QAAQ,UAAU,CAAC,MAAM,KAAK,GAAG;QAC1D,OAAO;IACT;IAEA,IAAI,SAAS,CAAC;;;6BAGa,EAAE,QAAQ,mBAAmB,CAAC,mBAAmB,EAAE,QAAQ,mBAAmB,KAAK,IAAI,KAAK,IAAI;;;AAG7H,CAAC;IAEC,KAAK,MAAM,MAAM,QAAQ,UAAU,CAAC,KAAK,CAAC,GAAG,GAAI;QAC/C,UAAU,CAAC,IAAI,EAAE,GAAG,SAAS,CAAC,eAAe,EAAE,GAAG,SAAS,CAAC,WAAW,EAAE,GAAG,KAAK,CAAC;uBAC/D,EAAE,GAAG,OAAO,CAAC;AACpC,CAAC;IACC;IAEA,IAAI,QAAQ,eAAe,CAAC,MAAM,GAAG,GAAG;QACtC,UAAU,CAAC;;;AAGf,EAAE,QAAQ,eAAe,CAAC,GAAG,CAAC,CAAC,IAAM,CAAC,EAAE,EAAE,GAAG,EAAE,IAAI,CAAC,MAAM;AAC1D,CAAC;IACC;IAEA,IAAI,QAAQ,iBAAiB,CAAC,MAAM,GAAG,GAAG;QACxC,UAAU,CAAC;;uDAEwC,EAAE,QAAQ,iBAAiB,CAAC,IAAI,CAAC,MAAM;;AAE9F,CAAC;IACC;IAEA,UAAU,CAAC;;yBAEY,EAAE,QAAQ,iBAAiB,CAAC;AACrD,EAAE,QAAQ,iBAAiB,KAAK,WAAW,yDAAyD,GAAG;AACvG,EAAE,QAAQ,iBAAiB,KAAK,WAAW,kEAAkE,GAAG;;;AAGhH,CAAC;IAEC,OAAO;AACT;AAKO,eAAe,wBACpB,MAAc,EACd,WAAmB,EACnB,SAAiB,EACjB,QAAgB;IAEhB,4CAA4C;IAC5C,MAAM,qBAAqB,MAAM,yMAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;QACzD,OAAO;YACL;YACA,QAAQ;YACR,IAAI;gBAAE,KAAK;YAAY;QACzB;QACA,SAAS;YAAE,OAAO;QAAK;QACvB,SAAS;YAAE,SAAS;QAAO;QAC3B,MAAM;IACR;IAEA,MAAM,iBAAiB,mBACpB,MAAM,CAAC,CAAC,IAAM,EAAE,KAAK,EACrB,GAAG,CAAC,CAAC,IAAM,cAAc,EAAE,KAAK,EAAG,YACnC,MAAM,CAAC,CAAC,IAAM,MAAM;IAEvB,IAAI,eAAe,MAAM,KAAK,GAAG;QAC/B,OAAO;YAAE,UAAU;YAAO,eAAe;QAAK;IAChD;IAEA,MAAM,cAAc,eAAe,MAAM,CAAC,CAAC,GAAG,IAAM,IAAI,GAAG,KAAK,eAAe,MAAM;IAErF,OAAO;QACL,UAAU,WAAW;QACrB,eAAe,OAAO,YAAY,OAAO,CAAC;IAC5C;AACF"}},
    {"offset": {"line": 1232, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/prompts/interviewer.ts"],"sourcesContent":["import { PersonalitySettings, AdaptedPersonality } from \"../ai-personality-adapter\";\nimport { FollowUpContext, generateFollowUpPromptAddition } from \"../followup-engine\";\n\nexport const INTERVIEW_PHASES = [\n  {\n    id: \"requirements\",\n    name: \"Requirements Clarification\",\n    duration: 8, // minutes\n    startTime: 45,\n    endTime: 37,\n    description: \"Understand the problem scope, scale, and constraints\",\n    keyPoints: [\n      \"Clarify functional requirements\",\n      \"Understand scale (users, QPS, data size)\",\n      \"Identify non-functional requirements (latency, availability)\",\n      \"Prioritize features\",\n    ],\n  },\n  {\n    id: \"high-level\",\n    name: \"High-Level Design\",\n    duration: 12,\n    startTime: 37,\n    endTime: 25,\n    description: \"Design the overall system architecture\",\n    keyPoints: [\n      \"Draw core components\",\n      \"Define APIs\",\n      \"Explain data flow\",\n      \"Choose databases and storage\",\n    ],\n  },\n  {\n    id: \"deep-dive\",\n    name: \"Deep Dive\",\n    duration: 12,\n    startTime: 25,\n    endTime: 13,\n    description: \"Explore critical components in detail\",\n    keyPoints: [\n      \"Data models and schemas\",\n      \"Algorithms and protocols\",\n      \"Failure handling\",\n      \"Edge cases\",\n    ],\n  },\n  {\n    id: \"scalability\",\n    name: \"Scalability & Trade-offs\",\n    duration: 10,\n    startTime: 13,\n    endTime: 3,\n    description: \"Discuss scaling and architectural decisions\",\n    keyPoints: [\n      \"Handle 10x-100x growth\",\n      \"Caching strategies\",\n      \"CAP theorem implications\",\n      \"Cost vs performance\",\n    ],\n  },\n  {\n    id: \"wrapup\",\n    name: \"Wrap-up\",\n    duration: 3,\n    startTime: 3,\n    endTime: 0,\n    description: \"Final questions and summary\",\n    keyPoints: [\n      \"Address remaining concerns\",\n      \"Candidate questions\",\n      \"Summary of design\",\n    ],\n  },\n] as const;\n\nexport type InterviewPhase = typeof INTERVIEW_PHASES[number][\"id\"];\n\nexport const INTERVIEWER_SYSTEM_PROMPT = `You are Bobby, a friendly and experienced FAANG system design interviewer with 10+ years of experience at companies like Google, Meta, Amazon, Netflix, and Uber. Your role is to conduct a realistic 45-minute system design interview.\n\n## Your Personality as Bobby\n- Be warm, encouraging, and professional\n- Use a conversational tone while maintaining technical rigor\n- Occasionally use phrases like \"Great point!\", \"That's interesting...\", \"I like that approach\"\n- Introduce yourself as Bobby at the start of the interview\n\n## Interview Structure (45 minutes total)\n\n### Phase 1: Requirements Clarification (Minutes 45:00 - 37:00) [8 min]\n- Ask about scale (DAU, requests/sec, data size)\n- Clarify functional vs non-functional requirements\n- Understand use cases and priorities\n- Key questions:\n  * \"What's the expected scale? DAU, requests per second?\"\n  * \"What are the most critical features we need to support?\"\n  * \"What are our latency requirements?\"\n  * \"Do we need strong consistency or is eventual consistency okay?\"\n\n### Phase 2: High-Level Design (Minutes 37:00 - 25:00) [12 min]\n- Guide them to draw core components\n- Discuss API design\n- Cover data flow between components\n- Key questions:\n  * \"Can you walk me through the high-level architecture?\"\n  * \"What databases would you use and why?\"\n  * \"How would data flow from client to storage?\"\n\n### Phase 3: Deep Dive (Minutes 25:00 - 13:00) [12 min]\n- Pick 2-3 critical components to explore in detail\n- Ask about data models, algorithms, protocols\n- Discuss failure scenarios and edge cases\n- Key questions:\n  * \"Let's dive deeper into [component]. How would you implement it?\"\n  * \"What happens if [failure scenario]?\"\n  * \"How would you handle [edge case]?\"\n\n### Phase 4: Scalability & Trade-offs (Minutes 13:00 - 3:00) [10 min]\n- How does it handle 10x, 100x scale?\n- CAP theorem implications\n- Cost vs performance tradeoffs\n- Key questions:\n  * \"How would this design change if we had 100x the users?\"\n  * \"What are the bottlenecks in this design?\"\n  * \"What trade-offs are you making here?\"\n\n### Phase 5: Wrap-up (Minutes 3:00 - 0:00) [3 min]\n- Address any remaining concerns\n- Allow candidate to ask questions\n- Summarize the design\n\n## Bobby's Interview Style\n\n1. **Be conversational and supportive** - Guide the candidate through each phase while being encouraging\n2. **Ask probing questions** - Push candidates to think deeper with genuine curiosity\n3. **Focus on tradeoffs** - There's no single right answer; evaluate reasoning\n4. **Manage time** - Gently transition between phases to cover all areas\n5. **Adapt to responses** - If they struggle, provide hints; if they excel, go deeper\n6. **Stay positive** - Even when challenging decisions, do so constructively\n\n## Phase Transition Signals\n\nWhen you determine it's time to move to the next phase, include this marker in your response:\n[PHASE_TRANSITION: <next_phase_id>]\n\nFor example: [PHASE_TRANSITION: high-level]\n\nOnly use these phase IDs: requirements, high-level, deep-dive, scalability, wrapup\n\n## Important Rules\n\n- DO NOT give away answers - guide them with questions\n- DO NOT be overly positive - be professional and objective\n- DO challenge their decisions - \"Why not use X instead?\"\n- DO acknowledge good points - \"That's a good consideration\"\n- DO redirect if they go off track - \"Let's focus on the core flow first\"\n- DO manage time - transition phases appropriately\n- KEEP responses concise - 2-4 sentences, then ask 1-2 questions\n\n## CRITICAL: Phase Boundary Enforcement\n\n**YOU MUST STRICTLY STAY WITHIN THE CURRENT PHASE. DO NOT JUMP AHEAD OR GO BACKWARDS.**\n\n- **In Requirements Phase (45:00-37:00)**: ONLY ask about scale, functional/non-functional requirements, priorities. DO NOT ask about architecture, databases, or implementation details yet.\n- **In High-Level Design Phase (37:00-25:00)**: ONLY ask about overall architecture, main components, API design, and data flow. DO NOT dive into implementation details, algorithms, or schemas yet.\n- **In Deep Dive Phase (25:00-13:00)**: NOW you can ask about data models, algorithms, protocols, and implementation details. DO NOT ask about scalability or caching yet.\n- **In Scalability Phase (13:00-3:00)**: NOW you can ask about scaling strategies, caching, sharding, load balancing, and performance optimization.\n- **In Wrap-up Phase (3:00-0:00)**: Summarize, answer candidate questions, discuss any remaining concerns.\n\n**If the candidate jumps ahead** (e.g., talks about caching in requirements phase), acknowledge briefly but redirect: \"That's an interesting point about caching, but let's first clarify the requirements. We'll discuss optimization strategies later.\"\n\n**If the candidate is stuck**, provide hints ONLY related to the current phase. Don't hint at future phases.\n\n## Response Format\n\nKeep responses focused. React to their answer, provide brief feedback, then ask the next question. If transitioning phases, acknowledge the transition naturally.`;\n\nexport const getInterviewPrompt = (topic: string, difficulty: string) => {\n  const difficultyGuide = {\n    easy: \"Be more guiding and provide more hints. Focus on basic concepts. Allow more time for explanations.\",\n    medium: \"Balance between guidance and challenge. Standard FAANG interview depth.\",\n    hard: \"Be more challenging. Ask about edge cases, failure modes, and push for optimal solutions. Expect quick, precise answers.\",\n  };\n\n  return `${INTERVIEWER_SYSTEM_PROMPT}\n\n## Current Interview\n\n**Topic:** ${topic}\n**Difficulty:** ${difficulty}\n**Approach:** ${difficultyGuide[difficulty as keyof typeof difficultyGuide]}\n\nBegin the interview now. Introduce yourself as Bobby, briefly introduce the problem, and start with requirements clarification. Ask what clarifying questions they have about the system.`;\n};\n\nexport const PHASE_ANALYSIS_PROMPT = `You are analyzing a specific phase of a system design interview. Evaluate the candidate's performance in this phase only.\n\n## CRITICAL EVALUATION RULES\n\n**IMPORTANT: You MUST evaluate based ONLY on what the USER (candidate) actually said. Do NOT give credit for things the ASSISTANT (interviewer) mentioned.**\n\n1. **If the candidate provided NO responses or only said \"hello\", \"ok\", \"yes\" - score MUST be 1**\n2. **If the candidate gave vague/incomplete answers - score should be 1-2**\n3. **Only give scores of 3-4 if candidate demonstrated clear technical knowledge**\n\n## Phase Being Evaluated: {{PHASE_NAME}}\n\n## Scoring Scale (1-4)\n- 4 (Excellent): Candidate provided detailed, expert-level technical responses\n- 3 (Good): Candidate showed solid understanding through their explanations\n- 2 (Needs Work): Candidate gave partial/vague answers\n- 1 (Poor): Candidate did not provide meaningful technical responses\n\n## Evaluation Criteria for {{PHASE_NAME}}:\n{{PHASE_CRITERIA}}\n\n**If the candidate did not address these criteria in their responses, the score is 1.**\n\n## Response Format\nReturn ONLY valid JSON:\n{\n  \"phase\": \"{{PHASE_ID}}\",\n  \"score\": <1-4>,\n  \"summary\": \"<2-3 sentence evaluation - be honest if candidate didn't respond>\",\n  \"strengths\": [\"<strength 1>\", \"<strength 2>\"],\n  \"improvements\": [\"<area 1>\", \"<area 2>\"],\n  \"keyObservations\": [\"<observation 1>\", \"<observation 2>\"]\n}`;\n\nexport const getPhaseAnalysisPrompt = (phaseId: string, phaseName: string) => {\n  const phaseCriteria: Record<string, string> = {\n    requirements: `\n- Did they ask about scale (users, QPS, data volume)?\n- Did they clarify functional requirements?\n- Did they identify non-functional requirements (latency, availability, consistency)?\n- Did they prioritize features appropriately?\n- Did they ask about constraints and edge cases?`,\n    \"high-level\": `\n- Is the architecture sound and complete?\n- Are components well-defined with clear responsibilities?\n- Is the API design reasonable?\n- Did they choose appropriate databases/storage?\n- Is the data flow logical and efficient?`,\n    \"deep-dive\": `\n- Can they explain component internals?\n- Do they understand data models and schemas?\n- Did they address failure scenarios?\n- Did they consider edge cases?\n- Do they know relevant algorithms/protocols?`,\n    scalability: `\n- Do they understand horizontal vs vertical scaling?\n- Did they propose caching strategies?\n- Did they discuss sharding/partitioning?\n- Did they address load balancing?\n- Can they reason about 10x-100x growth?`,\n    wrapup: `\n- Did they summarize the design clearly?\n- Did they acknowledge trade-offs made?\n- Were they open to feedback?\n- Did they ask thoughtful questions?`,\n  };\n\n  return PHASE_ANALYSIS_PROMPT\n    .replace(/{{PHASE_NAME}}/g, phaseName)\n    .replace(/{{PHASE_ID}}/g, phaseId)\n    .replace(/{{PHASE_CRITERIA}}/g, phaseCriteria[phaseId] || \"\");\n};\n\n/**\n * Get personalized interview prompt with personality adaptation and follow-up context\n */\nexport const getPersonalizedInterviewPrompt = (\n  topic: string,\n  difficulty: string,\n  personality: AdaptedPersonality,\n  followUpContext?: FollowUpContext\n): string => {\n  const difficultyGuide = {\n    easy: \"Be more guiding and provide more hints. Focus on basic concepts. Allow more time for explanations.\",\n    medium: \"Balance between guidance and challenge. Standard FAANG interview depth.\",\n    hard: \"Be more challenging. Ask about edge cases, failure modes, and push for optimal solutions. Expect quick, precise answers.\",\n  };\n\n  // Build the follow-up context section\n  const followUpSection = followUpContext\n    ? generateFollowUpPromptAddition(followUpContext)\n    : \"\";\n\n  return `${INTERVIEWER_SYSTEM_PROMPT}\n\n${personality.promptModifications}\n${followUpSection}\n## Current Interview\n\n**Topic:** ${topic}\n**Difficulty:** ${difficulty}\n**Approach:** ${difficultyGuide[difficulty as keyof typeof difficultyGuide] || difficultyGuide.medium}\n\nBegin the interview now. Introduce yourself as Bobby, briefly introduce the problem, and start with requirements clarification. Ask what clarifying questions they have about the system.`;\n};\n\nexport const SCORING_PROMPT = `You are evaluating a complete 45-minute system design interview. Based on the entire conversation, give a final comprehensive evaluation.\n\n## CRITICAL EVALUATION RULES\n\n**IMPORTANT: You MUST evaluate based ONLY on what the USER (candidate) actually said. Do NOT give credit for things the ASSISTANT (interviewer) mentioned.**\n\n1. **If the candidate provided NO substantive responses or only said things like \"hello\", \"ok\", \"yes\" without any technical content, ALL dimension scores MUST be 1.**\n2. **If the candidate gave only brief/incomplete answers, scores should be 1-2.**\n3. **Only give scores of 3-4 if the candidate demonstrated clear technical knowledge through their own explanations.**\n4. **Count the actual technical responses from the USER. Short acknowledgments don't count as responses.**\n\n## Scoring Scale\n- 4 (Strong Hire): Exceeds expectations, demonstrates expertise with detailed technical explanations\n- 3 (Hire): Meets expectations, solid understanding shown through their responses\n- 2 (Lean No Hire): Below expectations, only partial/vague answers provided\n- 1 (No Hire): Does not meet basic requirements - no meaningful technical responses given\n\n## Dimensions to Evaluate\n\n1. **Requirements Clarification (10%)**\n   - Did the CANDIDATE ask about scale, users, data size?\n   - Did the CANDIDATE clarify functional vs non-functional requirements?\n   - If the candidate didn't ask clarifying questions, score is 1.\n\n2. **High-Level Design (20%)**\n   - Did the CANDIDATE describe an architecture?\n   - Did the CANDIDATE explain components and their responsibilities?\n   - If the candidate didn't propose any design, score is 1.\n\n3. **Detailed Design (15%)**\n   - Did the CANDIDATE explain component internals?\n   - Did the CANDIDATE discuss data models and algorithms?\n   - If the candidate didn't go into any details, score is 1.\n\n4. **Scalability (20%)**\n   - Did the CANDIDATE discuss scaling strategies?\n   - Did the CANDIDATE propose caching, sharding, load balancing?\n   - If the candidate didn't address scalability, score is 1.\n\n5. **Tradeoffs (25%)**\n   - Did the CANDIDATE reason about tradeoffs?\n   - Did the CANDIDATE compare alternatives?\n   - If the candidate didn't discuss any tradeoffs, score is 1.\n\n6. **Communication (10%)**\n   - Did the CANDIDATE communicate clearly?\n   - If the candidate barely spoke, score is 1.\n\n## Response Format\n\nReturn a JSON object with:\n{\n  \"candidateResponseCount\": <number of substantive technical responses from the user>,\n  \"requirementsClarification\": <1-4>,\n  \"highLevelDesign\": <1-4>,\n  \"detailedDesign\": <1-4>,\n  \"scalability\": <1-4>,\n  \"tradeoffs\": <1-4>,\n  \"communication\": <1-4>,\n  \"overallScore\": <weighted average>,\n  \"passStatus\": <true ONLY if average >= 2.5 AND no dimension below 2 AND tradeoffs >= 3 AND candidateResponseCount >= 5>,\n  \"feedback\": {\n    \"requirementsClarification\": \"<specific feedback based on what candidate said>\",\n    \"highLevelDesign\": \"<specific feedback based on what candidate said>\",\n    \"detailedDesign\": \"<specific feedback based on what candidate said>\",\n    \"scalability\": \"<specific feedback based on what candidate said>\",\n    \"tradeoffs\": \"<specific feedback based on what candidate said>\",\n    \"communication\": \"<specific feedback based on what candidate said>\",\n    \"overallFeedback\": \"<2-3 sentence summary - be honest if candidate didn't participate>\",\n    \"strengths\": [\"<strength 1>\", \"<strength 2>\"],\n    \"improvements\": [\"<improvement 1>\", \"<improvement 2>\"]\n  }\n}\n\nReturn ONLY valid JSON.`;\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AACA;;;;;;AAEO,MAAM,mBAAmB;IAC9B;QACE,IAAI;QACJ,MAAM;QACN,UAAU;QACV,WAAW;QACX,SAAS;QACT,aAAa;QACb,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACA;QACE,IAAI;QACJ,MAAM;QACN,UAAU;QACV,WAAW;QACX,SAAS;QACT,aAAa;QACb,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACA;QACE,IAAI;QACJ,MAAM;QACN,UAAU;QACV,WAAW;QACX,SAAS;QACT,aAAa;QACb,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACA;QACE,IAAI;QACJ,MAAM;QACN,UAAU;QACV,WAAW;QACX,SAAS;QACT,aAAa;QACb,WAAW;YACT;YACA;YACA;YACA;SACD;IACH;IACA;QACE,IAAI;QACJ,MAAM;QACN,UAAU;QACV,WAAW;QACX,SAAS;QACT,aAAa;QACb,WAAW;YACT;YACA;YACA;SACD;IACH;CACD;AAIM,MAAM,4BAA4B,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;iKAgGuH,CAAC;AAE3J,MAAM,qBAAqB,CAAC,OAAe;IAChD,MAAM,kBAAkB;QACtB,MAAM;QACN,QAAQ;QACR,MAAM;IACR;IAEA,OAAO,GAAG,0BAA0B;;;;WAI3B,EAAE,MAAM;gBACH,EAAE,WAAW;cACf,EAAE,eAAe,CAAC,WAA2C,CAAC;;yLAE6G,CAAC;AAC1L;AAEO,MAAM,wBAAwB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAgCrC,CAAC;AAEK,MAAM,yBAAyB,CAAC,SAAiB;IACtD,MAAM,gBAAwC;QAC5C,cAAc,CAAC;;;;;gDAK6B,CAAC;QAC7C,cAAc,CAAC;;;;;yCAKsB,CAAC;QACtC,aAAa,CAAC;;;;;6CAK2B,CAAC;QAC1C,aAAa,CAAC;;;;;wCAKsB,CAAC;QACrC,QAAQ,CAAC;;;;oCAIuB,CAAC;IACnC;IAEA,OAAO,sBACJ,OAAO,CAAC,mBAAmB,WAC3B,OAAO,CAAC,iBAAiB,SACzB,OAAO,CAAC,uBAAuB,aAAa,CAAC,QAAQ,IAAI;AAC9D;AAKO,MAAM,iCAAiC,CAC5C,OACA,YACA,aACA;IAEA,MAAM,kBAAkB;QACtB,MAAM;QACN,QAAQ;QACR,MAAM;IACR;IAEA,sCAAsC;IACtC,MAAM,kBAAkB,kBACpB,IAAA,6OAA8B,EAAC,mBAC/B;IAEJ,OAAO,GAAG,0BAA0B;;AAEtC,EAAE,YAAY,mBAAmB,CAAC;AAClC,EAAE,gBAAgB;;;WAGP,EAAE,MAAM;gBACH,EAAE,WAAW;cACf,EAAE,eAAe,CAAC,WAA2C,IAAI,gBAAgB,MAAM,CAAC;;yLAEmF,CAAC;AAC1L;AAEO,MAAM,iBAAiB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;uBA0ER,CAAC"}},
    {"offset": {"line": 1611, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/redis.ts"],"sourcesContent":["/**\n * Redis Client using Upstash\n *\n * Provides a singleton Redis client for caching.\n * Falls back gracefully if Redis is not configured.\n */\n\nimport { Redis } from \"@upstash/redis\";\n\n// Cache key prefixes for organization\nexport const CACHE_KEYS = {\n  USER_ANALYTICS: \"analytics:user:\",\n  LEADERBOARD: \"leaderboard:\",\n  OLLAMA_HEALTH: \"ollama:health\",\n  INTERVIEW_QUESTIONS: \"questions:\",\n} as const;\n\n// TTL values in seconds\nexport const CACHE_TTL = {\n  USER_ANALYTICS: 5 * 60,      // 5 minutes\n  LEADERBOARD: 60,             // 1 minute\n  OLLAMA_HEALTH: 30,           // 30 seconds\n  INTERVIEW_QUESTIONS: 60 * 60, // 1 hour\n} as const;\n\n// Check if Redis is configured\nconst isRedisConfigured = () => {\n  return !!(\n    process.env.UPSTASH_REDIS_REST_URL &&\n    process.env.UPSTASH_REDIS_REST_TOKEN\n  );\n};\n\n// Create Redis client singleton\nlet redisClient: Redis | null = null;\n\nexport function getRedisClient(): Redis | null {\n  if (!isRedisConfigured()) {\n    return null;\n  }\n\n  if (!redisClient) {\n    redisClient = new Redis({\n      url: process.env.UPSTASH_REDIS_REST_URL!,\n      token: process.env.UPSTASH_REDIS_REST_TOKEN!,\n    });\n  }\n\n  return redisClient;\n}\n\n// Helper to check if Redis is available\nexport function isRedisAvailable(): boolean {\n  return isRedisConfigured();\n}\n\nexport { Redis };\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;;;;CAKC,GAED;;AAGO,MAAM,aAAa;IACxB,gBAAgB;IAChB,aAAa;IACb,eAAe;IACf,qBAAqB;AACvB;AAGO,MAAM,YAAY;IACvB,gBAAgB,IAAI;IACpB,aAAa;IACb,eAAe;IACf,qBAAqB,KAAK;AAC5B;AAEA,+BAA+B;AAC/B,MAAM,oBAAoB;IACxB,OAAO,CAAC,CAAC,CACP,QAAQ,GAAG,CAAC,sBAAsB,IAClC,QAAQ,GAAG,CAAC,wBAAwB,AACtC;AACF;AAEA,gCAAgC;AAChC,IAAI,cAA4B;AAEzB,SAAS;IACd,IAAI,CAAC,qBAAqB;QACxB,OAAO;IACT;IAEA,IAAI,CAAC,aAAa;QAChB,cAAc,IAAI,iPAAK,CAAC;YACtB,KAAK,QAAQ,GAAG,CAAC,sBAAsB;YACvC,OAAO,QAAQ,GAAG,CAAC,wBAAwB;QAC7C;IACF;IAEA,OAAO;AACT;AAGO,SAAS;IACd,OAAO;AACT"}},
    {"offset": {"line": 1666, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/rate-limit.ts"],"sourcesContent":["/**\n * Rate Limiting Utility\n *\n * Sliding window rate limiter using Upstash Redis.\n * Falls back to in-memory storage when Redis is not configured.\n */\n\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { getRedisClient, isRedisAvailable } from \"./redis\";\n\ninterface RateLimitConfig {\n  /** Maximum number of requests allowed in the window */\n  limit: number;\n  /** Time window in seconds */\n  window: number;\n}\n\ninterface RateLimitResult {\n  success: boolean;\n  limit: number;\n  remaining: number;\n  reset: number; // Unix timestamp when the window resets\n}\n\n// Predefined rate limit tiers\nexport const RATE_LIMITS = {\n  /** Auth routes (login, register) - strict to prevent brute force */\n  AUTH: { limit: 5, window: 60 },\n  /** Password change - very strict */\n  PASSWORD: { limit: 3, window: 60 },\n  /** Resource creation (interviews, challenges) - moderate */\n  CREATE: { limit: 10, window: 60 },\n  /** Chat/interaction endpoints - higher limit */\n  CHAT: { limit: 30, window: 60 },\n  /** Code submission - moderate */\n  SUBMIT: { limit: 20, window: 60 },\n  /** Read/list endpoints - generous */\n  READ: { limit: 60, window: 60 },\n  /** File upload - strict */\n  UPLOAD: { limit: 5, window: 60 },\n  /** AI/LLM endpoints (expensive) - moderate */\n  AI: { limit: 10, window: 60 },\n} as const;\n\n// In-memory fallback store\nconst memoryStore = new Map<string, { count: number; resetAt: number }>();\n\n// Clean up expired entries periodically\nsetInterval(() => {\n  const now = Date.now();\n  for (const [key, value] of memoryStore) {\n    if (value.resetAt <= now) {\n      memoryStore.delete(key);\n    }\n  }\n}, 60_000);\n\n/**\n * Extract client identifier from request.\n * Uses IP address for unauthenticated requests.\n */\nfunction getClientIp(request: NextRequest): string {\n  const forwarded = request.headers.get(\"x-forwarded-for\");\n  if (forwarded) {\n    return forwarded.split(\",\")[0].trim();\n  }\n  const realIp = request.headers.get(\"x-real-ip\");\n  if (realIp) {\n    return realIp;\n  }\n  return \"127.0.0.1\";\n}\n\n/**\n * Check rate limit using Redis sliding window.\n */\nasync function checkRedisRateLimit(\n  key: string,\n  config: RateLimitConfig\n): Promise<RateLimitResult> {\n  const redis = getRedisClient();\n  if (!redis) {\n    return { success: true, limit: config.limit, remaining: config.limit, reset: 0 };\n  }\n\n  const now = Date.now();\n  const windowMs = config.window * 1000;\n  const windowStart = now - windowMs;\n\n  // Use a sorted set for sliding window\n  const redisKey = `ratelimit:${key}`;\n\n  // Pipeline: remove old entries, add current, count, set expiry\n  const pipeline = redis.pipeline();\n  pipeline.zremrangebyscore(redisKey, 0, windowStart);\n  pipeline.zadd(redisKey, { score: now, member: `${now}:${Math.random()}` });\n  pipeline.zcard(redisKey);\n  pipeline.expire(redisKey, config.window);\n\n  const results = await pipeline.exec();\n  const count = (results[2] as number) || 0;\n\n  const reset = Math.ceil((now + windowMs) / 1000);\n  const remaining = Math.max(0, config.limit - count);\n  const success = count <= config.limit;\n\n  return { success, limit: config.limit, remaining, reset };\n}\n\n/**\n * Check rate limit using in-memory store (fallback).\n */\nfunction checkMemoryRateLimit(\n  key: string,\n  config: RateLimitConfig\n): RateLimitResult {\n  const now = Date.now();\n  const windowMs = config.window * 1000;\n  const storeKey = `ratelimit:${key}`;\n\n  const entry = memoryStore.get(storeKey);\n\n  if (!entry || entry.resetAt <= now) {\n    // New window\n    memoryStore.set(storeKey, { count: 1, resetAt: now + windowMs });\n    return {\n      success: true,\n      limit: config.limit,\n      remaining: config.limit - 1,\n      reset: Math.ceil((now + windowMs) / 1000),\n    };\n  }\n\n  entry.count++;\n  const remaining = Math.max(0, config.limit - entry.count);\n  const success = entry.count <= config.limit;\n\n  return {\n    success,\n    limit: config.limit,\n    remaining,\n    reset: Math.ceil(entry.resetAt / 1000),\n  };\n}\n\n/**\n * Core rate limit check. Returns result indicating if request is allowed.\n */\nexport async function checkRateLimit(\n  identifier: string,\n  config: RateLimitConfig\n): Promise<RateLimitResult> {\n  if (isRedisAvailable()) {\n    try {\n      return await checkRedisRateLimit(identifier, config);\n    } catch (error) {\n      console.error(\"Redis rate limit error, falling back to memory:\", error);\n      return checkMemoryRateLimit(identifier, config);\n    }\n  }\n  return checkMemoryRateLimit(identifier, config);\n}\n\n/**\n * Apply rate limiting to an API route handler.\n * Returns a 429 response if the limit is exceeded, or null if allowed.\n *\n * @param request - The incoming request\n * @param config - Rate limit configuration\n * @param keyPrefix - Prefix for the rate limit key (e.g., \"api:register\")\n * @param userId - Optional user ID for user-based limiting (falls back to IP)\n */\nexport async function rateLimit(\n  request: NextRequest,\n  config: RateLimitConfig,\n  keyPrefix: string,\n  userId?: string\n): Promise<NextResponse | null> {\n  const identifier = userId || getClientIp(request);\n  const key = `${keyPrefix}:${identifier}`;\n\n  const result = await checkRateLimit(key, config);\n\n  if (!result.success) {\n    const retryAfter = Math.max(1, result.reset - Math.ceil(Date.now() / 1000));\n    return NextResponse.json(\n      {\n        error: \"Too many requests\",\n        message: \"Rate limit exceeded. Please try again later.\",\n        retryAfter,\n      },\n      {\n        status: 429,\n        headers: {\n          \"Retry-After\": String(retryAfter),\n          \"X-RateLimit-Limit\": String(result.limit),\n          \"X-RateLimit-Remaining\": \"0\",\n          \"X-RateLimit-Reset\": String(result.reset),\n        },\n      }\n    );\n  }\n\n  return null;\n}\n\n/**\n * Add rate limit headers to a successful response.\n */\nexport function addRateLimitHeaders(\n  response: NextResponse,\n  result: RateLimitResult\n): NextResponse {\n  response.headers.set(\"X-RateLimit-Limit\", String(result.limit));\n  response.headers.set(\"X-RateLimit-Remaining\", String(result.remaining));\n  response.headers.set(\"X-RateLimit-Reset\", String(result.reset));\n  return response;\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;;;;CAKC,GAED;AACA;;;AAiBO,MAAM,cAAc;IACzB,kEAAkE,GAClE,MAAM;QAAE,OAAO;QAAG,QAAQ;IAAG;IAC7B,kCAAkC,GAClC,UAAU;QAAE,OAAO;QAAG,QAAQ;IAAG;IACjC,0DAA0D,GAC1D,QAAQ;QAAE,OAAO;QAAI,QAAQ;IAAG;IAChC,8CAA8C,GAC9C,MAAM;QAAE,OAAO;QAAI,QAAQ;IAAG;IAC9B,+BAA+B,GAC/B,QAAQ;QAAE,OAAO;QAAI,QAAQ;IAAG;IAChC,mCAAmC,GACnC,MAAM;QAAE,OAAO;QAAI,QAAQ;IAAG;IAC9B,yBAAyB,GACzB,QAAQ;QAAE,OAAO;QAAG,QAAQ;IAAG;IAC/B,4CAA4C,GAC5C,IAAI;QAAE,OAAO;QAAI,QAAQ;IAAG;AAC9B;AAEA,2BAA2B;AAC3B,MAAM,cAAc,IAAI;AAExB,wCAAwC;AACxC,YAAY;IACV,MAAM,MAAM,KAAK,GAAG;IACpB,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,YAAa;QACtC,IAAI,MAAM,OAAO,IAAI,KAAK;YACxB,YAAY,MAAM,CAAC;QACrB;IACF;AACF,GAAG;AAEH;;;CAGC,GACD,SAAS,YAAY,OAAoB;IACvC,MAAM,YAAY,QAAQ,OAAO,CAAC,GAAG,CAAC;IACtC,IAAI,WAAW;QACb,OAAO,UAAU,KAAK,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI;IACrC;IACA,MAAM,SAAS,QAAQ,OAAO,CAAC,GAAG,CAAC;IACnC,IAAI,QAAQ;QACV,OAAO;IACT;IACA,OAAO;AACT;AAEA;;CAEC,GACD,eAAe,oBACb,GAAW,EACX,MAAuB;IAEvB,MAAM,QAAQ,IAAA,gOAAc;IAC5B,IAAI,CAAC,OAAO;QACV,OAAO;YAAE,SAAS;YAAM,OAAO,OAAO,KAAK;YAAE,WAAW,OAAO,KAAK;YAAE,OAAO;QAAE;IACjF;IAEA,MAAM,MAAM,KAAK,GAAG;IACpB,MAAM,WAAW,OAAO,MAAM,GAAG;IACjC,MAAM,cAAc,MAAM;IAE1B,sCAAsC;IACtC,MAAM,WAAW,CAAC,UAAU,EAAE,KAAK;IAEnC,+DAA+D;IAC/D,MAAM,WAAW,MAAM,QAAQ;IAC/B,SAAS,gBAAgB,CAAC,UAAU,GAAG;IACvC,SAAS,IAAI,CAAC,UAAU;QAAE,OAAO;QAAK,QAAQ,GAAG,IAAI,CAAC,EAAE,KAAK,MAAM,IAAI;IAAC;IACxE,SAAS,KAAK,CAAC;IACf,SAAS,MAAM,CAAC,UAAU,OAAO,MAAM;IAEvC,MAAM,UAAU,MAAM,SAAS,IAAI;IACnC,MAAM,QAAQ,AAAC,OAAO,CAAC,EAAE,IAAe;IAExC,MAAM,QAAQ,KAAK,IAAI,CAAC,CAAC,MAAM,QAAQ,IAAI;IAC3C,MAAM,YAAY,KAAK,GAAG,CAAC,GAAG,OAAO,KAAK,GAAG;IAC7C,MAAM,UAAU,SAAS,OAAO,KAAK;IAErC,OAAO;QAAE;QAAS,OAAO,OAAO,KAAK;QAAE;QAAW;IAAM;AAC1D;AAEA;;CAEC,GACD,SAAS,qBACP,GAAW,EACX,MAAuB;IAEvB,MAAM,MAAM,KAAK,GAAG;IACpB,MAAM,WAAW,OAAO,MAAM,GAAG;IACjC,MAAM,WAAW,CAAC,UAAU,EAAE,KAAK;IAEnC,MAAM,QAAQ,YAAY,GAAG,CAAC;IAE9B,IAAI,CAAC,SAAS,MAAM,OAAO,IAAI,KAAK;QAClC,aAAa;QACb,YAAY,GAAG,CAAC,UAAU;YAAE,OAAO;YAAG,SAAS,MAAM;QAAS;QAC9D,OAAO;YACL,SAAS;YACT,OAAO,OAAO,KAAK;YACnB,WAAW,OAAO,KAAK,GAAG;YAC1B,OAAO,KAAK,IAAI,CAAC,CAAC,MAAM,QAAQ,IAAI;QACtC;IACF;IAEA,MAAM,KAAK;IACX,MAAM,YAAY,KAAK,GAAG,CAAC,GAAG,OAAO,KAAK,GAAG,MAAM,KAAK;IACxD,MAAM,UAAU,MAAM,KAAK,IAAI,OAAO,KAAK;IAE3C,OAAO;QACL;QACA,OAAO,OAAO,KAAK;QACnB;QACA,OAAO,KAAK,IAAI,CAAC,MAAM,OAAO,GAAG;IACnC;AACF;AAKO,eAAe,eACpB,UAAkB,EAClB,MAAuB;IAEvB,IAAI,IAAA,kOAAgB,KAAI;QACtB,IAAI;YACF,OAAO,MAAM,oBAAoB,YAAY;QAC/C,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,mDAAmD;YACjE,OAAO,qBAAqB,YAAY;QAC1C;IACF;IACA,OAAO,qBAAqB,YAAY;AAC1C;AAWO,eAAe,UACpB,OAAoB,EACpB,MAAuB,EACvB,SAAiB,EACjB,MAAe;IAEf,MAAM,aAAa,UAAU,YAAY;IACzC,MAAM,MAAM,GAAG,UAAU,CAAC,EAAE,YAAY;IAExC,MAAM,SAAS,MAAM,eAAe,KAAK;IAEzC,IAAI,CAAC,OAAO,OAAO,EAAE;QACnB,MAAM,aAAa,KAAK,GAAG,CAAC,GAAG,OAAO,KAAK,GAAG,KAAK,IAAI,CAAC,KAAK,GAAG,KAAK;QACrE,OAAO,yNAAY,CAAC,IAAI,CACtB;YACE,OAAO;YACP,SAAS;YACT;QACF,GACA;YACE,QAAQ;YACR,SAAS;gBACP,eAAe,OAAO;gBACtB,qBAAqB,OAAO,OAAO,KAAK;gBACxC,yBAAyB;gBACzB,qBAAqB,OAAO,OAAO,KAAK;YAC1C;QACF;IAEJ;IAEA,OAAO;AACT;AAKO,SAAS,oBACd,QAAsB,EACtB,MAAuB;IAEvB,SAAS,OAAO,CAAC,GAAG,CAAC,qBAAqB,OAAO,OAAO,KAAK;IAC7D,SAAS,OAAO,CAAC,GAAG,CAAC,yBAAyB,OAAO,OAAO,SAAS;IACrE,SAAS,OAAO,CAAC,GAAG,CAAC,qBAAqB,OAAO,OAAO,KAAK;IAC7D,OAAO;AACT"}},
    {"offset": {"line": 1857, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/app/api/interview/%5Bid%5D/end/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from \"next/server\";\nimport { auth } from \"@/lib/auth\";\nimport { prisma } from \"@/lib/prisma\";\nimport { openai } from \"@/lib/openai\";\nimport { SCORING_PROMPT } from \"@/lib/prompts/interviewer\";\nimport { updateUserAnalyticsCache } from \"@/lib/analytics/performance-analytics\";\nimport { rateLimit, RATE_LIMITS } from \"@/lib/rate-limit\";\n\nexport async function POST(\n  request: NextRequest,\n  { params }: { params: Promise<{ id: string }> }\n) {\n  try {\n    const session = await auth();\n\n    if (!session?.user?.id) {\n      return NextResponse.json({ error: \"Unauthorized\" }, { status: 401 });\n    }\n\n    const rateLimitResponse = await rateLimit(request, RATE_LIMITS.AI, \"api:interview:end\", session.user.id);\n    if (rateLimitResponse) return rateLimitResponse;\n\n    const { id } = await params;\n\n    // Verify ownership and get interview with messages\n    const interview = await prisma.interview.findFirst({\n      where: {\n        id,\n        userId: session.user.id,\n      },\n      include: {\n        messages: {\n          orderBy: { timestamp: \"asc\" },\n        },\n      },\n    });\n\n    if (!interview) {\n      return NextResponse.json({ error: \"Interview not found\" }, { status: 404 });\n    }\n\n    if (interview.status === \"completed\") {\n      return NextResponse.json({ error: \"Interview already completed\" }, { status: 400 });\n    }\n\n    // Build conversation for scoring\n    const userMessages = interview.messages.filter((m) => m.role === \"user\");\n    const assistantMessages = interview.messages.filter((m) => m.role === \"assistant\");\n\n    // Count substantive user messages (more than just short acknowledgments)\n    const substantiveUserMessages = userMessages.filter(\n      (m) => m.content.trim().split(/\\s+/).length > 10 // More than 10 words\n    );\n\n    const conversationText = interview.messages\n      .filter((m) => m.role !== \"system\")\n      .map((m) => `${m.role.toUpperCase()}: ${m.content}`)\n      .join(\"\\n\\n\");\n\n    // Determine which phases were actually completed\n    const completedPhases: string[] = [];\n    if (interview.phaseTransitions) {\n      const transitions: Array<{ phase: string; startedAt: string; endedAt?: string }> =\n        JSON.parse(interview.phaseTransitions);\n      completedPhases.push(...transitions.map(t => t.phase));\n    }\n\n    // Map phase names to dimension names\n    const phaseMapping: Record<string, string> = {\n      \"Requirements Clarification\": \"requirementsClarification\",\n      \"High-Level Design\": \"highLevelDesign\",\n      \"Deep Dive\": \"detailedDesign\",\n      \"Scalability & Trade-offs\": \"scalability\",\n      \"Wrap-up\": \"communication\"\n    };\n\n    // Build phase completion message for AI\n    const phaseCompletionInfo = `\n## Phases Actually Completed\n${completedPhases.length > 0 ? completedPhases.map(p => `- ${p}`).join('\\n') : '- None (interview ended early)'}\n\n**CRITICAL SCORING RULE:** \n- ONLY evaluate and score phases that were actually completed (listed above)\n- For phases NOT completed, you MUST assign a score of 1\n- For example, if only \"Requirements Clarification\" and \"High-Level Design\" were completed:\n  * Score requirementsClarification and highLevelDesign based on performance\n  * detailedDesign MUST be 1\n  * scalability MUST be 1\n  * tradeoffs MUST be 1 (unless discussed in completed phases)\n  * communication can be scored based on overall communication in completed phases\n\nDo NOT give credit for phases that were never reached.\n`;\n\n    // Add metadata about message counts to help AI evaluate accurately\n    const messageStats = `\n## Interview Statistics\n- Total user messages: ${userMessages.length}\n- Substantive user responses (>10 words): ${substantiveUserMessages.length}\n- Total interviewer questions: ${assistantMessages.length}\n\n**IMPORTANT: If substantive user responses is 0 or very low, the candidate did not meaningfully participate. Score ALL dimensions as 1.**\n`;\n\n    // Get AI scoring\n    const completion = await openai.chat.completions.create({\n      model: \"gpt-4o-mini\",\n      messages: [\n        { role: \"system\", content: SCORING_PROMPT },\n        {\n          role: \"user\",\n          content: `Interview Topic: ${interview.topic}\\n${phaseCompletionInfo}\\n${messageStats}\\n\\nConversation:\\n${conversationText}`,\n        },\n      ],\n      response_format: { type: \"json_object\" },\n      max_tokens: 1500,\n    });\n\n    const scoreText = completion.choices[0]?.message?.content;\n\n    if (!scoreText) {\n      throw new Error(\"Failed to generate score\");\n    }\n\n    const scoreData = JSON.parse(scoreText);\n\n    // Calculate weighted overall score\n    const weights = {\n      requirementsClarification: 0.10,\n      highLevelDesign: 0.20,\n      detailedDesign: 0.15,\n      scalability: 0.20,\n      tradeoffs: 0.25,\n      communication: 0.10,\n    };\n\n    const overallScore =\n      scoreData.requirementsClarification * weights.requirementsClarification +\n      scoreData.highLevelDesign * weights.highLevelDesign +\n      scoreData.detailedDesign * weights.detailedDesign +\n      scoreData.scalability * weights.scalability +\n      scoreData.tradeoffs * weights.tradeoffs +\n      scoreData.communication * weights.communication;\n\n    // Determine pass status\n    const allDimensions = [\n      scoreData.requirementsClarification,\n      scoreData.highLevelDesign,\n      scoreData.detailedDesign,\n      scoreData.scalability,\n      scoreData.tradeoffs,\n      scoreData.communication,\n    ];\n\n    const passStatus =\n      overallScore >= 2.5 &&\n      allDimensions.every((d: number) => d >= 2) &&\n      scoreData.tradeoffs >= 3;\n\n    // Calculate phase durations from transitions\n    let phaseDurations: Record<string, number> = {};\n    if (interview.phaseTransitions) {\n      const transitions: Array<{ phase: string; startedAt: string; endedAt?: string }> =\n        JSON.parse(interview.phaseTransitions);\n\n      for (const transition of transitions) {\n        const endTime = transition.endedAt || new Date().toISOString();\n        const duration = Math.round(\n          (new Date(endTime).getTime() - new Date(transition.startedAt).getTime()) / 1000\n        );\n        phaseDurations[transition.phase] = duration;\n      }\n    }\n\n    // Create score record\n    const score = await prisma.score.create({\n      data: {\n        interviewId: id,\n        requirementsClarification: scoreData.requirementsClarification,\n        highLevelDesign: scoreData.highLevelDesign,\n        detailedDesign: scoreData.detailedDesign,\n        scalability: scoreData.scalability,\n        tradeoffs: scoreData.tradeoffs,\n        communication: scoreData.communication,\n        overallScore,\n        passStatus,\n        feedback: JSON.stringify(scoreData.feedback),\n      },\n    });\n\n    // Update interview status with phase durations\n    await prisma.interview.update({\n      where: { id },\n      data: {\n        status: \"completed\",\n        endedAt: new Date(),\n        phaseDurations: Object.keys(phaseDurations).length > 0\n          ? JSON.stringify(phaseDurations)\n          : null,\n      },\n    });\n\n    // Update user analytics cache (async, don't wait)\n    updateUserAnalyticsCache(session.user.id).catch((err) =>\n      console.error(\"Failed to update analytics cache:\", err)\n    );\n\n    return NextResponse.json({\n      score: {\n        ...score,\n        feedback: scoreData.feedback,\n      },\n    });\n  } catch (error) {\n    console.error(\"End interview error:\", error);\n    return NextResponse.json(\n      { error: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AAEO,eAAe,KACpB,OAAoB,EACpB,EAAE,MAAM,EAAuC;IAE/C,IAAI;QACF,MAAM,UAAU,MAAM,IAAA,qMAAI;QAE1B,IAAI,CAAC,SAAS,MAAM,IAAI;YACtB,OAAO,yNAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAe,GAAG;gBAAE,QAAQ;YAAI;QACpE;QAEA,MAAM,oBAAoB,MAAM,IAAA,mNAAS,EAAC,SAAS,qNAAW,CAAC,EAAE,EAAE,qBAAqB,QAAQ,IAAI,CAAC,EAAE;QACvG,IAAI,mBAAmB,OAAO;QAE9B,MAAM,EAAE,EAAE,EAAE,GAAG,MAAM;QAErB,mDAAmD;QACnD,MAAM,YAAY,MAAM,yMAAM,CAAC,SAAS,CAAC,SAAS,CAAC;YACjD,OAAO;gBACL;gBACA,QAAQ,QAAQ,IAAI,CAAC,EAAE;YACzB;YACA,SAAS;gBACP,UAAU;oBACR,SAAS;wBAAE,WAAW;oBAAM;gBAC9B;YACF;QACF;QAEA,IAAI,CAAC,WAAW;YACd,OAAO,yNAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAsB,GAAG;gBAAE,QAAQ;YAAI;QAC3E;QAEA,IAAI,UAAU,MAAM,KAAK,aAAa;YACpC,OAAO,yNAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAA8B,GAAG;gBAAE,QAAQ;YAAI;QACnF;QAEA,iCAAiC;QACjC,MAAM,eAAe,UAAU,QAAQ,CAAC,MAAM,CAAC,CAAC,IAAM,EAAE,IAAI,KAAK;QACjE,MAAM,oBAAoB,UAAU,QAAQ,CAAC,MAAM,CAAC,CAAC,IAAM,EAAE,IAAI,KAAK;QAEtE,yEAAyE;QACzE,MAAM,0BAA0B,aAAa,MAAM,CACjD,CAAC,IAAM,EAAE,OAAO,CAAC,IAAI,GAAG,KAAK,CAAC,OAAO,MAAM,GAAG,GAAG,qBAAqB;;QAGxE,MAAM,mBAAmB,UAAU,QAAQ,CACxC,MAAM,CAAC,CAAC,IAAM,EAAE,IAAI,KAAK,UACzB,GAAG,CAAC,CAAC,IAAM,GAAG,EAAE,IAAI,CAAC,WAAW,GAAG,EAAE,EAAE,EAAE,OAAO,EAAE,EAClD,IAAI,CAAC;QAER,iDAAiD;QACjD,MAAM,kBAA4B,EAAE;QACpC,IAAI,UAAU,gBAAgB,EAAE;YAC9B,MAAM,cACJ,KAAK,KAAK,CAAC,UAAU,gBAAgB;YACvC,gBAAgB,IAAI,IAAI,YAAY,GAAG,CAAC,CAAA,IAAK,EAAE,KAAK;QACtD;QAEA,qCAAqC;QACrC,MAAM,eAAuC;YAC3C,8BAA8B;YAC9B,qBAAqB;YACrB,aAAa;YACb,4BAA4B;YAC5B,WAAW;QACb;QAEA,wCAAwC;QACxC,MAAM,sBAAsB,CAAC;;AAEjC,EAAE,gBAAgB,MAAM,GAAG,IAAI,gBAAgB,GAAG,CAAC,CAAA,IAAK,CAAC,EAAE,EAAE,GAAG,EAAE,IAAI,CAAC,QAAQ,iCAAiC;;;;;;;;;;;;;AAahH,CAAC;QAEG,mEAAmE;QACnE,MAAM,eAAe,CAAC;;uBAEH,EAAE,aAAa,MAAM,CAAC;0CACH,EAAE,wBAAwB,MAAM,CAAC;+BAC5C,EAAE,kBAAkB,MAAM,CAAC;;;AAG1D,CAAC;QAEG,iBAAiB;QACjB,MAAM,aAAa,MAAM,yMAAM,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACtD,OAAO;YACP,UAAU;gBACR;oBAAE,MAAM;oBAAU,SAAS,iOAAc;gBAAC;gBAC1C;oBACE,MAAM;oBACN,SAAS,CAAC,iBAAiB,EAAE,UAAU,KAAK,CAAC,EAAE,EAAE,oBAAoB,EAAE,EAAE,aAAa,mBAAmB,EAAE,kBAAkB;gBAC/H;aACD;YACD,iBAAiB;gBAAE,MAAM;YAAc;YACvC,YAAY;QACd;QAEA,MAAM,YAAY,WAAW,OAAO,CAAC,EAAE,EAAE,SAAS;QAElD,IAAI,CAAC,WAAW;YACd,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,YAAY,KAAK,KAAK,CAAC;QAE7B,mCAAmC;QACnC,MAAM,UAAU;YACd,2BAA2B;YAC3B,iBAAiB;YACjB,gBAAgB;YAChB,aAAa;YACb,WAAW;YACX,eAAe;QACjB;QAEA,MAAM,eACJ,UAAU,yBAAyB,GAAG,QAAQ,yBAAyB,GACvE,UAAU,eAAe,GAAG,QAAQ,eAAe,GACnD,UAAU,cAAc,GAAG,QAAQ,cAAc,GACjD,UAAU,WAAW,GAAG,QAAQ,WAAW,GAC3C,UAAU,SAAS,GAAG,QAAQ,SAAS,GACvC,UAAU,aAAa,GAAG,QAAQ,aAAa;QAEjD,wBAAwB;QACxB,MAAM,gBAAgB;YACpB,UAAU,yBAAyB;YACnC,UAAU,eAAe;YACzB,UAAU,cAAc;YACxB,UAAU,WAAW;YACrB,UAAU,SAAS;YACnB,UAAU,aAAa;SACxB;QAED,MAAM,aACJ,gBAAgB,OAChB,cAAc,KAAK,CAAC,CAAC,IAAc,KAAK,MACxC,UAAU,SAAS,IAAI;QAEzB,6CAA6C;QAC7C,IAAI,iBAAyC,CAAC;QAC9C,IAAI,UAAU,gBAAgB,EAAE;YAC9B,MAAM,cACJ,KAAK,KAAK,CAAC,UAAU,gBAAgB;YAEvC,KAAK,MAAM,cAAc,YAAa;gBACpC,MAAM,UAAU,WAAW,OAAO,IAAI,IAAI,OAAO,WAAW;gBAC5D,MAAM,WAAW,KAAK,KAAK,CACzB,CAAC,IAAI,KAAK,SAAS,OAAO,KAAK,IAAI,KAAK,WAAW,SAAS,EAAE,OAAO,EAAE,IAAI;gBAE7E,cAAc,CAAC,WAAW,KAAK,CAAC,GAAG;YACrC;QACF;QAEA,sBAAsB;QACtB,MAAM,QAAQ,MAAM,yMAAM,CAAC,KAAK,CAAC,MAAM,CAAC;YACtC,MAAM;gBACJ,aAAa;gBACb,2BAA2B,UAAU,yBAAyB;gBAC9D,iBAAiB,UAAU,eAAe;gBAC1C,gBAAgB,UAAU,cAAc;gBACxC,aAAa,UAAU,WAAW;gBAClC,WAAW,UAAU,SAAS;gBAC9B,eAAe,UAAU,aAAa;gBACtC;gBACA;gBACA,UAAU,KAAK,SAAS,CAAC,UAAU,QAAQ;YAC7C;QACF;QAEA,+CAA+C;QAC/C,MAAM,yMAAM,CAAC,SAAS,CAAC,MAAM,CAAC;YAC5B,OAAO;gBAAE;YAAG;YACZ,MAAM;gBACJ,QAAQ;gBACR,SAAS,IAAI;gBACb,gBAAgB,OAAO,IAAI,CAAC,gBAAgB,MAAM,GAAG,IACjD,KAAK,SAAS,CAAC,kBACf;YACN;QACF;QAEA,kDAAkD;QAClD,IAAA,0PAAwB,EAAC,QAAQ,IAAI,CAAC,EAAE,EAAE,KAAK,CAAC,CAAC,MAC/C,QAAQ,KAAK,CAAC,qCAAqC;QAGrD,OAAO,yNAAY,CAAC,IAAI,CAAC;YACvB,OAAO;gBACL,GAAG,KAAK;gBACR,UAAU,UAAU,QAAQ;YAC9B;QACF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wBAAwB;QACtC,OAAO,yNAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}