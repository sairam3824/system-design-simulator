{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 70, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/internal/class.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n * WARNING: This is an internal file that is subject to change!\n *\n * ðŸ›‘ Under no circumstances should you import this file directly! ðŸ›‘\n *\n * Please import the `PrismaClient` class from the `client.ts` file instead.\n */\n\nimport * as runtime from \"@prisma/client/runtime/client\"\nimport type * as Prisma from \"./prismaNamespace\"\n\n\nconst config: runtime.GetPrismaClientConfig = {\n  \"previewFeatures\": [],\n  \"clientVersion\": \"7.3.0\",\n  \"engineVersion\": \"9d6ad21cbbceab97458517b147a6a09ff43aa735\",\n  \"activeProvider\": \"sqlite\",\n  \"inlineSchema\": \"// Prisma schema for AI System Design Simulator\\ngenerator client {\\n  provider = \\\"prisma-client\\\"\\n  output   = \\\"../src/generated/prisma\\\"\\n}\\n\\ndatasource db {\\n  provider = \\\"sqlite\\\"\\n}\\n\\nmodel User {\\n  id        String   @id @default(cuid())\\n  email     String   @unique\\n  password  String\\n  name      String?\\n  avatar    String?\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n\\n  profile    Profile?\\n  resumes    Resume[]\\n  interviews Interview[]\\n}\\n\\nmodel Profile {\\n  id     String @id @default(cuid())\\n  userId String @unique\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  bio             String?\\n  yearsExperience Int?\\n  skills          String  @default(\\\"[]\\\") // JSON array stored as string\\n  targetCompanies String  @default(\\\"[]\\\") // JSON array stored as string\\n  targetRole      String?\\n\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n}\\n\\nmodel Resume {\\n  id     String @id @default(cuid())\\n  userId String\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  fileName String\\n  content  String // Full text content of resume\\n  analysis String? // JSON object with AI analysis\\n  filePath String? // Local path to the stored resume file\\n\\n  // ATS Score Data\\n  atsScore       Int? // Total ATS score (0-100)\\n  atsBreakdown   String? // JSON: { contactInfo, structure, experience, keywords, impact }\\n  atsFeedback    String? // JSON array of feedback strings\\n  keywords       String? // JSON array of extracted keywords\\n  softSkills     String? // JSON array of soft skills\\n  predictedRoles String? // JSON array of predicted job roles\\n\\n  uploadedAt DateTime @default(now())\\n  updatedAt  DateTime @updatedAt\\n}\\n\\nmodel Interview {\\n  id     String @id @default(cuid())\\n  userId String\\n  user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)\\n\\n  topic      String // e.g., \\\"Design Twitter\\\", \\\"Design Uber\\\"\\n  difficulty String @default(\\\"medium\\\") // easy, medium, hard\\n  status     String @default(\\\"pending\\\") // pending, in_progress, completed\\n\\n  startedAt DateTime?\\n  endedAt   DateTime?\\n  createdAt DateTime  @default(now())\\n\\n  messages Message[]\\n  score    Score?\\n}\\n\\nmodel Message {\\n  id          String    @id @default(cuid())\\n  interviewId String\\n  interview   Interview @relation(fields: [interviewId], references: [id], onDelete: Cascade)\\n\\n  role    String // user, assistant, system\\n  content String\\n\\n  timestamp DateTime @default(now())\\n}\\n\\nmodel Score {\\n  id          String    @id @default(cuid())\\n  interviewId String    @unique\\n  interview   Interview @relation(fields: [interviewId], references: [id], onDelete: Cascade)\\n\\n  // 6 Industry-Standard FAANG Evaluation Dimensions (1-4 scale)\\n  requirementsClarification Int @default(0)\\n  highLevelDesign           Int @default(0)\\n  detailedDesign            Int @default(0)\\n  scalability               Int @default(0)\\n  tradeoffs                 Int @default(0)\\n  communication             Int @default(0)\\n\\n  // Calculated fields\\n  overallScore Float   @default(0) // Weighted average\\n  passStatus   Boolean @default(false)\\n\\n  // Detailed feedback as JSON\\n  feedback String @default(\\\"{}\\\") // JSON with per-dimension comments\\n\\n  createdAt DateTime @default(now())\\n  updatedAt DateTime @updatedAt\\n}\\n\",\n  \"runtimeDataModel\": {\n    \"models\": {},\n    \"enums\": {},\n    \"types\": {}\n  }\n}\n\nconfig.runtimeDataModel = JSON.parse(\"{\\\"models\\\":{\\\"User\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"email\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"password\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"name\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"avatar\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"profile\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Profile\\\",\\\"relationName\\\":\\\"ProfileToUser\\\"},{\\\"name\\\":\\\"resumes\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Resume\\\",\\\"relationName\\\":\\\"ResumeToUser\\\"},{\\\"name\\\":\\\"interviews\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Interview\\\",\\\"relationName\\\":\\\"InterviewToUser\\\"}],\\\"dbName\\\":null},\\\"Profile\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"ProfileToUser\\\"},{\\\"name\\\":\\\"bio\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"yearsExperience\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"skills\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"targetCompanies\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"targetRole\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"Resume\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"ResumeToUser\\\"},{\\\"name\\\":\\\"fileName\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"content\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"analysis\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"filePath\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"atsScore\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"atsBreakdown\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"atsFeedback\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"keywords\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"softSkills\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"predictedRoles\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"uploadedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"Interview\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"userId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"user\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"User\\\",\\\"relationName\\\":\\\"InterviewToUser\\\"},{\\\"name\\\":\\\"topic\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"difficulty\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"status\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"startedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"endedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"messages\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Message\\\",\\\"relationName\\\":\\\"InterviewToMessage\\\"},{\\\"name\\\":\\\"score\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Score\\\",\\\"relationName\\\":\\\"InterviewToScore\\\"}],\\\"dbName\\\":null},\\\"Message\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interviewId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interview\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Interview\\\",\\\"relationName\\\":\\\"InterviewToMessage\\\"},{\\\"name\\\":\\\"role\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"content\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"timestamp\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null},\\\"Score\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interviewId\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"interview\\\",\\\"kind\\\":\\\"object\\\",\\\"type\\\":\\\"Interview\\\",\\\"relationName\\\":\\\"InterviewToScore\\\"},{\\\"name\\\":\\\"requirementsClarification\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"highLevelDesign\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"detailedDesign\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"scalability\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"tradeoffs\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"communication\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Int\\\"},{\\\"name\\\":\\\"overallScore\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Float\\\"},{\\\"name\\\":\\\"passStatus\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"Boolean\\\"},{\\\"name\\\":\\\"feedback\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"String\\\"},{\\\"name\\\":\\\"createdAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"},{\\\"name\\\":\\\"updatedAt\\\",\\\"kind\\\":\\\"scalar\\\",\\\"type\\\":\\\"DateTime\\\"}],\\\"dbName\\\":null}},\\\"enums\\\":{},\\\"types\\\":{}}\")\n\nasync function decodeBase64AsWasm(wasmBase64: string): Promise<WebAssembly.Module> {\n  const { Buffer } = await import('node:buffer')\n  const wasmArray = Buffer.from(wasmBase64, 'base64')\n  return new WebAssembly.Module(wasmArray)\n}\n\nconfig.compilerWasm = {\n  getRuntime: async () => await import(\"@prisma/client/runtime/query_compiler_fast_bg.sqlite.mjs\"),\n\n  getQueryCompilerWasmModule: async () => {\n    const { wasm } = await import(\"@prisma/client/runtime/query_compiler_fast_bg.sqlite.wasm-base64.mjs\")\n    return await decodeBase64AsWasm(wasm)\n  },\n\n  importName: \"./query_compiler_fast_bg.js\"\n}\n\n\n\nexport type LogOptions<ClientOptions extends Prisma.PrismaClientOptions> =\n  'log' extends keyof ClientOptions ? ClientOptions['log'] extends Array<Prisma.LogLevel | Prisma.LogDefinition> ? Prisma.GetEvents<ClientOptions['log']> : never : never\n\nexport interface PrismaClientConstructor {\n    /**\n   * ## Prisma Client\n   * \n   * Type-safe database client for TypeScript\n   * @example\n   * ```\n   * const prisma = new PrismaClient()\n   * // Fetch zero or more Users\n   * const users = await prisma.user.findMany()\n   * ```\n   * \n   * Read more in our [docs](https://pris.ly/d/client).\n   */\n\n  new <\n    Options extends Prisma.PrismaClientOptions = Prisma.PrismaClientOptions,\n    LogOpts extends LogOptions<Options> = LogOptions<Options>,\n    OmitOpts extends Prisma.PrismaClientOptions['omit'] = Options extends { omit: infer U } ? U : Prisma.PrismaClientOptions['omit'],\n    ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs\n  >(options: Prisma.Subset<Options, Prisma.PrismaClientOptions> ): PrismaClient<LogOpts, OmitOpts, ExtArgs>\n}\n\n/**\n * ## Prisma Client\n * \n * Type-safe database client for TypeScript\n * @example\n * ```\n * const prisma = new PrismaClient()\n * // Fetch zero or more Users\n * const users = await prisma.user.findMany()\n * ```\n * \n * Read more in our [docs](https://pris.ly/d/client).\n */\n\nexport interface PrismaClient<\n  in LogOpts extends Prisma.LogLevel = never,\n  in out OmitOpts extends Prisma.PrismaClientOptions['omit'] = undefined,\n  in out ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs\n> {\n  [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['other'] }\n\n  $on<V extends LogOpts>(eventType: V, callback: (event: V extends 'query' ? Prisma.QueryEvent : Prisma.LogEvent) => void): PrismaClient;\n\n  /**\n   * Connect with the database\n   */\n  $connect(): runtime.Types.Utils.JsPromise<void>;\n\n  /**\n   * Disconnect from the database\n   */\n  $disconnect(): runtime.Types.Utils.JsPromise<void>;\n\n/**\n   * Executes a prepared raw query and returns the number of affected rows.\n   * @example\n   * ```\n   * const result = await prisma.$executeRaw`UPDATE User SET cool = ${true} WHERE email = ${'user@email.com'};`\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $executeRaw<T = unknown>(query: TemplateStringsArray | Prisma.Sql, ...values: any[]): Prisma.PrismaPromise<number>;\n\n  /**\n   * Executes a raw query and returns the number of affected rows.\n   * Susceptible to SQL injections, see documentation.\n   * @example\n   * ```\n   * const result = await prisma.$executeRawUnsafe('UPDATE User SET cool = $1 WHERE email = $2 ;', true, 'user@email.com')\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $executeRawUnsafe<T = unknown>(query: string, ...values: any[]): Prisma.PrismaPromise<number>;\n\n  /**\n   * Performs a prepared raw query and returns the `SELECT` data.\n   * @example\n   * ```\n   * const result = await prisma.$queryRaw`SELECT * FROM User WHERE id = ${1} OR email = ${'user@email.com'};`\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $queryRaw<T = unknown>(query: TemplateStringsArray | Prisma.Sql, ...values: any[]): Prisma.PrismaPromise<T>;\n\n  /**\n   * Performs a raw query and returns the `SELECT` data.\n   * Susceptible to SQL injections, see documentation.\n   * @example\n   * ```\n   * const result = await prisma.$queryRawUnsafe('SELECT * FROM User WHERE id = $1 OR email = $2;', 1, 'user@email.com')\n   * ```\n   *\n   * Read more in our [docs](https://pris.ly/d/raw-queries).\n   */\n  $queryRawUnsafe<T = unknown>(query: string, ...values: any[]): Prisma.PrismaPromise<T>;\n\n\n  /**\n   * Allows the running of a sequence of read/write operations that are guaranteed to either succeed or fail as a whole.\n   * @example\n   * ```\n   * const [george, bob, alice] = await prisma.$transaction([\n   *   prisma.user.create({ data: { name: 'George' } }),\n   *   prisma.user.create({ data: { name: 'Bob' } }),\n   *   prisma.user.create({ data: { name: 'Alice' } }),\n   * ])\n   * ```\n   * \n   * Read more in our [docs](https://www.prisma.io/docs/concepts/components/prisma-client/transactions).\n   */\n  $transaction<P extends Prisma.PrismaPromise<any>[]>(arg: [...P], options?: { isolationLevel?: Prisma.TransactionIsolationLevel }): runtime.Types.Utils.JsPromise<runtime.Types.Utils.UnwrapTuple<P>>\n\n  $transaction<R>(fn: (prisma: Omit<PrismaClient, runtime.ITXClientDenyList>) => runtime.Types.Utils.JsPromise<R>, options?: { maxWait?: number, timeout?: number, isolationLevel?: Prisma.TransactionIsolationLevel }): runtime.Types.Utils.JsPromise<R>\n\n  $extends: runtime.Types.Extensions.ExtendsHook<\"extends\", Prisma.TypeMapCb<OmitOpts>, ExtArgs, runtime.Types.Utils.Call<Prisma.TypeMapCb<OmitOpts>, {\n    extArgs: ExtArgs\n  }>>\n\n      /**\n   * `prisma.user`: Exposes CRUD operations for the **User** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Users\n    * const users = await prisma.user.findMany()\n    * ```\n    */\n  get user(): Prisma.UserDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.profile`: Exposes CRUD operations for the **Profile** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Profiles\n    * const profiles = await prisma.profile.findMany()\n    * ```\n    */\n  get profile(): Prisma.ProfileDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.resume`: Exposes CRUD operations for the **Resume** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Resumes\n    * const resumes = await prisma.resume.findMany()\n    * ```\n    */\n  get resume(): Prisma.ResumeDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.interview`: Exposes CRUD operations for the **Interview** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Interviews\n    * const interviews = await prisma.interview.findMany()\n    * ```\n    */\n  get interview(): Prisma.InterviewDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.message`: Exposes CRUD operations for the **Message** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Messages\n    * const messages = await prisma.message.findMany()\n    * ```\n    */\n  get message(): Prisma.MessageDelegate<ExtArgs, { omit: OmitOpts }>;\n\n  /**\n   * `prisma.score`: Exposes CRUD operations for the **Score** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Scores\n    * const scores = await prisma.score.findMany()\n    * ```\n    */\n  get score(): Prisma.ScoreDelegate<ExtArgs, { omit: OmitOpts }>;\n}\n\nexport function getPrismaClientClass(): PrismaClientConstructor {\n  return runtime.getPrismaClient(config) as unknown as PrismaClientConstructor\n}\n"],"names":[],"mappings":";;;;AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;;;CAMC,GAED;;AAIA,MAAM,SAAwC;IAC5C,mBAAmB,EAAE;IACrB,iBAAiB;IACjB,iBAAiB;IACjB,kBAAkB;IAClB,gBAAgB;IAChB,oBAAoB;QAClB,UAAU,CAAC;QACX,SAAS,CAAC;QACV,SAAS,CAAC;IACZ;AACF;AAEA,OAAO,gBAAgB,GAAG,KAAK,KAAK,CAAC;AAErC,eAAe,mBAAmB,UAAkB;IAClD,MAAM,EAAE,MAAM,EAAE,GAAG;IACnB,MAAM,YAAY,OAAO,IAAI,CAAC,YAAY;IAC1C,OAAO,IAAI,YAAY,MAAM,CAAC;AAChC;AAEA,OAAO,YAAY,GAAG;IACpB,YAAY,UAAY;IAExB,4BAA4B;QAC1B,MAAM,EAAE,IAAI,EAAE,GAAG;QACjB,OAAO,MAAM,mBAAmB;IAClC;IAEA,YAAY;AACd;AAgMO,SAAS;IACd,OAAO,4TAAuB,CAAC;AACjC"}},
    {"offset": {"line": 117, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/internal/prismaNamespace.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n * WARNING: This is an internal file that is subject to change!\n *\n * ðŸ›‘ Under no circumstances should you import this file directly! ðŸ›‘\n *\n * All exports from this file are wrapped under a `Prisma` namespace object in the client.ts file.\n * While this enables partial backward compatibility, it is not part of the stable public API.\n *\n * If you are looking for your Models, Enums, and Input Types, please import them from the respective\n * model files in the `model` directory!\n */\n\nimport * as runtime from \"@prisma/client/runtime/client\"\nimport type * as Prisma from \"../models\"\nimport { type PrismaClient } from \"./class\"\n\nexport type * from '../models'\n\nexport type DMMF = typeof runtime.DMMF\n\nexport type PrismaPromise<T> = runtime.Types.Public.PrismaPromise<T>\n\n/**\n * Prisma Errors\n */\n\nexport const PrismaClientKnownRequestError = runtime.PrismaClientKnownRequestError\nexport type PrismaClientKnownRequestError = runtime.PrismaClientKnownRequestError\n\nexport const PrismaClientUnknownRequestError = runtime.PrismaClientUnknownRequestError\nexport type PrismaClientUnknownRequestError = runtime.PrismaClientUnknownRequestError\n\nexport const PrismaClientRustPanicError = runtime.PrismaClientRustPanicError\nexport type PrismaClientRustPanicError = runtime.PrismaClientRustPanicError\n\nexport const PrismaClientInitializationError = runtime.PrismaClientInitializationError\nexport type PrismaClientInitializationError = runtime.PrismaClientInitializationError\n\nexport const PrismaClientValidationError = runtime.PrismaClientValidationError\nexport type PrismaClientValidationError = runtime.PrismaClientValidationError\n\n/**\n * Re-export of sql-template-tag\n */\nexport const sql = runtime.sqltag\nexport const empty = runtime.empty\nexport const join = runtime.join\nexport const raw = runtime.raw\nexport const Sql = runtime.Sql\nexport type Sql = runtime.Sql\n\n\n\n/**\n * Decimal.js\n */\nexport const Decimal = runtime.Decimal\nexport type Decimal = runtime.Decimal\n\nexport type DecimalJsLike = runtime.DecimalJsLike\n\n/**\n* Extensions\n*/\nexport type Extension = runtime.Types.Extensions.UserArgs\nexport const getExtensionContext = runtime.Extensions.getExtensionContext\nexport type Args<T, F extends runtime.Operation> = runtime.Types.Public.Args<T, F>\nexport type Payload<T, F extends runtime.Operation = never> = runtime.Types.Public.Payload<T, F>\nexport type Result<T, A, F extends runtime.Operation> = runtime.Types.Public.Result<T, A, F>\nexport type Exact<A, W> = runtime.Types.Public.Exact<A, W>\n\nexport type PrismaVersion = {\n  client: string\n  engine: string\n}\n\n/**\n * Prisma Client JS version: 7.3.0\n * Query Engine version: 9d6ad21cbbceab97458517b147a6a09ff43aa735\n */\nexport const prismaVersion: PrismaVersion = {\n  client: \"7.3.0\",\n  engine: \"9d6ad21cbbceab97458517b147a6a09ff43aa735\"\n}\n\n/**\n * Utility Types\n */\n\nexport type Bytes = runtime.Bytes\nexport type JsonObject = runtime.JsonObject\nexport type JsonArray = runtime.JsonArray\nexport type JsonValue = runtime.JsonValue\nexport type InputJsonObject = runtime.InputJsonObject\nexport type InputJsonArray = runtime.InputJsonArray\nexport type InputJsonValue = runtime.InputJsonValue\n\n\nexport const NullTypes = {\n  DbNull: runtime.NullTypes.DbNull as (new (secret: never) => typeof runtime.DbNull),\n  JsonNull: runtime.NullTypes.JsonNull as (new (secret: never) => typeof runtime.JsonNull),\n  AnyNull: runtime.NullTypes.AnyNull as (new (secret: never) => typeof runtime.AnyNull),\n}\n/**\n * Helper for filtering JSON entries that have `null` on the database (empty on the db)\n *\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n */\nexport const DbNull = runtime.DbNull\n\n/**\n * Helper for filtering JSON entries that have JSON `null` values (not empty on the db)\n *\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n */\nexport const JsonNull = runtime.JsonNull\n\n/**\n * Helper for filtering JSON entries that are `Prisma.DbNull` or `Prisma.JsonNull`\n *\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n */\nexport const AnyNull = runtime.AnyNull\n\n\ntype SelectAndInclude = {\n  select: any\n  include: any\n}\n\ntype SelectAndOmit = {\n  select: any\n  omit: any\n}\n\n/**\n * From T, pick a set of properties whose keys are in the union K\n */\ntype Prisma__Pick<T, K extends keyof T> = {\n    [P in K]: T[P];\n};\n\nexport type Enumerable<T> = T | Array<T>;\n\n/**\n * Subset\n * @desc From `T` pick properties that exist in `U`. Simple version of Intersection\n */\nexport type Subset<T, U> = {\n  [key in keyof T]: key extends keyof U ? T[key] : never;\n};\n\n/**\n * SelectSubset\n * @desc From `T` pick properties that exist in `U`. Simple version of Intersection.\n * Additionally, it validates, if both select and include are present. If the case, it errors.\n */\nexport type SelectSubset<T, U> = {\n  [key in keyof T]: key extends keyof U ? T[key] : never\n} &\n  (T extends SelectAndInclude\n    ? 'Please either choose `select` or `include`.'\n    : T extends SelectAndOmit\n      ? 'Please either choose `select` or `omit`.'\n      : {})\n\n/**\n * Subset + Intersection\n * @desc From `T` pick properties that exist in `U` and intersect `K`\n */\nexport type SubsetIntersection<T, U, K> = {\n  [key in keyof T]: key extends keyof U ? T[key] : never\n} &\n  K\n\ntype Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };\n\n/**\n * XOR is needed to have a real mutually exclusive union type\n * https://stackoverflow.com/questions/42123407/does-typescript-support-mutually-exclusive-types\n */\nexport type XOR<T, U> =\n  T extends object ?\n  U extends object ?\n    (Without<T, U> & U) | (Without<U, T> & T)\n  : U : T\n\n\n/**\n * Is T a Record?\n */\ntype IsObject<T extends any> = T extends Array<any>\n? False\n: T extends Date\n? False\n: T extends Uint8Array\n? False\n: T extends BigInt\n? False\n: T extends object\n? True\n: False\n\n\n/**\n * If it's T[], return T\n */\nexport type UnEnumerate<T extends unknown> = T extends Array<infer U> ? U : T\n\n/**\n * From ts-toolbelt\n */\n\ntype __Either<O extends object, K extends Key> = Omit<O, K> &\n  {\n    // Merge all but K\n    [P in K]: Prisma__Pick<O, P & keyof O> // With K possibilities\n  }[K]\n\ntype EitherStrict<O extends object, K extends Key> = Strict<__Either<O, K>>\n\ntype EitherLoose<O extends object, K extends Key> = ComputeRaw<__Either<O, K>>\n\ntype _Either<\n  O extends object,\n  K extends Key,\n  strict extends Boolean\n> = {\n  1: EitherStrict<O, K>\n  0: EitherLoose<O, K>\n}[strict]\n\nexport type Either<\n  O extends object,\n  K extends Key,\n  strict extends Boolean = 1\n> = O extends unknown ? _Either<O, K, strict> : never\n\nexport type Union = any\n\nexport type PatchUndefined<O extends object, O1 extends object> = {\n  [K in keyof O]: O[K] extends undefined ? At<O1, K> : O[K]\n} & {}\n\n/** Helper Types for \"Merge\" **/\nexport type IntersectOf<U extends Union> = (\n  U extends unknown ? (k: U) => void : never\n) extends (k: infer I) => void\n  ? I\n  : never\n\nexport type Overwrite<O extends object, O1 extends object> = {\n    [K in keyof O]: K extends keyof O1 ? O1[K] : O[K];\n} & {};\n\ntype _Merge<U extends object> = IntersectOf<Overwrite<U, {\n    [K in keyof U]-?: At<U, K>;\n}>>;\n\ntype Key = string | number | symbol;\ntype AtStrict<O extends object, K extends Key> = O[K & keyof O];\ntype AtLoose<O extends object, K extends Key> = O extends unknown ? AtStrict<O, K> : never;\nexport type At<O extends object, K extends Key, strict extends Boolean = 1> = {\n    1: AtStrict<O, K>;\n    0: AtLoose<O, K>;\n}[strict];\n\nexport type ComputeRaw<A extends any> = A extends Function ? A : {\n  [K in keyof A]: A[K];\n} & {};\n\nexport type OptionalFlat<O> = {\n  [K in keyof O]?: O[K];\n} & {};\n\ntype _Record<K extends keyof any, T> = {\n  [P in K]: T;\n};\n\n// cause typescript not to expand types and preserve names\ntype NoExpand<T> = T extends unknown ? T : never;\n\n// this type assumes the passed object is entirely optional\nexport type AtLeast<O extends object, K extends string> = NoExpand<\n  O extends unknown\n  ? | (K extends keyof O ? { [P in K]: O[P] } & O : O)\n    | {[P in keyof O as P extends K ? P : never]-?: O[P]} & O\n  : never>;\n\ntype _Strict<U, _U = U> = U extends unknown ? U & OptionalFlat<_Record<Exclude<Keys<_U>, keyof U>, never>> : never;\n\nexport type Strict<U extends object> = ComputeRaw<_Strict<U>>;\n/** End Helper Types for \"Merge\" **/\n\nexport type Merge<U extends object> = ComputeRaw<_Merge<Strict<U>>>;\n\nexport type Boolean = True | False\n\nexport type True = 1\n\nexport type False = 0\n\nexport type Not<B extends Boolean> = {\n  0: 1\n  1: 0\n}[B]\n\nexport type Extends<A1 extends any, A2 extends any> = [A1] extends [never]\n  ? 0 // anything `never` is false\n  : A1 extends A2\n  ? 1\n  : 0\n\nexport type Has<U extends Union, U1 extends Union> = Not<\n  Extends<Exclude<U1, U>, U1>\n>\n\nexport type Or<B1 extends Boolean, B2 extends Boolean> = {\n  0: {\n    0: 0\n    1: 1\n  }\n  1: {\n    0: 1\n    1: 1\n  }\n}[B1][B2]\n\nexport type Keys<U extends Union> = U extends unknown ? keyof U : never\n\nexport type GetScalarType<T, O> = O extends object ? {\n  [P in keyof T]: P extends keyof O\n    ? O[P]\n    : never\n} : never\n\ntype FieldPaths<\n  T,\n  U = Omit<T, '_avg' | '_sum' | '_count' | '_min' | '_max'>\n> = IsObject<T> extends True ? U : T\n\nexport type GetHavingFields<T> = {\n  [K in keyof T]: Or<\n    Or<Extends<'OR', K>, Extends<'AND', K>>,\n    Extends<'NOT', K>\n  > extends True\n    ? // infer is only needed to not hit TS limit\n      // based on the brilliant idea of Pierre-Antoine Mills\n      // https://github.com/microsoft/TypeScript/issues/30188#issuecomment-478938437\n      T[K] extends infer TK\n      ? GetHavingFields<UnEnumerate<TK> extends object ? Merge<UnEnumerate<TK>> : never>\n      : never\n    : {} extends FieldPaths<T[K]>\n    ? never\n    : K\n}[keyof T]\n\n/**\n * Convert tuple to union\n */\ntype _TupleToUnion<T> = T extends (infer E)[] ? E : never\ntype TupleToUnion<K extends readonly any[]> = _TupleToUnion<K>\nexport type MaybeTupleToUnion<T> = T extends any[] ? TupleToUnion<T> : T\n\n/**\n * Like `Pick`, but additionally can also accept an array of keys\n */\nexport type PickEnumerable<T, K extends Enumerable<keyof T> | keyof T> = Prisma__Pick<T, MaybeTupleToUnion<K>>\n\n/**\n * Exclude all keys with underscores\n */\nexport type ExcludeUnderscoreKeys<T extends string> = T extends `_${string}` ? never : T\n\n\nexport type FieldRef<Model, FieldType> = runtime.FieldRef<Model, FieldType>\n\ntype FieldRefInputType<Model, FieldType> = Model extends never ? never : FieldRef<Model, FieldType>\n\n\nexport const ModelName = {\n  User: 'User',\n  Profile: 'Profile',\n  Resume: 'Resume',\n  Interview: 'Interview',\n  Message: 'Message',\n  Score: 'Score'\n} as const\n\nexport type ModelName = (typeof ModelName)[keyof typeof ModelName]\n\n\n\nexport interface TypeMapCb<GlobalOmitOptions = {}> extends runtime.Types.Utils.Fn<{extArgs: runtime.Types.Extensions.InternalArgs }, runtime.Types.Utils.Record<string, any>> {\n  returns: TypeMap<this['params']['extArgs'], GlobalOmitOptions>\n}\n\nexport type TypeMap<ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs, GlobalOmitOptions = {}> = {\n  globalOmitOptions: {\n    omit: GlobalOmitOptions\n  }\n  meta: {\n    modelProps: \"user\" | \"profile\" | \"resume\" | \"interview\" | \"message\" | \"score\"\n    txIsolationLevel: TransactionIsolationLevel\n  }\n  model: {\n    User: {\n      payload: Prisma.$UserPayload<ExtArgs>\n      fields: Prisma.UserFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.UserFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.UserFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        findFirst: {\n          args: Prisma.UserFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.UserFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        findMany: {\n          args: Prisma.UserFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>[]\n        }\n        create: {\n          args: Prisma.UserCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        createMany: {\n          args: Prisma.UserCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.UserCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>[]\n        }\n        delete: {\n          args: Prisma.UserDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        update: {\n          args: Prisma.UserUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        deleteMany: {\n          args: Prisma.UserDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.UserUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.UserUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>[]\n        }\n        upsert: {\n          args: Prisma.UserUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$UserPayload>\n        }\n        aggregate: {\n          args: Prisma.UserAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateUser>\n        }\n        groupBy: {\n          args: Prisma.UserGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.UserGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.UserCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.UserCountAggregateOutputType> | number\n        }\n      }\n    }\n    Profile: {\n      payload: Prisma.$ProfilePayload<ExtArgs>\n      fields: Prisma.ProfileFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ProfileFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ProfileFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        findFirst: {\n          args: Prisma.ProfileFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ProfileFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        findMany: {\n          args: Prisma.ProfileFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>[]\n        }\n        create: {\n          args: Prisma.ProfileCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        createMany: {\n          args: Prisma.ProfileCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ProfileCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>[]\n        }\n        delete: {\n          args: Prisma.ProfileDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        update: {\n          args: Prisma.ProfileUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        deleteMany: {\n          args: Prisma.ProfileDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ProfileUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ProfileUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>[]\n        }\n        upsert: {\n          args: Prisma.ProfileUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ProfilePayload>\n        }\n        aggregate: {\n          args: Prisma.ProfileAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateProfile>\n        }\n        groupBy: {\n          args: Prisma.ProfileGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ProfileGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ProfileCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ProfileCountAggregateOutputType> | number\n        }\n      }\n    }\n    Resume: {\n      payload: Prisma.$ResumePayload<ExtArgs>\n      fields: Prisma.ResumeFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ResumeFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ResumeFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        findFirst: {\n          args: Prisma.ResumeFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ResumeFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        findMany: {\n          args: Prisma.ResumeFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>[]\n        }\n        create: {\n          args: Prisma.ResumeCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        createMany: {\n          args: Prisma.ResumeCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ResumeCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>[]\n        }\n        delete: {\n          args: Prisma.ResumeDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        update: {\n          args: Prisma.ResumeUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        deleteMany: {\n          args: Prisma.ResumeDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ResumeUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ResumeUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>[]\n        }\n        upsert: {\n          args: Prisma.ResumeUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ResumePayload>\n        }\n        aggregate: {\n          args: Prisma.ResumeAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateResume>\n        }\n        groupBy: {\n          args: Prisma.ResumeGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ResumeGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ResumeCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ResumeCountAggregateOutputType> | number\n        }\n      }\n    }\n    Interview: {\n      payload: Prisma.$InterviewPayload<ExtArgs>\n      fields: Prisma.InterviewFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.InterviewFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.InterviewFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        findFirst: {\n          args: Prisma.InterviewFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.InterviewFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        findMany: {\n          args: Prisma.InterviewFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>[]\n        }\n        create: {\n          args: Prisma.InterviewCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        createMany: {\n          args: Prisma.InterviewCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.InterviewCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>[]\n        }\n        delete: {\n          args: Prisma.InterviewDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        update: {\n          args: Prisma.InterviewUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        deleteMany: {\n          args: Prisma.InterviewDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.InterviewUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.InterviewUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>[]\n        }\n        upsert: {\n          args: Prisma.InterviewUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$InterviewPayload>\n        }\n        aggregate: {\n          args: Prisma.InterviewAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateInterview>\n        }\n        groupBy: {\n          args: Prisma.InterviewGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.InterviewGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.InterviewCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.InterviewCountAggregateOutputType> | number\n        }\n      }\n    }\n    Message: {\n      payload: Prisma.$MessagePayload<ExtArgs>\n      fields: Prisma.MessageFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.MessageFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.MessageFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        findFirst: {\n          args: Prisma.MessageFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.MessageFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        findMany: {\n          args: Prisma.MessageFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>[]\n        }\n        create: {\n          args: Prisma.MessageCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        createMany: {\n          args: Prisma.MessageCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.MessageCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>[]\n        }\n        delete: {\n          args: Prisma.MessageDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        update: {\n          args: Prisma.MessageUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        deleteMany: {\n          args: Prisma.MessageDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.MessageUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.MessageUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>[]\n        }\n        upsert: {\n          args: Prisma.MessageUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$MessagePayload>\n        }\n        aggregate: {\n          args: Prisma.MessageAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateMessage>\n        }\n        groupBy: {\n          args: Prisma.MessageGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.MessageGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.MessageCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.MessageCountAggregateOutputType> | number\n        }\n      }\n    }\n    Score: {\n      payload: Prisma.$ScorePayload<ExtArgs>\n      fields: Prisma.ScoreFieldRefs\n      operations: {\n        findUnique: {\n          args: Prisma.ScoreFindUniqueArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload> | null\n        }\n        findUniqueOrThrow: {\n          args: Prisma.ScoreFindUniqueOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        findFirst: {\n          args: Prisma.ScoreFindFirstArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload> | null\n        }\n        findFirstOrThrow: {\n          args: Prisma.ScoreFindFirstOrThrowArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        findMany: {\n          args: Prisma.ScoreFindManyArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>[]\n        }\n        create: {\n          args: Prisma.ScoreCreateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        createMany: {\n          args: Prisma.ScoreCreateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        createManyAndReturn: {\n          args: Prisma.ScoreCreateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>[]\n        }\n        delete: {\n          args: Prisma.ScoreDeleteArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        update: {\n          args: Prisma.ScoreUpdateArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        deleteMany: {\n          args: Prisma.ScoreDeleteManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateMany: {\n          args: Prisma.ScoreUpdateManyArgs<ExtArgs>\n          result: BatchPayload\n        }\n        updateManyAndReturn: {\n          args: Prisma.ScoreUpdateManyAndReturnArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>[]\n        }\n        upsert: {\n          args: Prisma.ScoreUpsertArgs<ExtArgs>\n          result: runtime.Types.Utils.PayloadToResult<Prisma.$ScorePayload>\n        }\n        aggregate: {\n          args: Prisma.ScoreAggregateArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.AggregateScore>\n        }\n        groupBy: {\n          args: Prisma.ScoreGroupByArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ScoreGroupByOutputType>[]\n        }\n        count: {\n          args: Prisma.ScoreCountArgs<ExtArgs>\n          result: runtime.Types.Utils.Optional<Prisma.ScoreCountAggregateOutputType> | number\n        }\n      }\n    }\n  }\n} & {\n  other: {\n    payload: any\n    operations: {\n      $executeRaw: {\n        args: [query: TemplateStringsArray | Sql, ...values: any[]],\n        result: any\n      }\n      $executeRawUnsafe: {\n        args: [query: string, ...values: any[]],\n        result: any\n      }\n      $queryRaw: {\n        args: [query: TemplateStringsArray | Sql, ...values: any[]],\n        result: any\n      }\n      $queryRawUnsafe: {\n        args: [query: string, ...values: any[]],\n        result: any\n      }\n    }\n  }\n}\n\n/**\n * Enums\n */\n\nexport const TransactionIsolationLevel = runtime.makeStrictEnum({\n  Serializable: 'Serializable'\n} as const)\n\nexport type TransactionIsolationLevel = (typeof TransactionIsolationLevel)[keyof typeof TransactionIsolationLevel]\n\n\nexport const UserScalarFieldEnum = {\n  id: 'id',\n  email: 'email',\n  password: 'password',\n  name: 'name',\n  avatar: 'avatar',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type UserScalarFieldEnum = (typeof UserScalarFieldEnum)[keyof typeof UserScalarFieldEnum]\n\n\nexport const ProfileScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  bio: 'bio',\n  yearsExperience: 'yearsExperience',\n  skills: 'skills',\n  targetCompanies: 'targetCompanies',\n  targetRole: 'targetRole',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type ProfileScalarFieldEnum = (typeof ProfileScalarFieldEnum)[keyof typeof ProfileScalarFieldEnum]\n\n\nexport const ResumeScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  fileName: 'fileName',\n  content: 'content',\n  analysis: 'analysis',\n  filePath: 'filePath',\n  atsScore: 'atsScore',\n  atsBreakdown: 'atsBreakdown',\n  atsFeedback: 'atsFeedback',\n  keywords: 'keywords',\n  softSkills: 'softSkills',\n  predictedRoles: 'predictedRoles',\n  uploadedAt: 'uploadedAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type ResumeScalarFieldEnum = (typeof ResumeScalarFieldEnum)[keyof typeof ResumeScalarFieldEnum]\n\n\nexport const InterviewScalarFieldEnum = {\n  id: 'id',\n  userId: 'userId',\n  topic: 'topic',\n  difficulty: 'difficulty',\n  status: 'status',\n  startedAt: 'startedAt',\n  endedAt: 'endedAt',\n  createdAt: 'createdAt'\n} as const\n\nexport type InterviewScalarFieldEnum = (typeof InterviewScalarFieldEnum)[keyof typeof InterviewScalarFieldEnum]\n\n\nexport const MessageScalarFieldEnum = {\n  id: 'id',\n  interviewId: 'interviewId',\n  role: 'role',\n  content: 'content',\n  timestamp: 'timestamp'\n} as const\n\nexport type MessageScalarFieldEnum = (typeof MessageScalarFieldEnum)[keyof typeof MessageScalarFieldEnum]\n\n\nexport const ScoreScalarFieldEnum = {\n  id: 'id',\n  interviewId: 'interviewId',\n  requirementsClarification: 'requirementsClarification',\n  highLevelDesign: 'highLevelDesign',\n  detailedDesign: 'detailedDesign',\n  scalability: 'scalability',\n  tradeoffs: 'tradeoffs',\n  communication: 'communication',\n  overallScore: 'overallScore',\n  passStatus: 'passStatus',\n  feedback: 'feedback',\n  createdAt: 'createdAt',\n  updatedAt: 'updatedAt'\n} as const\n\nexport type ScoreScalarFieldEnum = (typeof ScoreScalarFieldEnum)[keyof typeof ScoreScalarFieldEnum]\n\n\nexport const SortOrder = {\n  asc: 'asc',\n  desc: 'desc'\n} as const\n\nexport type SortOrder = (typeof SortOrder)[keyof typeof SortOrder]\n\n\nexport const NullsOrder = {\n  first: 'first',\n  last: 'last'\n} as const\n\nexport type NullsOrder = (typeof NullsOrder)[keyof typeof NullsOrder]\n\n\n\n/**\n * Field references\n */\n\n\n/**\n * Reference to a field of type 'String'\n */\nexport type StringFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'String'>\n    \n\n\n/**\n * Reference to a field of type 'DateTime'\n */\nexport type DateTimeFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'DateTime'>\n    \n\n\n/**\n * Reference to a field of type 'Int'\n */\nexport type IntFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Int'>\n    \n\n\n/**\n * Reference to a field of type 'Float'\n */\nexport type FloatFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Float'>\n    \n\n\n/**\n * Reference to a field of type 'Boolean'\n */\nexport type BooleanFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Boolean'>\n    \n\n/**\n * Batch Payload for updateMany & deleteMany & createMany\n */\nexport type BatchPayload = {\n  count: number\n}\n\nexport const defineExtension = runtime.Extensions.defineExtension as unknown as runtime.Types.Extensions.ExtendsHook<\"define\", TypeMapCb, runtime.Types.Extensions.DefaultArgs>\nexport type DefaultPrismaClient = PrismaClient\nexport type ErrorFormat = 'pretty' | 'colorless' | 'minimal'\nexport type PrismaClientOptions = ({\n  /**\n   * Instance of a Driver Adapter, e.g., like one provided by `@prisma/adapter-pg`.\n   */\n  adapter: runtime.SqlDriverAdapterFactory\n  accelerateUrl?: never\n} | {\n  /**\n   * Prisma Accelerate URL allowing the client to connect through Accelerate instead of a direct database.\n   */\n  accelerateUrl: string\n  adapter?: never\n}) & {\n  /**\n   * @default \"colorless\"\n   */\n  errorFormat?: ErrorFormat\n  /**\n   * @example\n   * ```\n   * // Shorthand for `emit: 'stdout'`\n   * log: ['query', 'info', 'warn', 'error']\n   * \n   * // Emit as events only\n   * log: [\n   *   { emit: 'event', level: 'query' },\n   *   { emit: 'event', level: 'info' },\n   *   { emit: 'event', level: 'warn' }\n   *   { emit: 'event', level: 'error' }\n   * ]\n   * \n   * / Emit as events and log to stdout\n   * og: [\n   *  { emit: 'stdout', level: 'query' },\n   *  { emit: 'stdout', level: 'info' },\n   *  { emit: 'stdout', level: 'warn' }\n   *  { emit: 'stdout', level: 'error' }\n   * \n   * ```\n   * Read more in our [docs](https://pris.ly/d/logging).\n   */\n  log?: (LogLevel | LogDefinition)[]\n  /**\n   * The default values for transactionOptions\n   * maxWait ?= 2000\n   * timeout ?= 5000\n   */\n  transactionOptions?: {\n    maxWait?: number\n    timeout?: number\n    isolationLevel?: TransactionIsolationLevel\n  }\n  /**\n   * Global configuration for omitting model fields by default.\n   * \n   * @example\n   * ```\n   * const prisma = new PrismaClient({\n   *   omit: {\n   *     user: {\n   *       password: true\n   *     }\n   *   }\n   * })\n   * ```\n   */\n  omit?: GlobalOmitConfig\n  /**\n   * SQL commenter plugins that add metadata to SQL queries as comments.\n   * Comments follow the sqlcommenter format: https://google.github.io/sqlcommenter/\n   * \n   * @example\n   * ```\n   * const prisma = new PrismaClient({\n   *   adapter,\n   *   comments: [\n   *     traceContext(),\n   *     queryInsights(),\n   *   ],\n   * })\n   * ```\n   */\n  comments?: runtime.SqlCommenterPlugin[]\n}\nexport type GlobalOmitConfig = {\n  user?: Prisma.UserOmit\n  profile?: Prisma.ProfileOmit\n  resume?: Prisma.ResumeOmit\n  interview?: Prisma.InterviewOmit\n  message?: Prisma.MessageOmit\n  score?: Prisma.ScoreOmit\n}\n\n/* Types for Logging */\nexport type LogLevel = 'info' | 'query' | 'warn' | 'error'\nexport type LogDefinition = {\n  level: LogLevel\n  emit: 'stdout' | 'event'\n}\n\nexport type CheckIsLogLevel<T> = T extends LogLevel ? T : never;\n\nexport type GetLogType<T> = CheckIsLogLevel<\n  T extends LogDefinition ? T['level'] : T\n>;\n\nexport type GetEvents<T extends any[]> = T extends Array<LogLevel | LogDefinition>\n  ? GetLogType<T[number]>\n  : never;\n\nexport type QueryEvent = {\n  timestamp: Date\n  query: string\n  params: string\n  duration: number\n  target: string\n}\n\nexport type LogEvent = {\n  timestamp: Date\n  message: string\n  target: string\n}\n/* End Types for Logging */\n\n\nexport type PrismaAction =\n  | 'findUnique'\n  | 'findUniqueOrThrow'\n  | 'findMany'\n  | 'findFirst'\n  | 'findFirstOrThrow'\n  | 'create'\n  | 'createMany'\n  | 'createManyAndReturn'\n  | 'update'\n  | 'updateMany'\n  | 'updateManyAndReturn'\n  | 'upsert'\n  | 'delete'\n  | 'deleteMany'\n  | 'executeRaw'\n  | 'queryRaw'\n  | 'aggregate'\n  | 'count'\n  | 'runCommandRaw'\n  | 'findRaw'\n  | 'groupBy'\n\n/**\n * `PrismaClient` proxy available in interactive transactions.\n */\nexport type TransactionClient = Omit<DefaultPrismaClient, runtime.ITXClientDenyList>\n\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;;;;;;;CAUC,GAED;;AAcO,MAAM,gCAAgC,0UAAqC;AAG3E,MAAM,kCAAkC,4UAAuC;AAG/E,MAAM,6BAA6B,uUAAkC;AAGrE,MAAM,kCAAkC,4UAAuC;AAG/E,MAAM,8BAA8B,wUAAmC;AAMvE,MAAM,MAAM,mTAAc;AAC1B,MAAM,QAAQ,kTAAa;AAC3B,MAAM,OAAO,iTAAY;AACzB,MAAM,MAAM,gTAAW;AACvB,MAAM,MAAM,gTAAW;AAQvB,MAAM,UAAU,oTAAe;AAS/B,MAAM,sBAAsB,uTAAkB,CAAC,mBAAmB;AAelE,MAAM,gBAA+B;IAC1C,QAAQ;IACR,QAAQ;AACV;AAeO,MAAM,YAAY;IACvB,QAAQ,sTAAiB,CAAC,MAAM;IAChC,UAAU,sTAAiB,CAAC,QAAQ;IACpC,SAAS,sTAAiB,CAAC,OAAO;AACpC;AAMO,MAAM,SAAS,mTAAc;AAO7B,MAAM,WAAW,qTAAgB;AAOjC,MAAM,UAAU,oTAAe;AAkQ/B,MAAM,YAAY;IACvB,MAAM;IACN,SAAS;IACT,QAAQ;IACR,WAAW;IACX,SAAS;IACT,OAAO;AACT;AA4eO,MAAM,4BAA4B,2TAAsB,CAAC;IAC9D,cAAc;AAChB;AAKO,MAAM,sBAAsB;IACjC,IAAI;IACJ,OAAO;IACP,UAAU;IACV,MAAM;IACN,QAAQ;IACR,WAAW;IACX,WAAW;AACb;AAKO,MAAM,yBAAyB;IACpC,IAAI;IACJ,QAAQ;IACR,KAAK;IACL,iBAAiB;IACjB,QAAQ;IACR,iBAAiB;IACjB,YAAY;IACZ,WAAW;IACX,WAAW;AACb;AAKO,MAAM,wBAAwB;IACnC,IAAI;IACJ,QAAQ;IACR,UAAU;IACV,SAAS;IACT,UAAU;IACV,UAAU;IACV,UAAU;IACV,cAAc;IACd,aAAa;IACb,UAAU;IACV,YAAY;IACZ,gBAAgB;IAChB,YAAY;IACZ,WAAW;AACb;AAKO,MAAM,2BAA2B;IACtC,IAAI;IACJ,QAAQ;IACR,OAAO;IACP,YAAY;IACZ,QAAQ;IACR,WAAW;IACX,SAAS;IACT,WAAW;AACb;AAKO,MAAM,yBAAyB;IACpC,IAAI;IACJ,aAAa;IACb,MAAM;IACN,SAAS;IACT,WAAW;AACb;AAKO,MAAM,uBAAuB;IAClC,IAAI;IACJ,aAAa;IACb,2BAA2B;IAC3B,iBAAiB;IACjB,gBAAgB;IAChB,aAAa;IACb,WAAW;IACX,eAAe;IACf,cAAc;IACd,YAAY;IACZ,UAAU;IACV,WAAW;IACX,WAAW;AACb;AAKO,MAAM,YAAY;IACvB,KAAK;IACL,MAAM;AACR;AAKO,MAAM,aAAa;IACxB,OAAO;IACP,MAAM;AACR;AAoDO,MAAM,kBAAkB,uTAAkB,CAAC,eAAe"}},
    {"offset": {"line": 305, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/enums.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n* This file exports all enum related types from the schema.\n*\n* ðŸŸ¢ You can import this file directly.\n*/\n\n\n\n// This file is empty because there are no enums in the schema.\nexport {}\n"],"names":[],"mappings":"AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;AAIA,GAIA,+DAA+D"}},
    {"offset": {"line": 318, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/generated/prisma/client.ts"],"sourcesContent":["\n/* !!! This is code generated by Prisma. Do not edit directly. !!! */\n/* eslint-disable */\n// biome-ignore-all lint: generated file\n// @ts-nocheck \n/*\n * This file should be your main import to use Prisma. Through it you get access to all the models, enums, and input types.\n * If you're looking for something you can import in the client-side of your application, please refer to the `browser.ts` file instead.\n *\n * ðŸŸ¢ You can import this file directly.\n */\n\nimport * as process from 'node:process'\nimport * as path from 'node:path'\nimport { fileURLToPath } from 'node:url'\nglobalThis['__dirname'] = path.dirname(fileURLToPath(import.meta.url))\n\nimport * as runtime from \"@prisma/client/runtime/client\"\nimport * as $Enums from \"./enums\"\nimport * as $Class from \"./internal/class\"\nimport * as Prisma from \"./internal/prismaNamespace\"\n\nexport * as $Enums from './enums'\nexport * from \"./enums\"\n/**\n * ## Prisma Client\n * \n * Type-safe database client for TypeScript\n * @example\n * ```\n * const prisma = new PrismaClient()\n * // Fetch zero or more Users\n * const users = await prisma.user.findMany()\n * ```\n * \n * Read more in our [docs](https://pris.ly/d/client).\n */\nexport const PrismaClient = $Class.getPrismaClientClass()\nexport type PrismaClient<LogOpts extends Prisma.LogLevel = never, OmitOpts extends Prisma.PrismaClientOptions[\"omit\"] = Prisma.PrismaClientOptions[\"omit\"], ExtArgs extends runtime.Types.Extensions.InternalArgs = runtime.Types.Extensions.DefaultArgs> = $Class.PrismaClient<LogOpts, OmitOpts, ExtArgs>\nexport { Prisma }\n\n/**\n * Model User\n * \n */\nexport type User = Prisma.UserModel\n/**\n * Model Profile\n * \n */\nexport type Profile = Prisma.ProfileModel\n/**\n * Model Resume\n * \n */\nexport type Resume = Prisma.ResumeModel\n/**\n * Model Interview\n * \n */\nexport type Interview = Prisma.InterviewModel\n/**\n * Model Message\n * \n */\nexport type Message = Prisma.MessageModel\n/**\n * Model Score\n * \n */\nexport type Score = Prisma.ScoreModel\n"],"names":[],"mappings":"AACA,mEAAmE,GACnE,kBAAkB,GAClB,wCAAwC;AACxC,eAAe;AACf;;;;;CAKC;;;;AAGD;AACA;AAKA;AACA;AAEA;;;;;;;;AAPA,UAAU,CAAC,YAAY,GAAG,4HAAY,CAAC,IAAA,gIAAa,EAAC,8BAAY,GAAG;;;;;AAsB7D,MAAM,eAAe,kPAA2B"}},
    {"offset": {"line": 354, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/prisma.ts"],"sourcesContent":["import { PrismaClient } from \"../generated/prisma/client\";\nimport { PrismaLibSql } from \"@prisma/adapter-libsql\";\n\nconst adapter = new PrismaLibSql({\n  url: process.env.DATABASE_URL || \"file:./dev.db\",\n});\n\nconst globalForPrisma = globalThis as unknown as {\n  prisma: PrismaClient | undefined;\n};\n\nexport const prisma = globalForPrisma.prisma ?? new PrismaClient({ adapter });\n\nif (process.env.NODE_ENV !== \"production\") globalForPrisma.prisma = prisma;\n\nexport default prisma;\n"],"names":[],"mappings":";;;;;;AAAA;AACA;;;;;;;AAEA,MAAM,UAAU,IAAI,kQAAY,CAAC;IAC/B,KAAK,QAAQ,GAAG,CAAC,YAAY,IAAI;AACnC;AAEA,MAAM,kBAAkB;AAIjB,MAAM,SAAS,gBAAgB,MAAM,IAAI,IAAI,+OAAY,CAAC;IAAE;AAAQ;AAE3E,wCAA2C,gBAAgB,MAAM,GAAG;uCAErD"}},
    {"offset": {"line": 384, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/auth.ts"],"sourcesContent":["import NextAuth from \"next-auth\";\nimport Credentials from \"next-auth/providers/credentials\";\nimport bcrypt from \"bcryptjs\";\nimport { prisma } from \"./prisma\";\n\nexport const { handlers, signIn, signOut, auth } = NextAuth({\n  providers: [\n    Credentials({\n      name: \"credentials\",\n      credentials: {\n        email: { label: \"Email\", type: \"email\" },\n        password: { label: \"Password\", type: \"password\" },\n      },\n      async authorize(credentials) {\n        if (!credentials?.email || !credentials?.password) {\n          return null;\n        }\n\n        const email = credentials.email as string;\n        const password = credentials.password as string;\n\n        const user = await prisma.user.findUnique({\n          where: { email },\n        });\n\n        if (!user) {\n          return null;\n        }\n\n        const isPasswordValid = await bcrypt.compare(password, user.password);\n\n        if (!isPasswordValid) {\n          return null;\n        }\n\n        return {\n          id: user.id,\n          email: user.email,\n          name: user.name,\n          image: user.avatar,\n        };\n      },\n    }),\n  ],\n  callbacks: {\n    async jwt({ token, user }) {\n      if (user) {\n        token.id = user.id;\n      }\n      return token;\n    },\n    async session({ session, token }) {\n      if (session.user) {\n        session.user.id = token.id as string;\n      }\n      return session;\n    },\n  },\n  pages: {\n    signIn: \"/login\",\n  },\n  session: {\n    strategy: \"jwt\",\n  },\n});\n"],"names":[],"mappings":";;;;;;;;;;AAAA;AACA;AAAA;AACA;AACA;;;;;;;;;AAEO,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,OAAO,EAAE,IAAI,EAAE,GAAG,IAAA,2OAAQ,EAAC;IAC1D,WAAW;QACT,IAAA,gPAAW,EAAC;YACV,MAAM;YACN,aAAa;gBACX,OAAO;oBAAE,OAAO;oBAAS,MAAM;gBAAQ;gBACvC,UAAU;oBAAE,OAAO;oBAAY,MAAM;gBAAW;YAClD;YACA,MAAM,WAAU,WAAW;gBACzB,IAAI,CAAC,aAAa,SAAS,CAAC,aAAa,UAAU;oBACjD,OAAO;gBACT;gBAEA,MAAM,QAAQ,YAAY,KAAK;gBAC/B,MAAM,WAAW,YAAY,QAAQ;gBAErC,MAAM,OAAO,MAAM,yMAAM,CAAC,IAAI,CAAC,UAAU,CAAC;oBACxC,OAAO;wBAAE;oBAAM;gBACjB;gBAEA,IAAI,CAAC,MAAM;oBACT,OAAO;gBACT;gBAEA,MAAM,kBAAkB,MAAM,uNAAM,CAAC,OAAO,CAAC,UAAU,KAAK,QAAQ;gBAEpE,IAAI,CAAC,iBAAiB;oBACpB,OAAO;gBACT;gBAEA,OAAO;oBACL,IAAI,KAAK,EAAE;oBACX,OAAO,KAAK,KAAK;oBACjB,MAAM,KAAK,IAAI;oBACf,OAAO,KAAK,MAAM;gBACpB;YACF;QACF;KACD;IACD,WAAW;QACT,MAAM,KAAI,EAAE,KAAK,EAAE,IAAI,EAAE;YACvB,IAAI,MAAM;gBACR,MAAM,EAAE,GAAG,KAAK,EAAE;YACpB;YACA,OAAO;QACT;QACA,MAAM,SAAQ,EAAE,OAAO,EAAE,KAAK,EAAE;YAC9B,IAAI,QAAQ,IAAI,EAAE;gBAChB,QAAQ,IAAI,CAAC,EAAE,GAAG,MAAM,EAAE;YAC5B;YACA,OAAO;QACT;IACF;IACA,OAAO;QACL,QAAQ;IACV;IACA,SAAS;QACP,UAAU;IACZ;AACF"}},
    {"offset": {"line": 474, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/ollama.ts"],"sourcesContent":["/**\n * Ollama Client for Local LLM Inference\n *\n * Uses Ollama running locally for faster interview interactions.\n * Default model: llama3 (8B)\n *\n * Make sure Ollama is running: ollama serve\n * Pull the model: ollama pull llama3\n */\n\nconst OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || \"http://localhost:11434\";\nconst OLLAMA_MODEL = process.env.OLLAMA_MODEL || \"llama3\";\n\nexport interface OllamaMessage {\n  role: \"system\" | \"user\" | \"assistant\";\n  content: string;\n}\n\nexport interface OllamaCompletionOptions {\n  model?: string;\n  messages: OllamaMessage[];\n  stream?: boolean;\n  temperature?: number;\n  max_tokens?: number;\n  top_p?: number;\n  stop?: string[];\n}\n\nexport interface OllamaResponse {\n  model: string;\n  created_at: string;\n  message: {\n    role: string;\n    content: string;\n  };\n  done: boolean;\n  total_duration?: number;\n  load_duration?: number;\n  prompt_eval_count?: number;\n  eval_count?: number;\n}\n\n/**\n * Check if Ollama is running and available\n */\nexport async function checkOllamaHealth(): Promise<boolean> {\n  try {\n    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {\n      method: \"GET\",\n    });\n    return response.ok;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * List available models\n */\nexport async function listModels(): Promise<string[]> {\n  try {\n    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);\n    if (!response.ok) return [];\n    const data = await response.json();\n    return data.models?.map((m: { name: string }) => m.name) || [];\n  } catch {\n    return [];\n  }\n}\n\n/**\n * Non-streaming chat completion\n */\nexport async function ollamaChat(\n  options: OllamaCompletionOptions\n): Promise<OllamaResponse> {\n  const { model = OLLAMA_MODEL, messages, temperature = 0.7 } = options;\n\n  const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\n      model,\n      messages,\n      stream: false,\n      options: {\n        temperature,\n        num_predict: options.max_tokens || 800,\n        top_p: options.top_p || 0.9,\n        stop: options.stop,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Ollama error: ${error}`);\n  }\n\n  return response.json();\n}\n\n/**\n * Streaming chat completion - returns a ReadableStream\n */\nexport async function ollamaChatStream(\n  options: OllamaCompletionOptions\n): Promise<ReadableStream<Uint8Array>> {\n  const { model = OLLAMA_MODEL, messages, temperature = 0.7 } = options;\n\n  const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\n      model,\n      messages,\n      stream: true,\n      options: {\n        temperature,\n        num_predict: options.max_tokens || 800,\n        top_p: options.top_p || 0.9,\n        stop: options.stop,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Ollama streaming error: ${error}`);\n  }\n\n  if (!response.body) {\n    throw new Error(\"No response body from Ollama\");\n  }\n\n  return response.body;\n}\n\n/**\n * Transform Ollama stream to SSE format for client consumption\n */\nexport function createOllamaSSEStream(\n  ollamaStream: ReadableStream<Uint8Array>\n): ReadableStream<Uint8Array> {\n  const encoder = new TextEncoder();\n  const decoder = new TextDecoder();\n\n  let buffer = \"\";\n\n  return new ReadableStream({\n    async start(controller) {\n      const reader = ollamaStream.getReader();\n\n      try {\n        while (true) {\n          const { done, value } = await reader.read();\n\n          if (done) {\n            controller.close();\n            break;\n          }\n\n          buffer += decoder.decode(value, { stream: true });\n\n          // Process complete JSON lines\n          const lines = buffer.split(\"\\n\");\n          buffer = lines.pop() || \"\";\n\n          for (const line of lines) {\n            if (line.trim()) {\n              try {\n                const json = JSON.parse(line);\n                if (json.message?.content) {\n                  // Send as SSE format\n                  const sseData = `data: ${JSON.stringify({ content: json.message.content })}\\n\\n`;\n                  controller.enqueue(encoder.encode(sseData));\n                }\n                if (json.done) {\n                  controller.enqueue(encoder.encode(\"data: [DONE]\\n\\n\"));\n                }\n              } catch {\n                // Skip invalid JSON lines\n              }\n            }\n          }\n        }\n      } catch (error) {\n        controller.error(error);\n      }\n    },\n  });\n}\n\n/**\n * Simple wrapper for interview chat - handles both streaming and non-streaming\n */\nexport const ollama = {\n  chat: {\n    completions: {\n      create: async (options: {\n        model?: string;\n        messages: OllamaMessage[];\n        temperature?: number;\n        max_tokens?: number;\n        stream?: boolean;\n      }) => {\n        if (options.stream) {\n          const stream = await ollamaChatStream({\n            model: options.model || OLLAMA_MODEL,\n            messages: options.messages,\n            temperature: options.temperature,\n            max_tokens: options.max_tokens,\n            stream: true,\n          });\n          return { body: createOllamaSSEStream(stream) };\n        } else {\n          const response = await ollamaChat({\n            model: options.model || OLLAMA_MODEL,\n            messages: options.messages,\n            temperature: options.temperature,\n            max_tokens: options.max_tokens,\n            stream: false,\n          });\n          return {\n            choices: [\n              {\n                message: {\n                  role: response.message.role,\n                  content: response.message.content,\n                },\n              },\n            ],\n          };\n        }\n      },\n    },\n  },\n};\n\nexport default ollama;\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;;;;;;;;CAQC,GAED,MAAM,kBAAkB,QAAQ,GAAG,CAAC,eAAe,IAAI;AACvD,MAAM,eAAe,QAAQ,GAAG,CAAC,YAAY,IAAI;AAkC1C,eAAe;IACpB,IAAI;QACF,MAAM,WAAW,MAAM,MAAM,GAAG,gBAAgB,SAAS,CAAC,EAAE;YAC1D,QAAQ;QACV;QACA,OAAO,SAAS,EAAE;IACpB,EAAE,OAAM;QACN,OAAO;IACT;AACF;AAKO,eAAe;IACpB,IAAI;QACF,MAAM,WAAW,MAAM,MAAM,GAAG,gBAAgB,SAAS,CAAC;QAC1D,IAAI,CAAC,SAAS,EAAE,EAAE,OAAO,EAAE;QAC3B,MAAM,OAAO,MAAM,SAAS,IAAI;QAChC,OAAO,KAAK,MAAM,EAAE,IAAI,CAAC,IAAwB,EAAE,IAAI,KAAK,EAAE;IAChE,EAAE,OAAM;QACN,OAAO,EAAE;IACX;AACF;AAKO,eAAe,WACpB,OAAgC;IAEhC,MAAM,EAAE,QAAQ,YAAY,EAAE,QAAQ,EAAE,cAAc,GAAG,EAAE,GAAG;IAE9D,MAAM,WAAW,MAAM,MAAM,GAAG,gBAAgB,SAAS,CAAC,EAAE;QAC1D,QAAQ;QACR,SAAS;YACP,gBAAgB;QAClB;QACA,MAAM,KAAK,SAAS,CAAC;YACnB;YACA;YACA,QAAQ;YACR,SAAS;gBACP;gBACA,aAAa,QAAQ,UAAU,IAAI;gBACnC,OAAO,QAAQ,KAAK,IAAI;gBACxB,MAAM,QAAQ,IAAI;YACpB;QACF;IACF;IAEA,IAAI,CAAC,SAAS,EAAE,EAAE;QAChB,MAAM,QAAQ,MAAM,SAAS,IAAI;QACjC,MAAM,IAAI,MAAM,CAAC,cAAc,EAAE,OAAO;IAC1C;IAEA,OAAO,SAAS,IAAI;AACtB;AAKO,eAAe,iBACpB,OAAgC;IAEhC,MAAM,EAAE,QAAQ,YAAY,EAAE,QAAQ,EAAE,cAAc,GAAG,EAAE,GAAG;IAE9D,MAAM,WAAW,MAAM,MAAM,GAAG,gBAAgB,SAAS,CAAC,EAAE;QAC1D,QAAQ;QACR,SAAS;YACP,gBAAgB;QAClB;QACA,MAAM,KAAK,SAAS,CAAC;YACnB;YACA;YACA,QAAQ;YACR,SAAS;gBACP;gBACA,aAAa,QAAQ,UAAU,IAAI;gBACnC,OAAO,QAAQ,KAAK,IAAI;gBACxB,MAAM,QAAQ,IAAI;YACpB;QACF;IACF;IAEA,IAAI,CAAC,SAAS,EAAE,EAAE;QAChB,MAAM,QAAQ,MAAM,SAAS,IAAI;QACjC,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,OAAO;IACpD;IAEA,IAAI,CAAC,SAAS,IAAI,EAAE;QAClB,MAAM,IAAI,MAAM;IAClB;IAEA,OAAO,SAAS,IAAI;AACtB;AAKO,SAAS,sBACd,YAAwC;IAExC,MAAM,UAAU,IAAI;IACpB,MAAM,UAAU,IAAI;IAEpB,IAAI,SAAS;IAEb,OAAO,IAAI,eAAe;QACxB,MAAM,OAAM,UAAU;YACpB,MAAM,SAAS,aAAa,SAAS;YAErC,IAAI;gBACF,MAAO,KAAM;oBACX,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,OAAO,IAAI;oBAEzC,IAAI,MAAM;wBACR,WAAW,KAAK;wBAChB;oBACF;oBAEA,UAAU,QAAQ,MAAM,CAAC,OAAO;wBAAE,QAAQ;oBAAK;oBAE/C,8BAA8B;oBAC9B,MAAM,QAAQ,OAAO,KAAK,CAAC;oBAC3B,SAAS,MAAM,GAAG,MAAM;oBAExB,KAAK,MAAM,QAAQ,MAAO;wBACxB,IAAI,KAAK,IAAI,IAAI;4BACf,IAAI;gCACF,MAAM,OAAO,KAAK,KAAK,CAAC;gCACxB,IAAI,KAAK,OAAO,EAAE,SAAS;oCACzB,qBAAqB;oCACrB,MAAM,UAAU,CAAC,MAAM,EAAE,KAAK,SAAS,CAAC;wCAAE,SAAS,KAAK,OAAO,CAAC,OAAO;oCAAC,GAAG,IAAI,CAAC;oCAChF,WAAW,OAAO,CAAC,QAAQ,MAAM,CAAC;gCACpC;gCACA,IAAI,KAAK,IAAI,EAAE;oCACb,WAAW,OAAO,CAAC,QAAQ,MAAM,CAAC;gCACpC;4BACF,EAAE,OAAM;4BACN,0BAA0B;4BAC5B;wBACF;oBACF;gBACF;YACF,EAAE,OAAO,OAAO;gBACd,WAAW,KAAK,CAAC;YACnB;QACF;IACF;AACF;AAKO,MAAM,SAAS;IACpB,MAAM;QACJ,aAAa;YACX,QAAQ,OAAO;gBAOb,IAAI,QAAQ,MAAM,EAAE;oBAClB,MAAM,SAAS,MAAM,iBAAiB;wBACpC,OAAO,QAAQ,KAAK,IAAI;wBACxB,UAAU,QAAQ,QAAQ;wBAC1B,aAAa,QAAQ,WAAW;wBAChC,YAAY,QAAQ,UAAU;wBAC9B,QAAQ;oBACV;oBACA,OAAO;wBAAE,MAAM,sBAAsB;oBAAQ;gBAC/C,OAAO;oBACL,MAAM,WAAW,MAAM,WAAW;wBAChC,OAAO,QAAQ,KAAK,IAAI;wBACxB,UAAU,QAAQ,QAAQ;wBAC1B,aAAa,QAAQ,WAAW;wBAChC,YAAY,QAAQ,UAAU;wBAC9B,QAAQ;oBACV;oBACA,OAAO;wBACL,SAAS;4BACP;gCACE,SAAS;oCACP,MAAM,SAAS,OAAO,CAAC,IAAI;oCAC3B,SAAS,SAAS,OAAO,CAAC,OAAO;gCACnC;4BACF;yBACD;oBACH;gBACF;YACF;QACF;IACF;AACF;uCAEe"}},
    {"offset": {"line": 662, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/difficulty-calculator.ts"],"sourcesContent":["/**\n * Smart Difficulty Calculator\n *\n * Calculates the actual interview difficulty based on user profile,\n * skills, experience, target companies, and resume analysis.\n *\n * Weightages:\n * - Experience Level: 30%\n * - Skills Match: 25%\n * - Target Companies: 20%\n * - Resume Analysis: 15%\n * - Selected Difficulty: 10%\n */\n\nexport type DifficultyLevel = \"easy\" | \"medium\" | \"hard\";\n\nexport interface UserProfileData {\n  yearsExperience?: number | null;\n  skills?: string[];\n  targetCompanies?: string[];\n  targetRole?: string | null;\n  bio?: string | null;\n}\n\nexport interface ResumeData {\n  content?: string | null;\n  atsScore?: number | null;\n  keywords?: string[];\n  predictedRoles?: string[];\n  analysis?: {\n    experienceLevel?: string;\n    technicalDepth?: string;\n    systemDesignExperience?: string;\n  } | null;\n}\n\nexport interface DifficultyInput {\n  selectedDifficulty: DifficultyLevel;\n  profile: UserProfileData | null;\n  resume: ResumeData | null;\n  topic: string;\n}\n\nexport interface DifficultyResult {\n  calculatedDifficulty: DifficultyLevel;\n  confidenceScore: number;\n  adjustmentReason: string;\n  breakdown: {\n    experienceScore: number;\n    skillsScore: number;\n    companiesScore: number;\n    resumeScore: number;\n    selectedScore: number;\n    totalScore: number;\n  };\n  recommendations: string[];\n}\n\n// Weightages for each factor\nconst WEIGHTS = {\n  experience: 0.30,\n  skills: 0.25,\n  companies: 0.20,\n  resume: 0.15,\n  selected: 0.10,\n};\n\n// FAANG and top-tier companies (require higher difficulty)\nconst TOP_TIER_COMPANIES = [\n  \"google\", \"meta\", \"facebook\", \"amazon\", \"apple\", \"microsoft\", \"netflix\",\n  \"uber\", \"airbnb\", \"stripe\", \"coinbase\", \"linkedin\", \"twitter\", \"x\",\n  \"openai\", \"anthropic\", \"databricks\", \"snowflake\", \"palantir\", \"nvidia\",\n  \"tesla\", \"spacex\", \"bloomberg\", \"citadel\", \"two sigma\", \"jane street\",\n  \"bytedance\", \"tiktok\", \"spotify\", \"dropbox\", \"slack\", \"salesforce\"\n];\n\n// System design related skills\nconst SYSTEM_DESIGN_SKILLS = [\n  \"system design\", \"distributed systems\", \"microservices\", \"kubernetes\", \"docker\",\n  \"aws\", \"gcp\", \"azure\", \"kafka\", \"redis\", \"elasticsearch\", \"mongodb\",\n  \"postgresql\", \"mysql\", \"cassandra\", \"dynamodb\", \"graphql\", \"rest api\",\n  \"load balancing\", \"caching\", \"sharding\", \"replication\", \"cap theorem\",\n  \"event-driven\", \"message queues\", \"rabbitmq\", \"grpc\", \"websockets\",\n  \"cdn\", \"api gateway\", \"service mesh\", \"istio\", \"terraform\", \"ci/cd\",\n  \"scalability\", \"high availability\", \"fault tolerance\", \"database design\"\n];\n\n/**\n * Calculate experience score (0-100)\n * 0-2 years: Beginner (20-40)\n * 3-5 years: Intermediate (40-60)\n * 6-10 years: Senior (60-80)\n * 10+ years: Expert (80-100)\n */\nfunction calculateExperienceScore(yearsExperience?: number | null): number {\n  if (!yearsExperience || yearsExperience <= 0) return 20;\n\n  if (yearsExperience <= 2) {\n    return 20 + (yearsExperience / 2) * 20; // 20-40\n  } else if (yearsExperience <= 5) {\n    return 40 + ((yearsExperience - 2) / 3) * 20; // 40-60\n  } else if (yearsExperience <= 10) {\n    return 60 + ((yearsExperience - 5) / 5) * 20; // 60-80\n  } else {\n    return Math.min(100, 80 + ((yearsExperience - 10) / 10) * 20); // 80-100\n  }\n}\n\n/**\n * Calculate skills score based on system design relevant skills (0-100)\n */\nfunction calculateSkillsScore(skills?: string[]): number {\n  if (!skills || skills.length === 0) return 30;\n\n  const normalizedSkills = skills.map(s => s.toLowerCase().trim());\n\n  let matchCount = 0;\n  let totalRelevance = 0;\n\n  for (const skill of normalizedSkills) {\n    for (const sdSkill of SYSTEM_DESIGN_SKILLS) {\n      if (skill.includes(sdSkill) || sdSkill.includes(skill)) {\n        matchCount++;\n        // Some skills are more advanced\n        if ([\"distributed systems\", \"cap theorem\", \"sharding\", \"service mesh\", \"event-driven\"].some(s => skill.includes(s))) {\n          totalRelevance += 15;\n        } else if ([\"kubernetes\", \"kafka\", \"elasticsearch\", \"microservices\"].some(s => skill.includes(s))) {\n          totalRelevance += 12;\n        } else {\n          totalRelevance += 8;\n        }\n        break;\n      }\n    }\n  }\n\n  // Base score from match count\n  const matchScore = Math.min(50, matchCount * 10);\n  // Relevance bonus\n  const relevanceScore = Math.min(50, totalRelevance);\n\n  return Math.min(100, matchScore + relevanceScore);\n}\n\n/**\n * Calculate company tier score (0-100)\n * Top-tier companies expect higher difficulty\n */\nfunction calculateCompaniesScore(targetCompanies?: string[]): number {\n  if (!targetCompanies || targetCompanies.length === 0) return 50;\n\n  const normalizedCompanies = targetCompanies.map(c => c.toLowerCase().trim());\n\n  let topTierCount = 0;\n  for (const company of normalizedCompanies) {\n    if (TOP_TIER_COMPANIES.some(tc => company.includes(tc) || tc.includes(company))) {\n      topTierCount++;\n    }\n  }\n\n  const topTierRatio = topTierCount / targetCompanies.length;\n\n  // If mostly top-tier companies, expect higher difficulty\n  if (topTierRatio >= 0.7) return 85;\n  if (topTierRatio >= 0.5) return 70;\n  if (topTierRatio >= 0.3) return 55;\n  if (topTierRatio > 0) return 45;\n\n  return 40;\n}\n\n/**\n * Calculate resume score based on ATS analysis (0-100)\n */\nfunction calculateResumeScore(resume?: ResumeData | null): number {\n  if (!resume) return 50;\n\n  let score = 50;\n\n  // ATS score contribution\n  if (resume.atsScore) {\n    score = resume.atsScore * 0.5;\n  }\n\n  // Keywords analysis\n  if (resume.keywords && resume.keywords.length > 0) {\n    const normalizedKeywords = resume.keywords.map(k => k.toLowerCase());\n    let relevantKeywords = 0;\n\n    for (const keyword of normalizedKeywords) {\n      if (SYSTEM_DESIGN_SKILLS.some(s => keyword.includes(s) || s.includes(keyword))) {\n        relevantKeywords++;\n      }\n    }\n\n    score += Math.min(30, relevantKeywords * 5);\n  }\n\n  // Experience level from analysis\n  if (resume.analysis?.experienceLevel) {\n    const level = resume.analysis.experienceLevel.toLowerCase();\n    if (level.includes(\"senior\") || level.includes(\"lead\") || level.includes(\"principal\")) {\n      score += 20;\n    } else if (level.includes(\"mid\") || level.includes(\"intermediate\")) {\n      score += 10;\n    }\n  }\n\n  return Math.min(100, score);\n}\n\n/**\n * Convert selected difficulty to score (0-100)\n */\nfunction selectedDifficultyToScore(difficulty: DifficultyLevel): number {\n  switch (difficulty) {\n    case \"easy\": return 33;\n    case \"medium\": return 66;\n    case \"hard\": return 100;\n    default: return 50;\n  }\n}\n\n/**\n * Convert total score to difficulty level\n */\nfunction scoreToDifficulty(score: number): DifficultyLevel {\n  if (score < 40) return \"easy\";\n  if (score < 70) return \"medium\";\n  return \"hard\";\n}\n\n/**\n * Generate adjustment reason based on the calculation\n */\nfunction generateAdjustmentReason(\n  selected: DifficultyLevel,\n  calculated: DifficultyLevel,\n  breakdown: DifficultyResult[\"breakdown\"]\n): string {\n  if (selected === calculated) {\n    return \"Your selected difficulty matches your profile. No adjustment needed.\";\n  }\n\n  const reasons: string[] = [];\n\n  if (selected === \"hard\" && calculated !== \"hard\") {\n    if (breakdown.experienceScore < 50) {\n      reasons.push(\"your experience level suggests building more foundation first\");\n    }\n    if (breakdown.skillsScore < 50) {\n      reasons.push(\"developing more system design skills would help\");\n    }\n    if (breakdown.resumeScore < 50) {\n      reasons.push(\"your resume indicates room for technical growth\");\n    }\n  } else if (selected === \"easy\" && calculated !== \"easy\") {\n    if (breakdown.experienceScore > 60) {\n      reasons.push(\"your experience qualifies you for more challenge\");\n    }\n    if (breakdown.skillsScore > 60) {\n      reasons.push(\"your skills indicate strong system design knowledge\");\n    }\n    if (breakdown.companiesScore > 70) {\n      reasons.push(\"your target companies have rigorous interviews\");\n    }\n  }\n\n  if (reasons.length === 0) {\n    return `Adjusted from ${selected} to ${calculated} based on your overall profile analysis.`;\n  }\n\n  return `Adjusted from ${selected} to ${calculated} because ${reasons.join(\" and \")}.`;\n}\n\n/**\n * Generate recommendations based on profile analysis\n */\nfunction generateRecommendations(\n  breakdown: DifficultyResult[\"breakdown\"],\n  profile: UserProfileData | null\n): string[] {\n  const recommendations: string[] = [];\n\n  if (breakdown.experienceScore < 40) {\n    recommendations.push(\"Focus on building practical experience with distributed systems\");\n  }\n\n  if (breakdown.skillsScore < 50) {\n    recommendations.push(\"Study core system design concepts: caching, sharding, load balancing\");\n    recommendations.push(\"Practice designing systems like URL shortener, rate limiter, chat app\");\n  }\n\n  if (breakdown.companiesScore > 70 && breakdown.totalScore < 60) {\n    recommendations.push(\"Your target companies have high bars - consider more preparation\");\n    recommendations.push(\"Review system design case studies from FAANG interviews\");\n  }\n\n  if (breakdown.resumeScore < 50) {\n    recommendations.push(\"Update your resume to highlight system design experience\");\n  }\n\n  if (!profile?.skills || profile.skills.length < 3) {\n    recommendations.push(\"Add more skills to your profile for better question personalization\");\n  }\n\n  if (recommendations.length === 0) {\n    recommendations.push(\"You're well-prepared! Focus on articulating your thoughts clearly\");\n  }\n\n  return recommendations.slice(0, 4);\n}\n\n/**\n * Main function: Calculate smart difficulty\n */\nexport function calculateSmartDifficulty(input: DifficultyInput): DifficultyResult {\n  const { selectedDifficulty, profile, resume } = input;\n\n  // Calculate individual scores\n  const experienceScore = calculateExperienceScore(profile?.yearsExperience);\n  const skillsScore = calculateSkillsScore(profile?.skills);\n  const companiesScore = calculateCompaniesScore(profile?.targetCompanies);\n  const resumeScore = calculateResumeScore(resume);\n  const selectedScore = selectedDifficultyToScore(selectedDifficulty);\n\n  // Calculate weighted total\n  const totalScore =\n    experienceScore * WEIGHTS.experience +\n    skillsScore * WEIGHTS.skills +\n    companiesScore * WEIGHTS.companies +\n    resumeScore * WEIGHTS.resume +\n    selectedScore * WEIGHTS.selected;\n\n  const breakdown = {\n    experienceScore: Math.round(experienceScore),\n    skillsScore: Math.round(skillsScore),\n    companiesScore: Math.round(companiesScore),\n    resumeScore: Math.round(resumeScore),\n    selectedScore: Math.round(selectedScore),\n    totalScore: Math.round(totalScore),\n  };\n\n  const calculatedDifficulty = scoreToDifficulty(totalScore);\n\n  // Confidence score based on how much data we have\n  let confidenceScore = 50;\n  if (profile?.yearsExperience) confidenceScore += 15;\n  if (profile?.skills && profile.skills.length > 0) confidenceScore += 15;\n  if (profile?.targetCompanies && profile.targetCompanies.length > 0) confidenceScore += 10;\n  if (resume?.atsScore) confidenceScore += 10;\n\n  return {\n    calculatedDifficulty,\n    confidenceScore: Math.min(100, confidenceScore),\n    adjustmentReason: generateAdjustmentReason(selectedDifficulty, calculatedDifficulty, breakdown),\n    breakdown,\n    recommendations: generateRecommendations(breakdown, profile),\n  };\n}\n\n/**\n * Get difficulty description for prompts\n */\nexport function getDifficultyDescription(difficulty: DifficultyLevel): string {\n  switch (difficulty) {\n    case \"easy\":\n      return \"Entry-level: Focus on fundamental concepts, provide hints when stuck, allow more time for thinking, cover basic system design patterns.\";\n    case \"medium\":\n      return \"Mid-level: Balance guidance with challenge, expect knowledge of common patterns, probe on trade-offs, moderate depth on scalability.\";\n    case \"hard\":\n      return \"Senior-level: Minimal hints, expect precise technical answers, deep-dive on edge cases, challenge all design decisions, cover advanced patterns.\";\n    default:\n      return \"Standard difficulty level.\";\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;CAYC;;;;;;AA8CD,6BAA6B;AAC7B,MAAM,UAAU;IACd,YAAY;IACZ,QAAQ;IACR,WAAW;IACX,QAAQ;IACR,UAAU;AACZ;AAEA,2DAA2D;AAC3D,MAAM,qBAAqB;IACzB;IAAU;IAAQ;IAAY;IAAU;IAAS;IAAa;IAC9D;IAAQ;IAAU;IAAU;IAAY;IAAY;IAAW;IAC/D;IAAU;IAAa;IAAc;IAAa;IAAY;IAC9D;IAAS;IAAU;IAAa;IAAW;IAAa;IACxD;IAAa;IAAU;IAAW;IAAW;IAAS;CACvD;AAED,+BAA+B;AAC/B,MAAM,uBAAuB;IAC3B;IAAiB;IAAuB;IAAiB;IAAc;IACvE;IAAO;IAAO;IAAS;IAAS;IAAS;IAAiB;IAC1D;IAAc;IAAS;IAAa;IAAY;IAAW;IAC3D;IAAkB;IAAW;IAAY;IAAe;IACxD;IAAgB;IAAkB;IAAY;IAAQ;IACtD;IAAO;IAAe;IAAgB;IAAS;IAAa;IAC5D;IAAe;IAAqB;IAAmB;CACxD;AAED;;;;;;CAMC,GACD,SAAS,yBAAyB,eAA+B;IAC/D,IAAI,CAAC,mBAAmB,mBAAmB,GAAG,OAAO;IAErD,IAAI,mBAAmB,GAAG;QACxB,OAAO,KAAK,AAAC,kBAAkB,IAAK,IAAI,QAAQ;IAClD,OAAO,IAAI,mBAAmB,GAAG;QAC/B,OAAO,KAAK,AAAC,CAAC,kBAAkB,CAAC,IAAI,IAAK,IAAI,QAAQ;IACxD,OAAO,IAAI,mBAAmB,IAAI;QAChC,OAAO,KAAK,AAAC,CAAC,kBAAkB,CAAC,IAAI,IAAK,IAAI,QAAQ;IACxD,OAAO;QACL,OAAO,KAAK,GAAG,CAAC,KAAK,KAAK,AAAC,CAAC,kBAAkB,EAAE,IAAI,KAAM,KAAK,SAAS;IAC1E;AACF;AAEA;;CAEC,GACD,SAAS,qBAAqB,MAAiB;IAC7C,IAAI,CAAC,UAAU,OAAO,MAAM,KAAK,GAAG,OAAO;IAE3C,MAAM,mBAAmB,OAAO,GAAG,CAAC,CAAA,IAAK,EAAE,WAAW,GAAG,IAAI;IAE7D,IAAI,aAAa;IACjB,IAAI,iBAAiB;IAErB,KAAK,MAAM,SAAS,iBAAkB;QACpC,KAAK,MAAM,WAAW,qBAAsB;YAC1C,IAAI,MAAM,QAAQ,CAAC,YAAY,QAAQ,QAAQ,CAAC,QAAQ;gBACtD;gBACA,gCAAgC;gBAChC,IAAI;oBAAC;oBAAuB;oBAAe;oBAAY;oBAAgB;iBAAe,CAAC,IAAI,CAAC,CAAA,IAAK,MAAM,QAAQ,CAAC,KAAK;oBACnH,kBAAkB;gBACpB,OAAO,IAAI;oBAAC;oBAAc;oBAAS;oBAAiB;iBAAgB,CAAC,IAAI,CAAC,CAAA,IAAK,MAAM,QAAQ,CAAC,KAAK;oBACjG,kBAAkB;gBACpB,OAAO;oBACL,kBAAkB;gBACpB;gBACA;YACF;QACF;IACF;IAEA,8BAA8B;IAC9B,MAAM,aAAa,KAAK,GAAG,CAAC,IAAI,aAAa;IAC7C,kBAAkB;IAClB,MAAM,iBAAiB,KAAK,GAAG,CAAC,IAAI;IAEpC,OAAO,KAAK,GAAG,CAAC,KAAK,aAAa;AACpC;AAEA;;;CAGC,GACD,SAAS,wBAAwB,eAA0B;IACzD,IAAI,CAAC,mBAAmB,gBAAgB,MAAM,KAAK,GAAG,OAAO;IAE7D,MAAM,sBAAsB,gBAAgB,GAAG,CAAC,CAAA,IAAK,EAAE,WAAW,GAAG,IAAI;IAEzE,IAAI,eAAe;IACnB,KAAK,MAAM,WAAW,oBAAqB;QACzC,IAAI,mBAAmB,IAAI,CAAC,CAAA,KAAM,QAAQ,QAAQ,CAAC,OAAO,GAAG,QAAQ,CAAC,WAAW;YAC/E;QACF;IACF;IAEA,MAAM,eAAe,eAAe,gBAAgB,MAAM;IAE1D,yDAAyD;IACzD,IAAI,gBAAgB,KAAK,OAAO;IAChC,IAAI,gBAAgB,KAAK,OAAO;IAChC,IAAI,gBAAgB,KAAK,OAAO;IAChC,IAAI,eAAe,GAAG,OAAO;IAE7B,OAAO;AACT;AAEA;;CAEC,GACD,SAAS,qBAAqB,MAA0B;IACtD,IAAI,CAAC,QAAQ,OAAO;IAEpB,IAAI,QAAQ;IAEZ,yBAAyB;IACzB,IAAI,OAAO,QAAQ,EAAE;QACnB,QAAQ,OAAO,QAAQ,GAAG;IAC5B;IAEA,oBAAoB;IACpB,IAAI,OAAO,QAAQ,IAAI,OAAO,QAAQ,CAAC,MAAM,GAAG,GAAG;QACjD,MAAM,qBAAqB,OAAO,QAAQ,CAAC,GAAG,CAAC,CAAA,IAAK,EAAE,WAAW;QACjE,IAAI,mBAAmB;QAEvB,KAAK,MAAM,WAAW,mBAAoB;YACxC,IAAI,qBAAqB,IAAI,CAAC,CAAA,IAAK,QAAQ,QAAQ,CAAC,MAAM,EAAE,QAAQ,CAAC,WAAW;gBAC9E;YACF;QACF;QAEA,SAAS,KAAK,GAAG,CAAC,IAAI,mBAAmB;IAC3C;IAEA,iCAAiC;IACjC,IAAI,OAAO,QAAQ,EAAE,iBAAiB;QACpC,MAAM,QAAQ,OAAO,QAAQ,CAAC,eAAe,CAAC,WAAW;QACzD,IAAI,MAAM,QAAQ,CAAC,aAAa,MAAM,QAAQ,CAAC,WAAW,MAAM,QAAQ,CAAC,cAAc;YACrF,SAAS;QACX,OAAO,IAAI,MAAM,QAAQ,CAAC,UAAU,MAAM,QAAQ,CAAC,iBAAiB;YAClE,SAAS;QACX;IACF;IAEA,OAAO,KAAK,GAAG,CAAC,KAAK;AACvB;AAEA;;CAEC,GACD,SAAS,0BAA0B,UAA2B;IAC5D,OAAQ;QACN,KAAK;YAAQ,OAAO;QACpB,KAAK;YAAU,OAAO;QACtB,KAAK;YAAQ,OAAO;QACpB;YAAS,OAAO;IAClB;AACF;AAEA;;CAEC,GACD,SAAS,kBAAkB,KAAa;IACtC,IAAI,QAAQ,IAAI,OAAO;IACvB,IAAI,QAAQ,IAAI,OAAO;IACvB,OAAO;AACT;AAEA;;CAEC,GACD,SAAS,yBACP,QAAyB,EACzB,UAA2B,EAC3B,SAAwC;IAExC,IAAI,aAAa,YAAY;QAC3B,OAAO;IACT;IAEA,MAAM,UAAoB,EAAE;IAE5B,IAAI,aAAa,UAAU,eAAe,QAAQ;QAChD,IAAI,UAAU,eAAe,GAAG,IAAI;YAClC,QAAQ,IAAI,CAAC;QACf;QACA,IAAI,UAAU,WAAW,GAAG,IAAI;YAC9B,QAAQ,IAAI,CAAC;QACf;QACA,IAAI,UAAU,WAAW,GAAG,IAAI;YAC9B,QAAQ,IAAI,CAAC;QACf;IACF,OAAO,IAAI,aAAa,UAAU,eAAe,QAAQ;QACvD,IAAI,UAAU,eAAe,GAAG,IAAI;YAClC,QAAQ,IAAI,CAAC;QACf;QACA,IAAI,UAAU,WAAW,GAAG,IAAI;YAC9B,QAAQ,IAAI,CAAC;QACf;QACA,IAAI,UAAU,cAAc,GAAG,IAAI;YACjC,QAAQ,IAAI,CAAC;QACf;IACF;IAEA,IAAI,QAAQ,MAAM,KAAK,GAAG;QACxB,OAAO,CAAC,cAAc,EAAE,SAAS,IAAI,EAAE,WAAW,wCAAwC,CAAC;IAC7F;IAEA,OAAO,CAAC,cAAc,EAAE,SAAS,IAAI,EAAE,WAAW,SAAS,EAAE,QAAQ,IAAI,CAAC,SAAS,CAAC,CAAC;AACvF;AAEA;;CAEC,GACD,SAAS,wBACP,SAAwC,EACxC,OAA+B;IAE/B,MAAM,kBAA4B,EAAE;IAEpC,IAAI,UAAU,eAAe,GAAG,IAAI;QAClC,gBAAgB,IAAI,CAAC;IACvB;IAEA,IAAI,UAAU,WAAW,GAAG,IAAI;QAC9B,gBAAgB,IAAI,CAAC;QACrB,gBAAgB,IAAI,CAAC;IACvB;IAEA,IAAI,UAAU,cAAc,GAAG,MAAM,UAAU,UAAU,GAAG,IAAI;QAC9D,gBAAgB,IAAI,CAAC;QACrB,gBAAgB,IAAI,CAAC;IACvB;IAEA,IAAI,UAAU,WAAW,GAAG,IAAI;QAC9B,gBAAgB,IAAI,CAAC;IACvB;IAEA,IAAI,CAAC,SAAS,UAAU,QAAQ,MAAM,CAAC,MAAM,GAAG,GAAG;QACjD,gBAAgB,IAAI,CAAC;IACvB;IAEA,IAAI,gBAAgB,MAAM,KAAK,GAAG;QAChC,gBAAgB,IAAI,CAAC;IACvB;IAEA,OAAO,gBAAgB,KAAK,CAAC,GAAG;AAClC;AAKO,SAAS,yBAAyB,KAAsB;IAC7D,MAAM,EAAE,kBAAkB,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG;IAEhD,8BAA8B;IAC9B,MAAM,kBAAkB,yBAAyB,SAAS;IAC1D,MAAM,cAAc,qBAAqB,SAAS;IAClD,MAAM,iBAAiB,wBAAwB,SAAS;IACxD,MAAM,cAAc,qBAAqB;IACzC,MAAM,gBAAgB,0BAA0B;IAEhD,2BAA2B;IAC3B,MAAM,aACJ,kBAAkB,QAAQ,UAAU,GACpC,cAAc,QAAQ,MAAM,GAC5B,iBAAiB,QAAQ,SAAS,GAClC,cAAc,QAAQ,MAAM,GAC5B,gBAAgB,QAAQ,QAAQ;IAElC,MAAM,YAAY;QAChB,iBAAiB,KAAK,KAAK,CAAC;QAC5B,aAAa,KAAK,KAAK,CAAC;QACxB,gBAAgB,KAAK,KAAK,CAAC;QAC3B,aAAa,KAAK,KAAK,CAAC;QACxB,eAAe,KAAK,KAAK,CAAC;QAC1B,YAAY,KAAK,KAAK,CAAC;IACzB;IAEA,MAAM,uBAAuB,kBAAkB;IAE/C,kDAAkD;IAClD,IAAI,kBAAkB;IACtB,IAAI,SAAS,iBAAiB,mBAAmB;IACjD,IAAI,SAAS,UAAU,QAAQ,MAAM,CAAC,MAAM,GAAG,GAAG,mBAAmB;IACrE,IAAI,SAAS,mBAAmB,QAAQ,eAAe,CAAC,MAAM,GAAG,GAAG,mBAAmB;IACvF,IAAI,QAAQ,UAAU,mBAAmB;IAEzC,OAAO;QACL;QACA,iBAAiB,KAAK,GAAG,CAAC,KAAK;QAC/B,kBAAkB,yBAAyB,oBAAoB,sBAAsB;QACrF;QACA,iBAAiB,wBAAwB,WAAW;IACtD;AACF;AAKO,SAAS,yBAAyB,UAA2B;IAClE,OAAQ;QACN,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF"}},
    {"offset": {"line": 1002, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/lib/question-generator.ts"],"sourcesContent":["/**\n * Personalized Question Generator\n *\n * Uses Ollama (local LLM) to generate interview questions tailored to user's profile,\n * skills, experience, and target companies.\n */\n\nimport { ollamaChat } from \"./ollama\";\nimport {\n  DifficultyLevel,\n  UserProfileData,\n  ResumeData,\n  getDifficultyDescription,\n} from \"./difficulty-calculator\";\n\nexport interface QuestionGeneratorInput {\n  topic: string;\n  difficulty: DifficultyLevel;\n  profile: UserProfileData | null;\n  resume: ResumeData | null;\n}\n\nexport interface GeneratedQuestion {\n  id: string;\n  question: string;\n  category: \"requirements\" | \"high-level\" | \"deep-dive\" | \"scalability\" | \"trade-offs\";\n  difficulty: DifficultyLevel;\n  focusAreas: string[];\n  expectedTopics: string[];\n  timeAllocation: number; // minutes\n}\n\nexport interface PersonalizedQuestionSet {\n  topic: string;\n  difficulty: DifficultyLevel;\n  totalDuration: number;\n  questions: GeneratedQuestion[];\n  focusAreas: string[];\n  personalizationNotes: string;\n  interviewerContext: string;\n}\n\n/**\n * Build context string from user profile\n */\nfunction buildProfileContext(profile: UserProfileData | null): string {\n  if (!profile) return \"No profile data available.\";\n\n  const parts: string[] = [];\n\n  if (profile.yearsExperience) {\n    parts.push(`Years of experience: ${profile.yearsExperience}`);\n  }\n\n  if (profile.targetRole) {\n    parts.push(`Target role: ${profile.targetRole}`);\n  }\n\n  if (profile.skills && profile.skills.length > 0) {\n    parts.push(`Technical skills: ${profile.skills.join(\", \")}`);\n  }\n\n  if (profile.targetCompanies && profile.targetCompanies.length > 0) {\n    parts.push(`Target companies: ${profile.targetCompanies.join(\", \")}`);\n  }\n\n  if (profile.bio) {\n    parts.push(`Background: ${profile.bio}`);\n  }\n\n  return parts.length > 0 ? parts.join(\"\\n\") : \"Limited profile data available.\";\n}\n\n/**\n * Build context string from resume\n */\nfunction buildResumeContext(resume: ResumeData | null): string {\n  if (!resume) return \"No resume data available.\";\n\n  const parts: string[] = [];\n\n  if (resume.atsScore) {\n    parts.push(`ATS Score: ${resume.atsScore}/100`);\n  }\n\n  if (resume.keywords && resume.keywords.length > 0) {\n    parts.push(`Key technical keywords: ${resume.keywords.slice(0, 15).join(\", \")}`);\n  }\n\n  if (resume.predictedRoles && resume.predictedRoles.length > 0) {\n    parts.push(`Predicted suitable roles: ${resume.predictedRoles.join(\", \")}`);\n  }\n\n  if (resume.analysis) {\n    if (resume.analysis.experienceLevel) {\n      parts.push(`Experience level: ${resume.analysis.experienceLevel}`);\n    }\n    if (resume.analysis.technicalDepth) {\n      parts.push(`Technical depth: ${resume.analysis.technicalDepth}`);\n    }\n    if (resume.analysis.systemDesignExperience) {\n      parts.push(`System design experience: ${resume.analysis.systemDesignExperience}`);\n    }\n  }\n\n  return parts.length > 0 ? parts.join(\"\\n\") : \"Limited resume data available.\";\n}\n\n/**\n * Generate the question generation prompt\n */\nfunction buildQuestionPrompt(input: QuestionGeneratorInput): string {\n  const { topic, difficulty, profile, resume } = input;\n\n  const profileContext = buildProfileContext(profile);\n  const resumeContext = buildResumeContext(resume);\n  const difficultyDesc = getDifficultyDescription(difficulty);\n\n  return `You are an expert system design interview question generator for top tech companies (FAANG+).\n\nGenerate a personalized set of system design interview questions for the topic: \"${topic}\"\n\n## Candidate Profile\n${profileContext}\n\n## Resume Analysis\n${resumeContext}\n\n## Interview Parameters\n- Difficulty Level: ${difficulty.toUpperCase()}\n- ${difficultyDesc}\n- Total Interview Duration: 45 minutes\n\n## Question Generation Guidelines\n\n1. **Personalization**: Tailor questions to the candidate's skills and experience level.\n   - If they have specific skills (e.g., Kafka, Redis), include questions that let them showcase these.\n   - If they're targeting specific companies, align question style with those companies' interview patterns.\n\n2. **Difficulty Calibration**:\n   - EASY: Focus on fundamentals, basic patterns, straightforward requirements\n   - MEDIUM: Include trade-off discussions, moderate scale, some edge cases\n   - HARD: Complex scenarios, extreme scale, failure modes, advanced optimizations\n\n3. **Coverage**: Questions should cover all phases:\n   - Requirements Clarification (8 min): Scope, scale, constraints\n   - High-Level Design (12 min): Architecture, components, data flow\n   - Deep Dive (12 min): Specific component design, data models\n   - Scalability (10 min): Growth, optimization, trade-offs\n   - Trade-offs (3 min): Summary, alternatives considered\n\n4. **Question Types to Include**:\n   - Clarifying questions the interviewer should ask\n   - Follow-up probes based on expected answers\n   - Edge cases and failure scenarios\n   - Scaling challenges specific to the system\n\n## Output Format\nReturn a JSON object with the following structure:\n{\n  \"questions\": [\n    {\n      \"id\": \"q1\",\n      \"question\": \"The main question text\",\n      \"category\": \"requirements|high-level|deep-dive|scalability|trade-offs\",\n      \"difficulty\": \"easy|medium|hard\",\n      \"focusAreas\": [\"area1\", \"area2\"],\n      \"expectedTopics\": [\"topic candidate should mention\"],\n      \"timeAllocation\": 5\n    }\n  ],\n  \"focusAreas\": [\"Overall focus areas based on candidate profile\"],\n  \"personalizationNotes\": \"How questions were personalized for this candidate\",\n  \"interviewerContext\": \"Context for the AI interviewer about this candidate's background\"\n}\n\nGenerate 8-12 questions covering all categories. Ensure the total time allocation sums to approximately 45 minutes.`;\n}\n\n/**\n * Parse OpenAI response into structured format\n */\nfunction parseQuestionResponse(response: string): Partial<PersonalizedQuestionSet> {\n  try {\n    // Try to extract JSON from the response\n    const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n      return JSON.parse(jsonMatch[0]);\n    }\n    throw new Error(\"No JSON found in response\");\n  } catch (error) {\n    console.error(\"Failed to parse question response:\", error);\n    return {\n      questions: [],\n      focusAreas: [],\n      personalizationNotes: \"Failed to generate personalized questions\",\n      interviewerContext: \"\",\n    };\n  }\n}\n\n/**\n * Generate personalized questions using Ollama (local LLM)\n */\nexport async function generatePersonalizedQuestions(\n  input: QuestionGeneratorInput\n): Promise<PersonalizedQuestionSet> {\n  const prompt = buildQuestionPrompt(input);\n\n  try {\n    const completion = await ollamaChat({\n      messages: [\n        {\n          role: \"system\",\n          content: \"You are an expert system design interview question generator. Always respond with valid JSON only, no additional text.\",\n        },\n        {\n          role: \"user\",\n          content: prompt,\n        },\n      ],\n      temperature: 0.7,\n      max_tokens: 2500,\n    });\n\n    const responseText = completion.message?.content || \"\";\n    const parsed = parseQuestionResponse(responseText);\n\n    return {\n      topic: input.topic,\n      difficulty: input.difficulty,\n      totalDuration: 45,\n      questions: parsed.questions || [],\n      focusAreas: parsed.focusAreas || [],\n      personalizationNotes: parsed.personalizationNotes || \"\",\n      interviewerContext: parsed.interviewerContext || \"\",\n    };\n  } catch (error) {\n    console.error(\"Ollama question generation error:\", error);\n\n    // Return fallback questions\n    return generateFallbackQuestions(input);\n  }\n}\n\n/**\n * Generate fallback questions if Ollama fails\n */\nfunction generateFallbackQuestions(input: QuestionGeneratorInput): PersonalizedQuestionSet {\n  const { topic, difficulty } = input;\n\n  const baseQuestions: GeneratedQuestion[] = [\n    {\n      id: \"q1\",\n      question: `Let's design ${topic}. Before we start, what clarifying questions would you like to ask about the requirements?`,\n      category: \"requirements\",\n      difficulty,\n      focusAreas: [\"scope\", \"constraints\", \"users\"],\n      expectedTopics: [\"scale\", \"features\", \"non-functional requirements\"],\n      timeAllocation: 8,\n    },\n    {\n      id: \"q2\",\n      question: \"Can you walk me through the high-level architecture? What are the main components?\",\n      category: \"high-level\",\n      difficulty,\n      focusAreas: [\"architecture\", \"components\"],\n      expectedTopics: [\"clients\", \"servers\", \"databases\", \"caches\"],\n      timeAllocation: 12,\n    },\n    {\n      id: \"q3\",\n      question: \"Let's dive deeper into the data model. How would you structure the database?\",\n      category: \"deep-dive\",\n      difficulty,\n      focusAreas: [\"data modeling\", \"storage\"],\n      expectedTopics: [\"tables\", \"relationships\", \"indexes\"],\n      timeAllocation: 6,\n    },\n    {\n      id: \"q4\",\n      question: \"How would you handle the core functionality? Walk me through the main flow.\",\n      category: \"deep-dive\",\n      difficulty,\n      focusAreas: [\"implementation\", \"algorithms\"],\n      expectedTopics: [\"API design\", \"business logic\"],\n      timeAllocation: 6,\n    },\n    {\n      id: \"q5\",\n      question: \"How would you scale this system to handle 10x or 100x the current load?\",\n      category: \"scalability\",\n      difficulty,\n      focusAreas: [\"scaling\", \"performance\"],\n      expectedTopics: [\"horizontal scaling\", \"caching\", \"sharding\"],\n      timeAllocation: 5,\n    },\n    {\n      id: \"q6\",\n      question: \"What are the potential bottlenecks and how would you address them?\",\n      category: \"scalability\",\n      difficulty,\n      focusAreas: [\"bottlenecks\", \"optimization\"],\n      expectedTopics: [\"database\", \"network\", \"compute\"],\n      timeAllocation: 5,\n    },\n    {\n      id: \"q7\",\n      question: \"What trade-offs did you make in your design? Would you change anything?\",\n      category: \"trade-offs\",\n      difficulty,\n      focusAreas: [\"trade-offs\", \"alternatives\"],\n      expectedTopics: [\"consistency vs availability\", \"cost vs performance\"],\n      timeAllocation: 3,\n    },\n  ];\n\n  return {\n    topic,\n    difficulty,\n    totalDuration: 45,\n    questions: baseQuestions,\n    focusAreas: [\"System Design Fundamentals\", \"Scalability\", \"Trade-offs\"],\n    personalizationNotes: \"Using standard question set due to limited personalization data\",\n    interviewerContext: `Interviewing for ${topic} at ${difficulty} difficulty level.`,\n  };\n}\n\n/**\n * Build enhanced interviewer prompt with personalization\n */\nexport function buildPersonalizedInterviewerPrompt(\n  questionSet: PersonalizedQuestionSet,\n  profile: UserProfileData | null\n): string {\n  const { topic, difficulty, interviewerContext, focusAreas, personalizationNotes } = questionSet;\n\n  const skillsContext = profile?.skills?.length\n    ? `The candidate has experience with: ${profile.skills.join(\", \")}.`\n    : \"\";\n\n  const experienceContext = profile?.yearsExperience\n    ? `They have ${profile.yearsExperience} years of experience.`\n    : \"\";\n\n  const companiesContext = profile?.targetCompanies?.length\n    ? `They are targeting companies like: ${profile.targetCompanies.join(\", \")}.`\n    : \"\";\n\n  return `You are Bobby, a friendly and experienced senior software engineer conducting a 45-minute system design interview at a top tech company. You have 10+ years of experience building large-scale distributed systems.\n\n## Interview Topic: ${topic}\n## Difficulty: ${difficulty.toUpperCase()}\n\n## Candidate Context\n${interviewerContext}\n${skillsContext}\n${experienceContext}\n${companiesContext}\n\n## Personalization Notes\n${personalizationNotes}\n\n## Focus Areas for This Interview\n${focusAreas.map(area => `- ${area}`).join(\"\\n\")}\n\n## Interview Guidelines\n\n1. **Your Personality as Bobby**:\n   - Be warm, encouraging, and professional\n   - Use a conversational tone while maintaining technical rigor\n   - Occasionally use phrases like \"Great point!\", \"That's interesting...\", \"I like that approach\"\n\n2. **Adapt to the Candidate**: Use their background to ask relevant follow-up questions.\n   - If they mention technologies they know, probe deeper on those.\n   - If they're junior, provide more guidance; if senior, expect more depth.\n\n3. **Difficulty Calibration**:\n   ${difficulty === \"easy\" ? \"- Be supportive and provide hints when the candidate is stuck\" : \"\"}\n   ${difficulty === \"medium\" ? \"- Balance guidance with challenge, probe on trade-offs\" : \"\"}\n   ${difficulty === \"hard\" ? \"- Be rigorous, expect precise answers, challenge all decisions\" : \"\"}\n\n4. **Phase Management**: Guide through all phases:\n   - Requirements (8 min) â†’ High-Level Design (12 min) â†’ Deep Dive (12 min) â†’ Scalability (10 min) â†’ Wrap-up (3 min)\n\n5. **Question Style**:\n   - Keep responses concise (2-4 sentences)\n   - Ask one question at a time\n   - Acknowledge good points before probing deeper\n   - Use \"[PHASE_TRANSITION: phase-id]\" to signal phase changes\n\n6. **Personalized Probing**:\n   - If candidate mentions their known technologies, ask how they'd apply them\n   - For target company alignment, use similar question patterns those companies use\n\nStart by introducing yourself as Bobby, mention you're excited to discuss ${topic} with them, and ask the first clarifying question about requirements.`;\n}\n"],"names":[],"mappings":";;;;;;AAAA;;;;;CAKC,GAED;AACA;;;AAkCA;;CAEC,GACD,SAAS,oBAAoB,OAA+B;IAC1D,IAAI,CAAC,SAAS,OAAO;IAErB,MAAM,QAAkB,EAAE;IAE1B,IAAI,QAAQ,eAAe,EAAE;QAC3B,MAAM,IAAI,CAAC,CAAC,qBAAqB,EAAE,QAAQ,eAAe,EAAE;IAC9D;IAEA,IAAI,QAAQ,UAAU,EAAE;QACtB,MAAM,IAAI,CAAC,CAAC,aAAa,EAAE,QAAQ,UAAU,EAAE;IACjD;IAEA,IAAI,QAAQ,MAAM,IAAI,QAAQ,MAAM,CAAC,MAAM,GAAG,GAAG;QAC/C,MAAM,IAAI,CAAC,CAAC,kBAAkB,EAAE,QAAQ,MAAM,CAAC,IAAI,CAAC,OAAO;IAC7D;IAEA,IAAI,QAAQ,eAAe,IAAI,QAAQ,eAAe,CAAC,MAAM,GAAG,GAAG;QACjE,MAAM,IAAI,CAAC,CAAC,kBAAkB,EAAE,QAAQ,eAAe,CAAC,IAAI,CAAC,OAAO;IACtE;IAEA,IAAI,QAAQ,GAAG,EAAE;QACf,MAAM,IAAI,CAAC,CAAC,YAAY,EAAE,QAAQ,GAAG,EAAE;IACzC;IAEA,OAAO,MAAM,MAAM,GAAG,IAAI,MAAM,IAAI,CAAC,QAAQ;AAC/C;AAEA;;CAEC,GACD,SAAS,mBAAmB,MAAyB;IACnD,IAAI,CAAC,QAAQ,OAAO;IAEpB,MAAM,QAAkB,EAAE;IAE1B,IAAI,OAAO,QAAQ,EAAE;QACnB,MAAM,IAAI,CAAC,CAAC,WAAW,EAAE,OAAO,QAAQ,CAAC,IAAI,CAAC;IAChD;IAEA,IAAI,OAAO,QAAQ,IAAI,OAAO,QAAQ,CAAC,MAAM,GAAG,GAAG;QACjD,MAAM,IAAI,CAAC,CAAC,wBAAwB,EAAE,OAAO,QAAQ,CAAC,KAAK,CAAC,GAAG,IAAI,IAAI,CAAC,OAAO;IACjF;IAEA,IAAI,OAAO,cAAc,IAAI,OAAO,cAAc,CAAC,MAAM,GAAG,GAAG;QAC7D,MAAM,IAAI,CAAC,CAAC,0BAA0B,EAAE,OAAO,cAAc,CAAC,IAAI,CAAC,OAAO;IAC5E;IAEA,IAAI,OAAO,QAAQ,EAAE;QACnB,IAAI,OAAO,QAAQ,CAAC,eAAe,EAAE;YACnC,MAAM,IAAI,CAAC,CAAC,kBAAkB,EAAE,OAAO,QAAQ,CAAC,eAAe,EAAE;QACnE;QACA,IAAI,OAAO,QAAQ,CAAC,cAAc,EAAE;YAClC,MAAM,IAAI,CAAC,CAAC,iBAAiB,EAAE,OAAO,QAAQ,CAAC,cAAc,EAAE;QACjE;QACA,IAAI,OAAO,QAAQ,CAAC,sBAAsB,EAAE;YAC1C,MAAM,IAAI,CAAC,CAAC,0BAA0B,EAAE,OAAO,QAAQ,CAAC,sBAAsB,EAAE;QAClF;IACF;IAEA,OAAO,MAAM,MAAM,GAAG,IAAI,MAAM,IAAI,CAAC,QAAQ;AAC/C;AAEA;;CAEC,GACD,SAAS,oBAAoB,KAA6B;IACxD,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG;IAE/C,MAAM,iBAAiB,oBAAoB;IAC3C,MAAM,gBAAgB,mBAAmB;IACzC,MAAM,iBAAiB,IAAA,6OAAwB,EAAC;IAEhD,OAAO,CAAC;;iFAEuE,EAAE,MAAM;;;AAGzF,EAAE,eAAe;;;AAGjB,EAAE,cAAc;;;oBAGI,EAAE,WAAW,WAAW,GAAG;EAC7C,EAAE,eAAe;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;mHA8CgG,CAAC;AACpH;AAEA;;CAEC,GACD,SAAS,sBAAsB,QAAgB;IAC7C,IAAI;QACF,wCAAwC;QACxC,MAAM,YAAY,SAAS,KAAK,CAAC;QACjC,IAAI,WAAW;YACb,OAAO,KAAK,KAAK,CAAC,SAAS,CAAC,EAAE;QAChC;QACA,MAAM,IAAI,MAAM;IAClB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,sCAAsC;QACpD,OAAO;YACL,WAAW,EAAE;YACb,YAAY,EAAE;YACd,sBAAsB;YACtB,oBAAoB;QACtB;IACF;AACF;AAKO,eAAe,8BACpB,KAA6B;IAE7B,MAAM,SAAS,oBAAoB;IAEnC,IAAI;QACF,MAAM,aAAa,MAAM,IAAA,6MAAU,EAAC;YAClC,UAAU;gBACR;oBACE,MAAM;oBACN,SAAS;gBACX;gBACA;oBACE,MAAM;oBACN,SAAS;gBACX;aACD;YACD,aAAa;YACb,YAAY;QACd;QAEA,MAAM,eAAe,WAAW,OAAO,EAAE,WAAW;QACpD,MAAM,SAAS,sBAAsB;QAErC,OAAO;YACL,OAAO,MAAM,KAAK;YAClB,YAAY,MAAM,UAAU;YAC5B,eAAe;YACf,WAAW,OAAO,SAAS,IAAI,EAAE;YACjC,YAAY,OAAO,UAAU,IAAI,EAAE;YACnC,sBAAsB,OAAO,oBAAoB,IAAI;YACrD,oBAAoB,OAAO,kBAAkB,IAAI;QACnD;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,qCAAqC;QAEnD,4BAA4B;QAC5B,OAAO,0BAA0B;IACnC;AACF;AAEA;;CAEC,GACD,SAAS,0BAA0B,KAA6B;IAC9D,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,GAAG;IAE9B,MAAM,gBAAqC;QACzC;YACE,IAAI;YACJ,UAAU,CAAC,aAAa,EAAE,MAAM,0FAA0F,CAAC;YAC3H,UAAU;YACV;YACA,YAAY;gBAAC;gBAAS;gBAAe;aAAQ;YAC7C,gBAAgB;gBAAC;gBAAS;gBAAY;aAA8B;YACpE,gBAAgB;QAClB;QACA;YACE,IAAI;YACJ,UAAU;YACV,UAAU;YACV;YACA,YAAY;gBAAC;gBAAgB;aAAa;YAC1C,gBAAgB;gBAAC;gBAAW;gBAAW;gBAAa;aAAS;YAC7D,gBAAgB;QAClB;QACA;YACE,IAAI;YACJ,UAAU;YACV,UAAU;YACV;YACA,YAAY;gBAAC;gBAAiB;aAAU;YACxC,gBAAgB;gBAAC;gBAAU;gBAAiB;aAAU;YACtD,gBAAgB;QAClB;QACA;YACE,IAAI;YACJ,UAAU;YACV,UAAU;YACV;YACA,YAAY;gBAAC;gBAAkB;aAAa;YAC5C,gBAAgB;gBAAC;gBAAc;aAAiB;YAChD,gBAAgB;QAClB;QACA;YACE,IAAI;YACJ,UAAU;YACV,UAAU;YACV;YACA,YAAY;gBAAC;gBAAW;aAAc;YACtC,gBAAgB;gBAAC;gBAAsB;gBAAW;aAAW;YAC7D,gBAAgB;QAClB;QACA;YACE,IAAI;YACJ,UAAU;YACV,UAAU;YACV;YACA,YAAY;gBAAC;gBAAe;aAAe;YAC3C,gBAAgB;gBAAC;gBAAY;gBAAW;aAAU;YAClD,gBAAgB;QAClB;QACA;YACE,IAAI;YACJ,UAAU;YACV,UAAU;YACV;YACA,YAAY;gBAAC;gBAAc;aAAe;YAC1C,gBAAgB;gBAAC;gBAA+B;aAAsB;YACtE,gBAAgB;QAClB;KACD;IAED,OAAO;QACL;QACA;QACA,eAAe;QACf,WAAW;QACX,YAAY;YAAC;YAA8B;YAAe;SAAa;QACvE,sBAAsB;QACtB,oBAAoB,CAAC,iBAAiB,EAAE,MAAM,IAAI,EAAE,WAAW,kBAAkB,CAAC;IACpF;AACF;AAKO,SAAS,mCACd,WAAoC,EACpC,OAA+B;IAE/B,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,kBAAkB,EAAE,UAAU,EAAE,oBAAoB,EAAE,GAAG;IAEpF,MAAM,gBAAgB,SAAS,QAAQ,SACnC,CAAC,mCAAmC,EAAE,QAAQ,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAClE;IAEJ,MAAM,oBAAoB,SAAS,kBAC/B,CAAC,UAAU,EAAE,QAAQ,eAAe,CAAC,qBAAqB,CAAC,GAC3D;IAEJ,MAAM,mBAAmB,SAAS,iBAAiB,SAC/C,CAAC,mCAAmC,EAAE,QAAQ,eAAe,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAC3E;IAEJ,OAAO,CAAC;;oBAEU,EAAE,MAAM;eACb,EAAE,WAAW,WAAW,GAAG;;;AAG1C,EAAE,mBAAmB;AACrB,EAAE,cAAc;AAChB,EAAE,kBAAkB;AACpB,EAAE,iBAAiB;;;AAGnB,EAAE,qBAAqB;;;AAGvB,EAAE,WAAW,GAAG,CAAC,CAAA,OAAQ,CAAC,EAAE,EAAE,MAAM,EAAE,IAAI,CAAC,MAAM;;;;;;;;;;;;;;GAc9C,EAAE,eAAe,SAAS,kEAAkE,GAAG;GAC/F,EAAE,eAAe,WAAW,2DAA2D,GAAG;GAC1F,EAAE,eAAe,SAAS,mEAAmE,GAAG;;;;;;;;;;;;;;;0EAezB,EAAE,MAAM,qEAAqE,CAAC;AACxJ"}},
    {"offset": {"line": 1378, "column": 0}, "map": {"version":3,"sources":["file:///Users/sairammaruri/Documents/Git/system-design/system-design-simulator/src/app/api/interview/personalized/route.ts"],"sourcesContent":["/**\n * Personalized Interview API\n *\n * Creates an interview with smart difficulty adjustment and personalized questions\n * based on user profile, skills, experience, and resume analysis.\n *\n * POST /api/interview/personalized\n * Body: { topic: string, selectedDifficulty: \"easy\" | \"medium\" | \"hard\" }\n */\n\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { auth } from \"@/lib/auth\";\nimport { prisma } from \"@/lib/prisma\";\nimport { ollamaChat } from \"@/lib/ollama\";\nimport {\n  calculateSmartDifficulty,\n  DifficultyLevel,\n  UserProfileData,\n  ResumeData,\n} from \"@/lib/difficulty-calculator\";\nimport {\n  generatePersonalizedQuestions,\n  buildPersonalizedInterviewerPrompt,\n} from \"@/lib/question-generator\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    // 1. Authenticate user\n    const session = await auth();\n    if (!session?.user?.id) {\n      return NextResponse.json({ error: \"Unauthorized\" }, { status: 401 });\n    }\n\n    // 2. Parse request body\n    const body = await request.json();\n    const { topic, selectedDifficulty = \"medium\" } = body;\n\n    if (!topic) {\n      return NextResponse.json(\n        { error: \"Topic is required\" },\n        { status: 400 }\n      );\n    }\n\n    // Validate difficulty\n    const validDifficulties: DifficultyLevel[] = [\"easy\", \"medium\", \"hard\"];\n    if (!validDifficulties.includes(selectedDifficulty)) {\n      return NextResponse.json(\n        { error: \"Invalid difficulty level\" },\n        { status: 400 }\n      );\n    }\n\n    // 3. Fetch user profile\n    const profile = await prisma.profile.findUnique({\n      where: { userId: session.user.id },\n    });\n\n    // 4. Fetch latest resume\n    const latestResume = await prisma.resume.findFirst({\n      where: { userId: session.user.id },\n      orderBy: { uploadedAt: \"desc\" },\n    });\n\n    // 5. Parse profile data\n    const profileData: UserProfileData | null = profile\n      ? {\n          yearsExperience: profile.yearsExperience,\n          skills: profile.skills ? JSON.parse(profile.skills) : [],\n          targetCompanies: profile.targetCompanies\n            ? JSON.parse(profile.targetCompanies)\n            : [],\n          targetRole: profile.targetRole,\n          bio: profile.bio,\n        }\n      : null;\n\n    // 6. Parse resume data\n    const resumeData: ResumeData | null = latestResume\n      ? {\n          content: latestResume.content,\n          atsScore: latestResume.atsScore,\n          keywords: latestResume.keywords\n            ? JSON.parse(latestResume.keywords)\n            : [],\n          predictedRoles: latestResume.predictedRoles\n            ? JSON.parse(latestResume.predictedRoles)\n            : [],\n          analysis: latestResume.analysis\n            ? JSON.parse(latestResume.analysis)\n            : null,\n        }\n      : null;\n\n    // 7. Calculate smart difficulty\n    const difficultyResult = calculateSmartDifficulty({\n      selectedDifficulty,\n      profile: profileData,\n      resume: resumeData,\n      topic,\n    });\n\n    const actualDifficulty = difficultyResult.calculatedDifficulty;\n\n    // 8. Generate personalized questions\n    const questionSet = await generatePersonalizedQuestions({\n      topic,\n      difficulty: actualDifficulty,\n      profile: profileData,\n      resume: resumeData,\n    });\n\n    // 9. Build personalized interviewer prompt\n    const interviewerPrompt = buildPersonalizedInterviewerPrompt(\n      questionSet,\n      profileData\n    );\n\n    // 10. Create interview record\n    const interview = await prisma.interview.create({\n      data: {\n        userId: session.user.id,\n        topic,\n        difficulty: actualDifficulty,\n        status: \"in_progress\",\n        startedAt: new Date(),\n      },\n    });\n\n    // 11. Generate initial interviewer message using Ollama\n    const initialCompletion = await ollamaChat({\n      messages: [\n        { role: \"system\", content: interviewerPrompt },\n        { role: \"user\", content: \"Start the interview.\" },\n      ],\n      max_tokens: 500,\n      temperature: 0.7,\n    });\n\n    const initialMessage =\n      initialCompletion.message?.content ||\n      `Hey there! I'm Bobby, and I'll be your interviewer today. I'm excited to discuss ${topic} with you! Let's start with some clarifying questions - what's the first thing you'd want to understand about the requirements?`;\n\n    // 12. Save messages to database\n    await prisma.message.createMany({\n      data: [\n        {\n          interviewId: interview.id,\n          role: \"system\",\n          content: interviewerPrompt,\n        },\n        {\n          interviewId: interview.id,\n          role: \"assistant\",\n          content: initialMessage,\n        },\n      ],\n    });\n\n    // 13. Return response\n    return NextResponse.json({\n      success: true,\n      interview: {\n        id: interview.id,\n        topic: interview.topic,\n        difficulty: interview.difficulty,\n        status: interview.status,\n        startedAt: interview.startedAt,\n      },\n      initialMessage,\n      personalization: {\n        selectedDifficulty,\n        calculatedDifficulty: actualDifficulty,\n        wasAdjusted: selectedDifficulty !== actualDifficulty,\n        adjustmentReason: difficultyResult.adjustmentReason,\n        confidenceScore: difficultyResult.confidenceScore,\n        breakdown: difficultyResult.breakdown,\n        recommendations: difficultyResult.recommendations,\n      },\n      questionSet: {\n        focusAreas: questionSet.focusAreas,\n        personalizationNotes: questionSet.personalizationNotes,\n        questionCount: questionSet.questions.length,\n      },\n    });\n  } catch (error) {\n    console.error(\"Personalized interview creation error:\", error);\n    return NextResponse.json(\n      { error: \"Failed to create personalized interview\" },\n      { status: 500 }\n    );\n  }\n}\n\n/**\n * GET endpoint to preview difficulty calculation without creating interview\n */\nexport async function GET(request: NextRequest) {\n  try {\n    const session = await auth();\n    if (!session?.user?.id) {\n      return NextResponse.json({ error: \"Unauthorized\" }, { status: 401 });\n    }\n\n    const { searchParams } = new URL(request.url);\n    const selectedDifficulty =\n      (searchParams.get(\"difficulty\") as DifficultyLevel) || \"medium\";\n    const topic = searchParams.get(\"topic\") || \"System Design\";\n\n    // Fetch user data\n    const profile = await prisma.profile.findUnique({\n      where: { userId: session.user.id },\n    });\n\n    const latestResume = await prisma.resume.findFirst({\n      where: { userId: session.user.id },\n      orderBy: { uploadedAt: \"desc\" },\n    });\n\n    // Parse data\n    const profileData: UserProfileData | null = profile\n      ? {\n          yearsExperience: profile.yearsExperience,\n          skills: profile.skills ? JSON.parse(profile.skills) : [],\n          targetCompanies: profile.targetCompanies\n            ? JSON.parse(profile.targetCompanies)\n            : [],\n          targetRole: profile.targetRole,\n          bio: profile.bio,\n        }\n      : null;\n\n    const resumeData: ResumeData | null = latestResume\n      ? {\n          content: latestResume.content,\n          atsScore: latestResume.atsScore,\n          keywords: latestResume.keywords\n            ? JSON.parse(latestResume.keywords)\n            : [],\n          predictedRoles: latestResume.predictedRoles\n            ? JSON.parse(latestResume.predictedRoles)\n            : [],\n          analysis: latestResume.analysis\n            ? JSON.parse(latestResume.analysis)\n            : null,\n        }\n      : null;\n\n    // Calculate difficulty\n    const difficultyResult = calculateSmartDifficulty({\n      selectedDifficulty,\n      profile: profileData,\n      resume: resumeData,\n      topic,\n    });\n\n    return NextResponse.json({\n      selectedDifficulty,\n      calculatedDifficulty: difficultyResult.calculatedDifficulty,\n      wasAdjusted: selectedDifficulty !== difficultyResult.calculatedDifficulty,\n      adjustmentReason: difficultyResult.adjustmentReason,\n      confidenceScore: difficultyResult.confidenceScore,\n      breakdown: difficultyResult.breakdown,\n      recommendations: difficultyResult.recommendations,\n      profileSummary: {\n        hasProfile: !!profile,\n        hasResume: !!latestResume,\n        yearsExperience: profileData?.yearsExperience || null,\n        skillsCount: profileData?.skills?.length || 0,\n        targetCompaniesCount: profileData?.targetCompanies?.length || 0,\n      },\n    });\n  } catch (error) {\n    console.error(\"Difficulty preview error:\", error);\n    return NextResponse.json(\n      { error: \"Failed to calculate difficulty\" },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;;;AAAA;;;;;;;;CAQC,GAED;AACA;AACA;AACA;AACA;AAMA;;;;;;;;;;;;AAKO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,uBAAuB;QACvB,MAAM,UAAU,MAAM,IAAA,qMAAI;QAC1B,IAAI,CAAC,SAAS,MAAM,IAAI;YACtB,OAAO,yNAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAe,GAAG;gBAAE,QAAQ;YAAI;QACpE;QAEA,wBAAwB;QACxB,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,EAAE,KAAK,EAAE,qBAAqB,QAAQ,EAAE,GAAG;QAEjD,IAAI,CAAC,OAAO;YACV,OAAO,yNAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAoB,GAC7B;gBAAE,QAAQ;YAAI;QAElB;QAEA,sBAAsB;QACtB,MAAM,oBAAuC;YAAC;YAAQ;YAAU;SAAO;QACvE,IAAI,CAAC,kBAAkB,QAAQ,CAAC,qBAAqB;YACnD,OAAO,yNAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA2B,GACpC;gBAAE,QAAQ;YAAI;QAElB;QAEA,wBAAwB;QACxB,MAAM,UAAU,MAAM,yMAAM,CAAC,OAAO,CAAC,UAAU,CAAC;YAC9C,OAAO;gBAAE,QAAQ,QAAQ,IAAI,CAAC,EAAE;YAAC;QACnC;QAEA,yBAAyB;QACzB,MAAM,eAAe,MAAM,yMAAM,CAAC,MAAM,CAAC,SAAS,CAAC;YACjD,OAAO;gBAAE,QAAQ,QAAQ,IAAI,CAAC,EAAE;YAAC;YACjC,SAAS;gBAAE,YAAY;YAAO;QAChC;QAEA,wBAAwB;QACxB,MAAM,cAAsC,UACxC;YACE,iBAAiB,QAAQ,eAAe;YACxC,QAAQ,QAAQ,MAAM,GAAG,KAAK,KAAK,CAAC,QAAQ,MAAM,IAAI,EAAE;YACxD,iBAAiB,QAAQ,eAAe,GACpC,KAAK,KAAK,CAAC,QAAQ,eAAe,IAClC,EAAE;YACN,YAAY,QAAQ,UAAU;YAC9B,KAAK,QAAQ,GAAG;QAClB,IACA;QAEJ,uBAAuB;QACvB,MAAM,aAAgC,eAClC;YACE,SAAS,aAAa,OAAO;YAC7B,UAAU,aAAa,QAAQ;YAC/B,UAAU,aAAa,QAAQ,GAC3B,KAAK,KAAK,CAAC,aAAa,QAAQ,IAChC,EAAE;YACN,gBAAgB,aAAa,cAAc,GACvC,KAAK,KAAK,CAAC,aAAa,cAAc,IACtC,EAAE;YACN,UAAU,aAAa,QAAQ,GAC3B,KAAK,KAAK,CAAC,aAAa,QAAQ,IAChC;QACN,IACA;QAEJ,gCAAgC;QAChC,MAAM,mBAAmB,IAAA,6OAAwB,EAAC;YAChD;YACA,SAAS;YACT,QAAQ;YACR;QACF;QAEA,MAAM,mBAAmB,iBAAiB,oBAAoB;QAE9D,qCAAqC;QACrC,MAAM,cAAc,MAAM,IAAA,+OAA6B,EAAC;YACtD;YACA,YAAY;YACZ,SAAS;YACT,QAAQ;QACV;QAEA,2CAA2C;QAC3C,MAAM,oBAAoB,IAAA,oPAAkC,EAC1D,aACA;QAGF,8BAA8B;QAC9B,MAAM,YAAY,MAAM,yMAAM,CAAC,SAAS,CAAC,MAAM,CAAC;YAC9C,MAAM;gBACJ,QAAQ,QAAQ,IAAI,CAAC,EAAE;gBACvB;gBACA,YAAY;gBACZ,QAAQ;gBACR,WAAW,IAAI;YACjB;QACF;QAEA,wDAAwD;QACxD,MAAM,oBAAoB,MAAM,IAAA,6MAAU,EAAC;YACzC,UAAU;gBACR;oBAAE,MAAM;oBAAU,SAAS;gBAAkB;gBAC7C;oBAAE,MAAM;oBAAQ,SAAS;gBAAuB;aACjD;YACD,YAAY;YACZ,aAAa;QACf;QAEA,MAAM,iBACJ,kBAAkB,OAAO,EAAE,WAC3B,CAAC,iFAAiF,EAAE,MAAM,+HAA+H,CAAC;QAE5N,gCAAgC;QAChC,MAAM,yMAAM,CAAC,OAAO,CAAC,UAAU,CAAC;YAC9B,MAAM;gBACJ;oBACE,aAAa,UAAU,EAAE;oBACzB,MAAM;oBACN,SAAS;gBACX;gBACA;oBACE,aAAa,UAAU,EAAE;oBACzB,MAAM;oBACN,SAAS;gBACX;aACD;QACH;QAEA,sBAAsB;QACtB,OAAO,yNAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,WAAW;gBACT,IAAI,UAAU,EAAE;gBAChB,OAAO,UAAU,KAAK;gBACtB,YAAY,UAAU,UAAU;gBAChC,QAAQ,UAAU,MAAM;gBACxB,WAAW,UAAU,SAAS;YAChC;YACA;YACA,iBAAiB;gBACf;gBACA,sBAAsB;gBACtB,aAAa,uBAAuB;gBACpC,kBAAkB,iBAAiB,gBAAgB;gBACnD,iBAAiB,iBAAiB,eAAe;gBACjD,WAAW,iBAAiB,SAAS;gBACrC,iBAAiB,iBAAiB,eAAe;YACnD;YACA,aAAa;gBACX,YAAY,YAAY,UAAU;gBAClC,sBAAsB,YAAY,oBAAoB;gBACtD,eAAe,YAAY,SAAS,CAAC,MAAM;YAC7C;QACF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0CAA0C;QACxD,OAAO,yNAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAA0C,GACnD;YAAE,QAAQ;QAAI;IAElB;AACF;AAKO,eAAe,IAAI,OAAoB;IAC5C,IAAI;QACF,MAAM,UAAU,MAAM,IAAA,qMAAI;QAC1B,IAAI,CAAC,SAAS,MAAM,IAAI;YACtB,OAAO,yNAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAe,GAAG;gBAAE,QAAQ;YAAI;QACpE;QAEA,MAAM,EAAE,YAAY,EAAE,GAAG,IAAI,IAAI,QAAQ,GAAG;QAC5C,MAAM,qBACJ,AAAC,aAAa,GAAG,CAAC,iBAAqC;QACzD,MAAM,QAAQ,aAAa,GAAG,CAAC,YAAY;QAE3C,kBAAkB;QAClB,MAAM,UAAU,MAAM,yMAAM,CAAC,OAAO,CAAC,UAAU,CAAC;YAC9C,OAAO;gBAAE,QAAQ,QAAQ,IAAI,CAAC,EAAE;YAAC;QACnC;QAEA,MAAM,eAAe,MAAM,yMAAM,CAAC,MAAM,CAAC,SAAS,CAAC;YACjD,OAAO;gBAAE,QAAQ,QAAQ,IAAI,CAAC,EAAE;YAAC;YACjC,SAAS;gBAAE,YAAY;YAAO;QAChC;QAEA,aAAa;QACb,MAAM,cAAsC,UACxC;YACE,iBAAiB,QAAQ,eAAe;YACxC,QAAQ,QAAQ,MAAM,GAAG,KAAK,KAAK,CAAC,QAAQ,MAAM,IAAI,EAAE;YACxD,iBAAiB,QAAQ,eAAe,GACpC,KAAK,KAAK,CAAC,QAAQ,eAAe,IAClC,EAAE;YACN,YAAY,QAAQ,UAAU;YAC9B,KAAK,QAAQ,GAAG;QAClB,IACA;QAEJ,MAAM,aAAgC,eAClC;YACE,SAAS,aAAa,OAAO;YAC7B,UAAU,aAAa,QAAQ;YAC/B,UAAU,aAAa,QAAQ,GAC3B,KAAK,KAAK,CAAC,aAAa,QAAQ,IAChC,EAAE;YACN,gBAAgB,aAAa,cAAc,GACvC,KAAK,KAAK,CAAC,aAAa,cAAc,IACtC,EAAE;YACN,UAAU,aAAa,QAAQ,GAC3B,KAAK,KAAK,CAAC,aAAa,QAAQ,IAChC;QACN,IACA;QAEJ,uBAAuB;QACvB,MAAM,mBAAmB,IAAA,6OAAwB,EAAC;YAChD;YACA,SAAS;YACT,QAAQ;YACR;QACF;QAEA,OAAO,yNAAY,CAAC,IAAI,CAAC;YACvB;YACA,sBAAsB,iBAAiB,oBAAoB;YAC3D,aAAa,uBAAuB,iBAAiB,oBAAoB;YACzE,kBAAkB,iBAAiB,gBAAgB;YACnD,iBAAiB,iBAAiB,eAAe;YACjD,WAAW,iBAAiB,SAAS;YACrC,iBAAiB,iBAAiB,eAAe;YACjD,gBAAgB;gBACd,YAAY,CAAC,CAAC;gBACd,WAAW,CAAC,CAAC;gBACb,iBAAiB,aAAa,mBAAmB;gBACjD,aAAa,aAAa,QAAQ,UAAU;gBAC5C,sBAAsB,aAAa,iBAAiB,UAAU;YAChE;QACF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,6BAA6B;QAC3C,OAAO,yNAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAiC,GAC1C;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}